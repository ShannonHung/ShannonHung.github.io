<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>How to Handle Multi-Column Text Sorting with Amazon Textract</title>
      <link href="/en/posts/textract-multi-column/"/>
      <url>/en/posts/textract-multi-column/</url>
      
        <content type="html"><![CDATA[<h1 id="前言">前言</h1><p>AWS Textract is an AWS tool used for extracting text from PDFs (or images). Ideally, your original document would have only one column, such as a book. However, things become more complex when dealing with multiple columns, such as newspaper articles. Therefore, this article aims to share how to use Amazon Textract to handle sorting of text from multi-column documents. This article is inspired by <a href="https://medium.com/claranet-ch/aws-textract-how-to-detect-and-sort-text-from-a-multi-column-document-61e411f3e259">AWS Textract: how to detect and sort text from a multi-column document</a>, with some improvements made.</p><p>My source material is a newspaper article, with the layout as shown below:</p><p><img src="https://i.imgur.com/XOevNWt.png" alt=""></p><h1 id="Textract-Response-Format">Textract Response Format</h1><p>The Textract output is structured JSON formed by various BlockTypes. A “Page” BlockType consists of multiple “Line” blocks, and each “Line” block consists of multiple “Word” blocks. In these responses, you cannot see any structural information to simply sort multi-column text into a single column. However, what can be known is that Textract parses text from top to bottom and left to right. You can observe this parsing order from the numbered sections 27 to 48 in the image below, where even though they belong to different columns, Textract parses them sequentially from left to right and top to bottom.</p><p><img src="https://i.imgur.com/kWd9zkK.png" alt=""></p><h1 id="Solution">Solution</h1><p>The approach we adopt is to utilize the bounding box coordinates provided by Textract to draw boundaries around text blocks. By grouping nearby lines into a block, we can identify lines belonging to the same column. The final result will resemble the image below:</p><p><img src="https://i.imgur.com/szs2EFK.png" alt=""></p><p>From the above image, the following information can be inferred:</p><ul><li>The longest block is likely the title.</li><li>Other blocks can be sorted from top to bottom and left to right, allowing us to determine the reading order and understand the distribution of columns.</li></ul><h2 id="Step-1-Define-the-Class">Step 1: Define the Class</h2><p>From the official documentation on <a href="https://docs.aws.amazon.com/zh_tw/textract/latest/dg/text-location.html">how to interpret target locations on the document</a>, it is described as follows:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;BoundingBox&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;Width&quot;</span><span class="punctuation">:</span> <span class="number">0.007353090215474367</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;Height&quot;</span><span class="punctuation">:</span> <span class="number">0.0288887619972229</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;Left&quot;</span><span class="punctuation">:</span> <span class="number">0.08638829737901688</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;Top&quot;</span><span class="punctuation">:</span> <span class="number">0.03477252274751663</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><blockquote><p>From the official documentation<br><img src="https://i.imgur.com/hHWgQl7.png" alt=""><br><img src="https://i.imgur.com/wjdj6r2.png" alt=""></p></blockquote><p>After understanding the format, we can define a class to handle this data:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">```python</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Page</span>: </span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Used to handle the content returned by Textract. Each Page may have one or more Lines.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        page (int): The number of this Page.</span></span><br><span class="line"><span class="string">        lines (Line): The Lines contained in this Page.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, page_number, lines</span>):</span><br><span class="line">        self.lines = lines</span><br><span class="line">        self.page = page_number</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> self.lines:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;line: <span class="subst">&#123;line.__str__()&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;Page: <span class="subst">&#123;self.page&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Block</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Block: This is the Block we are dealing with. Each Block may have one or more Lines.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        page (int): The Page where this Block is located.</span></span><br><span class="line"><span class="string">        id (int): Simply records the index of this Block.</span></span><br><span class="line"><span class="string">        lines (Line): The Lines contained in this Block.</span></span><br><span class="line"><span class="string">        left (float): The x-coordinate of the top-left corner of the Block.</span></span><br><span class="line"><span class="string">        top (float): The y-coordinate of the top-left corner of the Block.</span></span><br><span class="line"><span class="string">        height (float): The height of the Block.</span></span><br><span class="line"><span class="string">        width (float): The width of the Block.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.lines = []</span><br><span class="line">        self.page = <span class="number">0</span></span><br><span class="line">        self.<span class="built_in">id</span> = <span class="string">&quot;&quot;</span></span><br><span class="line">        self.left = <span class="number">0</span> </span><br><span class="line">        self.top = <span class="number">0</span> </span><br><span class="line">        self.height = <span class="number">0</span> </span><br><span class="line">        self.width = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;Block: page=<span class="subst">&#123;self.page&#125;</span>, id=<span class="subst">&#123;self.<span class="built_in">id</span>&#125;</span>, (x1,y1)=(<span class="subst">&#123;self.left&#125;</span>, <span class="subst">&#123;self.top&#125;</span>), (x2,y2)=(<span class="subst">&#123;self.left + self.width&#125;</span>,<span class="subst">&#123;self.top + self.height&#125;</span>)&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_line</span>(<span class="params">self, line</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot; </span></span><br><span class="line"><span class="string">        Add a line to the block and recalculate the center of the block.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.lines.append(line)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Line</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Handles the smallest unit of text.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        page (int): The Page where this Line is located.</span></span><br><span class="line"><span class="string">        Id (int): The Line Id returned by Textract for easy lookup of the corresponding text in the original document.</span></span><br><span class="line"><span class="string">        text (str): The text of the Line.</span></span><br><span class="line"><span class="string">        top (float): The y-coordinate of the top-left corner of the Line.</span></span><br><span class="line"><span class="string">        left (float): The x-coordinate of the top-left corner of the Line.</span></span><br><span class="line"><span class="string">        width (float): The width of the Line.</span></span><br><span class="line"><span class="string">        height (float): The height of the Line.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, Id, page, text, top, left, width, height</span>):</span><br><span class="line">        self.top = top</span><br><span class="line">        self.left = left</span><br><span class="line">        self.width = width</span><br><span class="line">        self.height = height</span><br><span class="line">        self.page = page</span><br><span class="line">        self.Id = Id</span><br><span class="line">        self.text = text </span><br><span class="line">        self.center = self.get_center()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;Line: \t page=<span class="subst">&#123;self.page&#125;</span>, Id=<span class="subst">&#123;self.Id&#125;</span>, Text=<span class="subst">&#123;self.text&#125;</span>, \n\t (x1,y1)=(<span class="subst">&#123;self.left&#125;</span>, top=<span class="subst">&#123;self.top&#125;</span>); width=<span class="subst">&#123;self.width&#125;</span>, height=<span class="subst">&#123;self.height&#125;</span> \n&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_center</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Get the center of the Line.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        x = self.left</span><br><span class="line">        y = self.top</span><br><span class="line">        x1 = self.left + self.width</span><br><span class="line">        y1 = self.top + self.height</span><br><span class="line">        x_center = (x + x1) / <span class="number">2</span></span><br><span class="line">        y_center = (y + y1) / <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> [x_center, y_center]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Step-2-General-Function">Step 2: General Function</h2><p>Next, we need some general functions to handle the data. Here, we will need the following functions:</p><ul><li><code>read_json_file</code>: Read the JSON file returned by Textract.</li><li><code>two_point_distance</code>: Calculate the distance between two points. This will be used to calculate whether the center distance between Lines is too far.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo>=</mo><msqrt><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo>−</mo><msub><mi>x</mi><mn>1</mn></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><msub><mi>y</mi><mn>2</mn></msub><mo>−</mo><msub><mi>y</mi><mn>1</mn></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></msqrt></mrow><annotation encoding="application/x-tex">d = \sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.24em;vertical-align:-0.305em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.935em;"><span class="svg-align" style="top:-3.2em;"><span class="pstrut" style="height:3.2em;"></span><span class="mord" style="padding-left:1em;"><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7401em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7401em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-2.895em;"><span class="pstrut" style="height:3.2em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.28em;"><svg xmlns="http://www.w3.org/2000/svg" width='400em' height='1.28em' viewBox='0 0 400000 1296' preserveAspectRatio='xMinYMin slice'><path d='M263,681c0.7,0,18,39.7,52,119c34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120c340,-704.7,510.7,-1060.3,512,-1067l0 -0c4.7,-7.3,11,-11,19,-11H40000v40H1012.3s-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232c-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1s-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60zM1001 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.305em;"><span></span></span></span></span></span></span></span></span></li></ul></li><li><code>two_point_height</code>: Calculate the vertical distance between two Lines to determine if they are close enough.</li><li><code>pretty_similar</code>: Determine if the difference is within an acceptable range.</li><li><code>print_blocks</code>: Print information about Blocks.</li><li><code>get_lines_from_json</code>: Get information about Lines from the JSON returned by Textract.</li><li><code>find_block_corners</code>: Find the four corner coordinates of a Block to enclose all Lines.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> json </span><br><span class="line"><span class="keyword">from</span> pdf2image <span class="keyword">import</span> convert_from_bytes</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.patches <span class="keyword">import</span> Rectangle</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_json_file</span>(<span class="params">file_name</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_name, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">        <span class="keyword">return</span> json.load(file)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">two_point_distance</span>(<span class="params">x, y, x1, y1</span>):</span><br><span class="line">    distance = math.sqrt((x - x1) ** <span class="number">2</span> + (y - y1) ** <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> distance</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">two_point_hight</span>(<span class="params">y, y1</span>): </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">abs</span>(y-y1)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pretty_similar</span>(<span class="params">x, x1, tolerance</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">abs</span>(x - x1) &lt; tolerance</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">print_blocks</span>(<span class="params">blocks</span>):</span><br><span class="line">    <span class="keyword">for</span> block <span class="keyword">in</span> blocks:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;block.__str__()&#125;</span>&quot;</span>)</span><br><span class="line">        last_line = block.lines[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> block.lines:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Line: \t Page=<span class="subst">&#123;line.page&#125;</span>, Id=<span class="subst">&#123;line.Id&#125;</span>, left=<span class="subst">&#123;line.left&#125;</span>, top=<span class="subst">&#123;line.top&#125;</span>, width=<span class="subst">&#123;line.width&#125;</span>, height=<span class="subst">&#123;line.height&#125;</span>, center=<span class="subst">&#123;line.center&#125;</span> two_point_distance = <span class="subst">&#123;two_point_distance(last_line.center[<span class="number">0</span>], last_line.center[<span class="number">1</span>], line.center[<span class="number">0</span>], line.center[<span class="number">1</span>])&#125;</span> (x1,y1)=(<span class="subst">&#123;line.left&#125;</span>, <span class="subst">&#123;line.top&#125;</span>), (x2,y2)=(<span class="subst">&#123;line.left + line.width&#125;</span>,<span class="subst">&#123;line.top + line.height&#125;</span>)&quot;</span>)</span><br><span class="line">            last_line = line</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_lines_from_json</span>(<span class="params">file_path</span>):</span><br><span class="line">    json_response = read_json_file(file_path)</span><br><span class="line">    lines = []</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> json_response[<span class="string">&quot;Blocks&quot;</span>]:</span><br><span class="line">        <span class="keyword">if</span> item[<span class="string">&quot;BlockType&quot;</span>] == <span class="string">&quot;LINE&quot;</span>:</span><br><span class="line">            box = item[<span class="string">&quot;Geometry&quot;</span>][<span class="string">&quot;BoundingBox&quot;</span>]</span><br><span class="line">            lines.append(Line(item[<span class="string">&quot;Id&quot;</span>], item[<span class="string">&quot;Page&quot;</span>], item[<span class="string">&quot;Text&quot;</span>], box[<span class="string">&quot;Top&quot;</span>], box[<span class="string">&quot;Left&quot;</span>], box[<span class="string">&quot;Width&quot;</span>], box[<span class="string">&quot;Height&quot;</span>]))</span><br><span class="line">    <span class="keyword">return</span> lines</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">find_block_corners</span>(<span class="params">blocks</span>): </span><br><span class="line">    min_top = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">    min_left = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> index, block <span class="keyword">in</span> <span class="built_in">enumerate</span>(blocks):</span><br><span class="line">        min_top = <span class="built_in">min</span>(line.top <span class="keyword">for</span> line <span class="keyword">in</span> block.lines)</span><br><span class="line">        min_left = <span class="built_in">min</span>(line.left <span class="keyword">for</span> line <span class="keyword">in</span> block.lines)</span><br><span class="line">        max_bottom = <span class="built_in">max</span>(line.top + line.height <span class="keyword">for</span> line <span class="keyword">in</span> block.lines)</span><br><span class="line">        max_right = <span class="built_in">max</span>(line.left + line.width <span class="keyword">for</span> line <span class="keyword">in</span> block.lines)</span><br><span class="line"></span><br><span class="line">        block.height = max_bottom - min_top </span><br><span class="line">        block.width = max_right - min_left</span><br><span class="line">        block.top = min_top</span><br><span class="line">        block.left = min_left </span><br><span class="line">        block.<span class="built_in">id</span> = index</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> blocks</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_image_bbox</span>(<span class="params">pdf_file, blocks</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Use to show the image with bounding box</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(pdf_file, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">        images = convert_from_bytes(file.read())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> index, image <span class="keyword">in</span> <span class="built_in">enumerate</span>(images):</span><br><span class="line">        width, height =image.size  </span><br><span class="line">        page = index + <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Process Page Index: <span class="subst">&#123;page&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        plt.figure(figsize=(<span class="number">20</span>,<span class="number">16</span>))</span><br><span class="line">        plt.imshow(image)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># iterate over the blocks </span></span><br><span class="line">        <span class="keyword">for</span> i, block <span class="keyword">in</span> <span class="built_in">enumerate</span>(blocks):</span><br><span class="line">            <span class="keyword">if</span> (block.page == page):</span><br><span class="line">                rect = Rectangle((width * block.left, height * block.top), block.width * width, block.height * height, edgecolor=<span class="string">&#x27;r&#x27;</span>, facecolor=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">                plt.text(width * block.left, height * block.top, block.<span class="built_in">id</span>, fontsize=<span class="number">12</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">                plt.gca().add_patch(rect)</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure><h2 id="Step-3-Define-Rule-of-Block">Step 3: Define Rule of Block</h2><p>Now we need to design the conditions under which a Block can be formed. The rules we design are as follows:<br><img src="https://i.imgur.com/l5NS4ZB.png" alt=""></p><p>The code for defining the rules is as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">is_two_line_close</span>(<span class="params">block, target_line, cur_line</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Check if two lines are close enough, so we can merge them into a block</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    left_tolerance = <span class="number">0.02</span></span><br><span class="line">    width_tolerance =  <span class="number">0.01</span> <span class="comment"># [left_tolerance, (target_line.width - cur_line.width).abs / 2].max</span></span><br><span class="line">    distance_tolerance = <span class="number">0.04</span></span><br><span class="line">    height_tolerance = <span class="number">0.03</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_left_similar</span>(<span class="params">line1, line2, tolerance = left_tolerance</span>):</span><br><span class="line">        <span class="keyword">return</span> pretty_similar(line1.left, line2.left, tolerance)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_width_similar</span>(<span class="params">line1, line2, tolerance = width_tolerance</span>): </span><br><span class="line">        <span class="keyword">return</span>  pretty_similar(line1.width, line2.width, tolerance)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_height_similar</span>(<span class="params">line1, line2, tolerance = height_tolerance</span>):</span><br><span class="line">        <span class="keyword">return</span> two_point_hight(line1.top, line2.top) &lt; tolerance </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_on_same_page</span>(<span class="params">line1, line2</span>):</span><br><span class="line">        <span class="keyword">return</span> line1.page == line2.page</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_center_close</span>(<span class="params">line1, line2</span>):</span><br><span class="line">        <span class="keyword">return</span> two_point_distance(line1.center[<span class="number">0</span>], line1.center[<span class="number">1</span>], line2.center[<span class="number">0</span>], line2.center[<span class="number">1</span>]) &lt; distance_tolerance</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_same_paragraph</span>():</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Use to handle the same paragraph</span></span><br><span class="line"><span class="string">        If the starting point on the left is the same and the height is similar, they are in the same Block</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> (is_left_similar(target_line, cur_line) <span class="keyword">and</span> </span><br><span class="line">            is_height_similar(block.lines[-<span class="number">1</span>], cur_line)):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span> </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span> </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_text_center_context</span>():</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Use to handle the text in the center</span></span><br><span class="line"><span class="string">        If the center is close and the height is similar, they are in the same Block</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> (is_center_close(target_line, cur_line) <span class="keyword">and</span> is_height_similar(block.lines[-<span class="number">1</span>], cur_line))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># First check if they are on the same page, as a Block cannot span multiple pages</span></span><br><span class="line">    <span class="keyword">if</span> is_on_same_page(target_line, cur_line): </span><br><span class="line">        <span class="comment"># If in the same paragraph or the text is centered, select them into block</span></span><br><span class="line">        <span class="keyword">if</span> is_same_paragraph() <span class="keyword">or</span> is_text_center_context():</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>: </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><h2 id="Step-4-Iterate-Line-to-Form-Block">Step 4: Iterate Line to Form Block</h2><p>Then we can start iterating through all the Lines to find the Block.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">merge_lines_to_block</span>(<span class="params">lines</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Merge Lines into Blocks.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    ready_blocks = [] </span><br><span class="line"></span><br><span class="line">    <span class="comment"># As long as there are still lines, continue to form Blocks</span></span><br><span class="line">    <span class="keyword">while</span> lines: </span><br><span class="line">        block = Block()</span><br><span class="line">        target_line = lines[<span class="number">0</span>] <span class="comment"># Take the first Line as the first object to compare for forming a Block</span></span><br><span class="line">        block.add_line(lines[<span class="number">0</span>]) <span class="comment"># Add the target_line to the Block</span></span><br><span class="line">        block.page = target_line.page <span class="comment"># Set the Block&#x27;s Page</span></span><br><span class="line">        lines.pop(<span class="number">0</span>) <span class="comment"># Remove the target_line from lines</span></span><br><span class="line">        index = <span class="number">0</span>  <span class="comment"># Reset index to 0 because pop affects the index order</span></span><br><span class="line">        <span class="comment"># Recursively iterate through all Lines until there are no more lines to compare</span></span><br><span class="line">        <span class="keyword">while</span> index &lt; <span class="built_in">len</span>(lines):</span><br><span class="line">            cur_line = lines[index]</span><br><span class="line">            <span class="keyword">if</span> target_line.page == cur_line.page: </span><br><span class="line">                <span class="comment"># If the width is the same, the centers cannot be too far apart</span></span><br><span class="line">                <span class="keyword">if</span> is_two_line_close(block, target_line, cur_line):</span><br><span class="line">                    block.add_line(cur_line)</span><br><span class="line">                    lines.pop(index) <span class="comment"># After popping, cur_line needs to start from index 0</span></span><br><span class="line">                    index = <span class="number">0</span>  <span class="comment"># Reset index to 0</span></span><br><span class="line">                    <span class="keyword">continue</span>  <span class="comment"># Continue to the next iteration</span></span><br><span class="line">            index += <span class="number">1</span>  <span class="comment"># Check the next element</span></span><br><span class="line"></span><br><span class="line">        ready_blocks.append(block) <span class="comment"># Add the organized Block to the list</span></span><br><span class="line">    <span class="keyword">return</span> ready_blocks</span><br></pre></td></tr></table></figure><h2 id="Step-5-Execution">Step 5: Execution</h2><p>Finally, we can execute the code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">json_path = <span class="string">&quot;./result/test.json&quot;</span> <span class="comment"># Path to the JSON file returned by Textract</span></span><br><span class="line">pdf_path = <span class="string">&quot;../../src/test.pdf&quot;</span></span><br><span class="line"></span><br><span class="line">lines = get_lines_from_json(json_path) <span class="comment"># Get information about Lines from the JSON returned by Textract</span></span><br><span class="line">blocks = merge_lines_to_block(lines) <span class="comment"># Merge Lines into Blocks </span></span><br><span class="line">blocks = find_block_corners(blocks) <span class="comment"># Find the four corner coordinates of a Block to enclose all Lines</span></span><br><span class="line">show_image_bbox(pdf_path, blocks) <span class="comment"># Display the image with bounding boxes around Blocks</span></span><br><span class="line"><span class="comment">#print_blocks(blocks) # Print information about Blocks</span></span><br></pre></td></tr></table></figure><p>The result is shown in the image below:<br><img src="https://i.imgur.com/szs2EFK.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> Tech </category>
          
          <category> OCR </category>
          
      </categories>
      
      
        <tags>
            
            <tag> aws </tag>
            
            <tag> textract </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Twitter Dataset - Using LSTM to predict the emotion of the article</title>
      <link href="/en/posts/nlp-twitter-emotion-diagnoise/"/>
      <url>/en/posts/nlp-twitter-emotion-diagnoise/</url>
      
        <content type="html"><![CDATA[<h1 id="Introduction">Introduction</h1><p>Recently, I took an AI course, and this is the sixth assignment. The main content taught includes the following topics:</p><ol><li>Learn to use LSTM</li><li>Use SpaCy</li></ol><h1 id="Homework-Requirements">Homework Requirements</h1><p>Train a text classification on the <a href="https://github.com/cardiffnlp/tweeteval">TweetEval</a> emotion recognition dataset using LSTMs and GRUs.</p><ol><li><strong>Build an LSTM model</strong>: Follow the example described <a href="https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html">here</a>. Use the same architecture, but:<ol><li>only use the last output of the LSTM in the loss function</li><li>use an embedding dim of 128</li><li>use a hidden dim of 256.</li></ol></li><li><strong>Use SpaCy to split words</strong>: Use spaCy to split the tweets into words.</li><li><strong>Select the Top 5000 words</strong>: Limit your vocabulary (i.e., the words that you converted to an index) to the most frequent 5000 words and replace all other words with a placeholder index (e.g., 1001).</li><li><strong>Train the model and calculate accuracy</strong>: Evaluate the accuracy on the test set. (Note: If the training takes too long, try to use only a fraction of the training data.)</li><li><strong>Build and train a GRU model</strong>: Do the same, but this time use GRUs instead of LSTMs.</li></ol><h1 id="Task-0-Download-the-Dataset">Task 0: Download the Dataset</h1><div class="note info flat"><p>In this section, we need to do the following:</p><ol><li>Download the dataset</li><li>Use pandas to convert the dataset into the format we need</li></ol></div><h2 id="Download-the-Dataset">Download the Dataset</h2><ol><li>Refer to this link to download the required data: <a href="https://github.com/cardiffnlp/tweeteval">TweetEval</a></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/cardiffnlp/tweeteval.git</span><br></pre></td></tr></table></figure><ol start="2"><li>After downloading, you can see the following information, the <code>emotion</code> folder is the information we will use this time:</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── README.md</span><br><span class="line">├── TweetEval_Tutorial.ipynb</span><br><span class="line">├── datasets</span><br><span class="line">│   ├── README.txt</span><br><span class="line">│   ├── emoji</span><br><span class="line">│   ├── emotion <span class="comment"># This is the data we need</span></span><br><span class="line">│   │   ├── mapping.txt <span class="comment"># Emotion corresponding to numbers e.g. &#123;0:&#x27;angry&#x27;, 1:&#x27;happy&#x27;&#125;</span></span><br><span class="line">│   │   ├── test_labels.txt <span class="comment"># Emotion labels for test data, i.e., the answers e.g. 0 </span></span><br><span class="line">│   │   ├── test_text.txt <span class="comment"># Content of the test data e.g. &quot;I&#x27;m so angry&quot;</span></span><br><span class="line">│   │   ├── train_labels.txt <span class="comment"># Emotion labels for training data, i.e., the answers e.g. 0</span></span><br><span class="line">│   │   ├── train_text.txt <span class="comment"># Content of the training data e.g. &quot;I&#x27;m so angry&quot;</span></span><br><span class="line">│   │   ├── val_labels.txt <span class="comment"># Emotion labels for validation data, i.e., the answers e.g. 0</span></span><br><span class="line">│   │   └── val_text.txt <span class="comment"># Content of the validation data e.g. &quot;I&#x27;m so angry&quot;</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><h2 id="Covert-data-format">Covert data format</h2><p>We first introduce the required packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CNN</span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> lr_scheduler</span><br><span class="line"></span><br><span class="line"><span class="comment"># others</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> tempfile <span class="keyword">import</span> TemporaryDirectory</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># dataset</span></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, models, transforms</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> Flowers102</span><br><span class="line"></span><br><span class="line"><span class="comment"># read file </span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># label</span></span><br><span class="line"><span class="keyword">from</span> scipy.io <span class="keyword">import</span> loadmat</span><br><span class="line"><span class="keyword">import</span> json</span><br></pre></td></tr></table></figure><p>Then we convert the data into the format we need, this time we use <code>panda</code> to process the data and read the data into variables for later use.</p><div class="note warning flat"><p>Make sure to change the root path to the folder path of your git clone!</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set the relative path of each file first </span></span><br><span class="line">root = <span class="string">&#x27;../../Data/tweeteval/datasets/emotion/&#x27;</span></span><br><span class="line">mapping_file = os.path.join(root, <span class="string">&#x27;mapping.txt&#x27;</span>)</span><br><span class="line">test_labels_file = os.path.join(root, <span class="string">&#x27;test_labels.txt&#x27;</span>)</span><br><span class="line">test_text_file = os.path.join(root, <span class="string">&#x27;test_text.txt&#x27;</span>)</span><br><span class="line">train_labels_file = os.path.join(root, <span class="string">&#x27;train_labels.txt&#x27;</span>)</span><br><span class="line">train_text_file = os.path.join(root, <span class="string">&#x27;train_text.txt&#x27;</span>)</span><br><span class="line">val_labels_file = os.path.join(root, <span class="string">&#x27;val_labels.txt&#x27;</span>)</span><br><span class="line">val_text_file = os.path.join(root, <span class="string">&#x27;val_text.txt&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use panda to read the data and read the labels </span></span><br><span class="line">mapping_pd = pd.read_csv(mapping_file, sep=<span class="string">&#x27;\t&#x27;</span>, header=<span class="literal">None</span>)</span><br><span class="line">test_label_pd = pd.read_csv(test_labels_file, sep=<span class="string">&#x27;\t&#x27;</span>, header=<span class="literal">None</span>)</span><br><span class="line">train_label_pd = pd.read_csv(train_labels_file, sep=<span class="string">&#x27;\t&#x27;</span>, header=<span class="literal">None</span>)</span><br><span class="line">val_label_pd = pd.read_csv(val_labels_file, sep=<span class="string">&#x27;\t&#x27;</span>, header=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use \n to split the content of the training and testing data, and remove the last blank word_embeddings </span></span><br><span class="line"><span class="comment"># because test_dataset[-1] is empty, and the length will be consistent with the length of labels after removing the length </span></span><br><span class="line">test_dataset = <span class="built_in">open</span>(test_text_file).read().split(<span class="string">&#x27;\n&#x27;</span>)[:-<span class="number">1</span>] <span class="comment"># remove last empty line </span></span><br><span class="line">train_dataset = <span class="built_in">open</span>(train_text_file).read().split(<span class="string">&#x27;\n&#x27;</span>)[:-<span class="number">1</span>] <span class="comment"># remove last empty line</span></span><br><span class="line">val_dataset = <span class="built_in">open</span>(val_text_file).read().split(<span class="string">&#x27;\n&#x27;</span>)[:-<span class="number">1</span>] <span class="comment"># remove last empty line</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the length of the dataset </span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;len(train_dataset)= <span class="subst">&#123;<span class="built_in">len</span>(train_dataset)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;len(train_label_pd)= <span class="subst">&#123;<span class="built_in">len</span>(train_label_pd)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;=== train_label_pd === \n<span class="subst">&#123;train_label_pd.value_counts()&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;len(test_dataset)= <span class="subst">&#123;<span class="built_in">len</span>(test_dataset)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;len(test_label_pd)= <span class="subst">&#123;<span class="built_in">len</span>(test_label_pd)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;=== test_label_pd === \n<span class="subst">&#123;test_label_pd.value_counts()&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><blockquote><p>Result</p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(train_dataset)= <span class="number">3257</span></span><br><span class="line"><span class="built_in">len</span>(train_label_pd)= <span class="number">3257</span></span><br><span class="line">=== train_label_pd === </span><br><span class="line"><span class="number">0</span>    <span class="number">1400</span></span><br><span class="line"><span class="number">3</span>     <span class="number">855</span></span><br><span class="line"><span class="number">1</span>     <span class="number">708</span></span><br><span class="line"><span class="number">2</span>     <span class="number">294</span></span><br><span class="line">Name: count, dtype: int64</span><br><span class="line"><span class="built_in">len</span>(test_dataset)= <span class="number">1421</span></span><br><span class="line"><span class="built_in">len</span>(test_label_pd)= <span class="number">1421</span></span><br><span class="line">=== test_label_pd === </span><br><span class="line"><span class="number">0</span>    <span class="number">558</span></span><br><span class="line"><span class="number">3</span>    <span class="number">382</span></span><br><span class="line"><span class="number">1</span>    <span class="number">358</span></span><br><span class="line"><span class="number">2</span>    <span class="number">123</span></span><br><span class="line">Name: count, dtype: int64</span><br></pre></td></tr></table></figure><h1 id="Task-1-5-Build-LSTM-GRU-Models">Task 1 + 5: Build LSTM, GRU Models</h1><div class="note info flat"><ol><li><strong>Build an LSTM model</strong>: Follow the example described <a href="https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html">here</a>. Use the same architecture, but:<ol><li>only use the last output of the LSTM in the loss function</li><li>use an embedding dim of 128</li><li>use a hidden dim of 256.</li></ol></li><li><strong>Build and train a GRU model</strong>: Do the same, but this time use GRUs instead of LSTMs.</li></ol></div><p>From the official example, we can learn how to build an LSTM model, which basically includes the following elements:</p><ul><li><code>hidden_dim</code>: The dimension of the hidden layer, representing the number of neurons in the hidden layer.</li><li><code>word_embeddings</code>: Converts each word in the input sentence into word vectors.<ul><li><code>embedding_dim(vocab_size, embedding_dim)</code>:<ul><li><code>vocab_size</code>: The size of the dictionary, i.e., the total number of words we have. In this example, we will input 5001 words: 5000 common words + 1 unrecognized word.</li><li><code>embedding_dim</code>: Represents mapping each word or symbol to a fixed-size vector space. For instance, if your <code>embedding_dim</code> is set to 6, and your input vector is [1, 2, 3, 5], the model will map each number to a six-dimensional vector space, forming a representation like [1, 2, 3, 5, 6, 4].</li></ul></li><li><code>lstm(input_size, hidden_size, dropout)</code><ul><li><code>input_size</code>: The dimension of the input, which is our word vector dimension.</li><li><code>hidden_size</code>: The dimension of the hidden layer, representing the number of neurons in the hidden layer.</li><li><code>dropout</code>: The proportion of dropout, default is 0, meaning no dropout is used.</li></ul></li><li><code>hidden2tag(in_features, out_features)</code><ul><li><code>in_features</code>: The input dimension, which is also the word vector dimension.</li><li><code>out_features</code>: The output dimension, which is the dimension of our emotion labels.</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LSTMTagger</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embedding_dim, hidden_dim, vocab_size, tagset_size, dropout=<span class="number">0.0</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(LSTMTagger, self).__init__()</span><br><span class="line">        self.hidden_dim = hidden_dim</span><br><span class="line">        <span class="comment"># Convert the input word into a word vector </span></span><br><span class="line">        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># The LSTM takes word embeddings as inputs, and outputs hidden states</span></span><br><span class="line">        <span class="comment"># with dimensionality hidden_dim.</span></span><br><span class="line">        self.lstm = nn.LSTM(embedding_dim, hidden_dim, dropout=dropout)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># The linear layer that maps from hidden state space to tag space</span></span><br><span class="line">        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, sentence</span>):</span><br><span class="line">        <span class="comment"># convert the input word into a word vector. Now the sentence is already an index vector</span></span><br><span class="line">        embeds = self.word_embeddings(sentence) </span><br><span class="line">        <span class="comment"># Use the index vector as the input of the LSTM model to get the output and hidden state of the LSTM layer</span></span><br><span class="line">        lstm_out, _ = self.lstm(embeds.view(<span class="built_in">len</span>(sentence), <span class="number">1</span>, -<span class="number">1</span>)) </span><br><span class="line">        <span class="comment"># Take only the last output of the LSTM</span></span><br><span class="line">        last_output = lstm_out[-<span class="number">1</span>].view(<span class="number">1</span>, -<span class="number">1</span>)  </span><br><span class="line">        tag_space = self.hidden2tag(last_output) <span class="comment">#  Use the last output of the LSTM model to convert to the word tag space</span></span><br><span class="line">        tag_scores = F.log_softmax(tag_space, dim=<span class="number">1</span>) <span class="comment"># Use log_softmax to convert to probability </span></span><br><span class="line">        <span class="keyword">return</span> tag_scores</span><br></pre></td></tr></table></figure><p>GRU and LSTM are similar, except that the only thing to modify is:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GRUTagger</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embedding_dim, hidden_dim, vocab_size, tagset_size, dropout=<span class="number">0.0</span></span>):</span><br><span class="line">        ...</span><br><span class="line">        <span class="comment"># Here !!! Change to GRU  </span></span><br><span class="line">        self.gru = nn.GRU(embedding_dim, hidden_dim, dropout=dropout)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, sentence</span>):</span><br><span class="line">        ...</span><br><span class="line">        <span class="comment"># Here !!! Change to GRU </span></span><br><span class="line">        <span class="comment">## Use the index vector as the input of the GRU model to get the output and hidden state of the GRU layer</span></span><br><span class="line">        gru_out, _ = self.gru(embeds.view(<span class="built_in">len</span>(sentence), <span class="number">1</span>, -<span class="number">1</span>)) <span class="comment"># 將詞向量作為LSTM模型的輸入 得到LSTM曾的輸出和隱藏狀態</span></span><br><span class="line">        last_output = gru_out[-<span class="number">1</span>].view(<span class="number">1</span>, -<span class="number">1</span>) <span class="comment"># Selecting the last output 為了滿足作業要求，我們只取最後一個輸出 </span></span><br><span class="line">        ... </span><br></pre></td></tr></table></figure><p>After the above modification, the completed LSTM program is as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GRUTagger</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embedding_dim, hidden_dim, vocab_size, tagset_size, dropout=<span class="number">0.0</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(GRUTagger, self).__init__()</span><br><span class="line">        self.hidden_dim = hidden_dim</span><br><span class="line">        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)</span><br><span class="line">        self.gru = nn.GRU(embedding_dim, hidden_dim, dropout=dropout) <span class="comment"># &lt;== Here ! </span></span><br><span class="line">        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, sentence</span>):</span><br><span class="line">        embeds = self.word_embeddings(sentence) </span><br><span class="line">        gru_out, _ = self.gru(embeds.view(<span class="built_in">len</span>(sentence), <span class="number">1</span>, -<span class="number">1</span>))  <span class="comment"># &lt;== Here ! </span></span><br><span class="line">        last_output = gru_out[-<span class="number">1</span>].view(<span class="number">1</span>, -<span class="number">1</span>)  <span class="comment"># &lt;== Here ! </span></span><br><span class="line">        tag_space = self.hidden2tag(last_output)</span><br><span class="line">        tag_scores = F.log_softmax(tag_space, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> tag_scores</span><br></pre></td></tr></table></figure><h1 id="Task-2-3-Split-Words-Using-SpaCy-Find-Top-5000-Words">Task 2 + 3: Split Words Using SpaCy, Find Top 5000 Words</h1><div class="note info flat"><p>We have already placed the necessary data into a list variable in Task 0, with each data entry being a sentence. Now, we need to do a few things:<br>2. <strong>Split Words Using SpaCy</strong>: Use spaCy to split the tweets into words.<br>3. <strong>Select Top 5000 Words</strong>: Limit your vocabulary (i.e., the words that you converted to an index) to the most frequent 5000 words and replace all other words with a placeholder index (e.g., 1001).</p></div><h2 id="Install-SpaCy">Install SpaCy</h2><p>We need to execute the following commands to install the SpaCy package:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># If you are using Python3 </span></span><br><span class="line">pip install -U spacy</span><br><span class="line"><span class="comment"># If you are using Anaconda </span></span><br><span class="line">conda install -c conda-forge spacy</span><br></pre></td></tr></table></figure><p>As we are analyzing English text, we need to download the English model. Execute the following command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m spacy download en_core_web_sm</span><br></pre></td></tr></table></figure><p>Only then can we import the spacy package in the notebook and use the English model.</p><div class="note warning flat"><p>If the above command is not executed, you will encounter an error here!!<br>nlp = spacy.load(“en_core_web_sm”)</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy </span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="comment"># use spacy to tokenize the sentence with english model </span></span><br><span class="line">nlp = spacy.load(<span class="string">&quot;en_core_web_sm&quot;</span>) <span class="comment"># &lt;=== If the above command is not executed, you will encounter an error here!!</span></span><br></pre></td></tr></table></figure><h2 id="Prepare-a-Dictionary-of-Top-5000-Common-Words">Prepare a Dictionary of Top 5000 Common Words</h2><p>We need to identify the top 5000 common words and create a dictionary for this purpose:</p><ol><li>First, prepare a string concatenating all sentences.</li><li>Then, send the entire string to spacy for data segmentation, filtering out <code>punctuation (punct)</code>, <code>stop words</code>, and <code>spaces</code>.</li><li>Use the Counter package to count the words, which facilitates identifying the top 5000 common words.</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># join all the sentence together </span></span><br><span class="line"><span class="comment"># e.g. [&#x27;today is good&#x27;, &#x27;today is bad&#x27;] =&gt; [&#x27;today is good today is bad&#x27;]</span></span><br><span class="line">text = <span class="string">&#x27; &#x27;</span>.join(train_dataset)</span><br><span class="line"></span><br><span class="line"><span class="comment"># use spacy to tokenize the sentence </span></span><br><span class="line">doc = nlp(text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># filter out the punctuation and stop words</span></span><br><span class="line">word_freq = Counter(token.text <span class="keyword">for</span> token <span class="keyword">in</span> doc \</span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> token.is_punct <span class="keyword">and</span> \</span><br><span class="line">                        <span class="keyword">not</span> token.is_stop <span class="keyword">and</span> \</span><br><span class="line">                            <span class="keyword">not</span> token.is_space )</span><br><span class="line">word_freq</span><br></pre></td></tr></table></figure><blockquote><p>Result</p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Counter(&#123;<span class="string">&#x27;@user&#x27;</span>: <span class="number">2019</span>, <span class="comment">--  @user appear 2019 times</span></span><br><span class="line">         <span class="string">&#x27;like&#x27;</span>: <span class="number">212</span>,</span><br><span class="line">         <span class="string">&#x27;amp&#x27;</span>: <span class="number">148</span>,</span><br><span class="line">         <span class="string">&#x27;people&#x27;</span>: <span class="number">126</span>,</span><br><span class="line">         <span class="string">&#x27;know&#x27;</span>: <span class="number">96</span>,</span><br><span class="line">         <span class="string">&#x27;think&#x27;</span>: <span class="number">92</span>,</span><br><span class="line">         <span class="string">&#x27;sad&#x27;</span>: <span class="number">90</span>,</span><br><span class="line">         <span class="string">&#x27;got&#x27;</span>: <span class="number">85</span>,</span><br><span class="line">         <span class="string">&#x27;day&#x27;</span>: <span class="number">81</span>,</span><br><span class="line">         <span class="string">&#x27;u&#x27;</span>: <span class="number">80</span>,</span><br><span class="line">         <span class="string">&#x27;time&#x27;</span>: <span class="number">78</span>,</span><br><span class="line">         <span class="string">&#x27;✨&#x27;</span>: <span class="number">75</span>,</span><br><span class="line">         <span class="string">&#x27;😂&#x27;</span>: <span class="number">75</span>,</span><br><span class="line">         <span class="string">&#x27;want&#x27;</span>: <span class="number">74</span>,</span><br><span class="line">         <span class="string">&#x27;life&#x27;</span>: <span class="number">73</span>,</span><br><span class="line">         <span class="string">&#x27;going&#x27;</span>: <span class="number">69</span>,</span><br><span class="line">         <span class="string">&#x27;feel&#x27;</span>: <span class="number">67</span>,</span><br><span class="line">         <span class="string">&#x27;angry&#x27;</span>: <span class="number">66</span>,</span><br><span class="line">         <span class="string">&#x27;2&#x27;</span>: <span class="number">65</span>,</span><br><span class="line">         ...&#125;)</span><br></pre></td></tr></table></figure><p>Next, we can select the top 5000 words based on the number of times they appear:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># select the top 5000 most common words </span></span><br><span class="line">most_common_words = word_freq.most_common(<span class="number">5000</span>)</span><br><span class="line"><span class="comment"># Build a dictionary mapping words to indexes e.g. &#123;&#x27;hello&#x27;:0, &#x27;like&#x27;:1 ...&#125; </span></span><br><span class="line">vocab = &#123;word[<span class="number">0</span>]: idx <span class="keyword">for</span> idx, word <span class="keyword">in</span> <span class="built_in">enumerate</span>(most_common_words)&#125;</span><br></pre></td></tr></table></figure><h2 id="Convert-Sentences-to-Tensors">Convert Sentences to Tensors</h2><p>With the <code>vocab</code> dictionary at hand, we can now convert sentences into an index format based on this dictionary. For example:</p><ul><li>Original sentence: <code>I like apple</code></li><li>Converted into index format: <code>[100, 3923, 123]</code></li></ul><p>But what if we encounter a word that we don’t understand or is not included in the dictionary?</p><ul><li>Here, we also need a <code>placeholder_index</code>.</li><li>When a word in our sentence is not in the <code>vocab</code> dictionary, we convert that word to the <code>placeholder_index</code>.</li><li>We set this as 5000, representing an unrecognizable word. For example:<ul><li>Original sentence: <code>I like jifw8evjk</code></li><li>Converted into index format: <code>[100, 3923, 5000]</code></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Convert words to indexes, and use the placeholder index 5000 for words that are not in the vocabulary table </span></span><br><span class="line">placeholder_index = <span class="number">5000</span></span><br><span class="line"><span class="comment"># Store the result of the entire dataset converted to index </span></span><br><span class="line">indexed_dataset = []</span><br><span class="line"><span class="comment"># Iterate over the entire dataset</span></span><br><span class="line"><span class="keyword">for</span> tweet <span class="keyword">in</span> train_dataset:</span><br><span class="line">    <span class="comment"># Build an empty list to store the results of the current sentence (e.g. I like apple -&gt; [100, 3923, 123])</span></span><br><span class="line">    indexed_words = []</span><br><span class="line">    <span class="comment"># Use spacy to split the sentence into words</span></span><br><span class="line">    <span class="keyword">for</span> token <span class="keyword">in</span> nlp(tweet): </span><br><span class="line">        <span class="comment"># filter out the punctuation and stop words and space</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> token.is_punct <span class="keyword">and</span> <span class="keyword">not</span> token.is_stop <span class="keyword">and</span> <span class="keyword">not</span> token.is_space: </span><br><span class="line">            word = token.text </span><br><span class="line">            <span class="comment"># If the word is in the top 5000 words in the vocab, convert it to its index</span></span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">in</span> vocab:</span><br><span class="line">                indexed_words.append(vocab[word])</span><br><span class="line">            <span class="comment"># Otherwise, convert it to the index of the placeholder token</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                indexed_words.append(placeholder_index) </span><br><span class="line">    indexed_dataset.append(indexed_words)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the converted data </span></span><br><span class="line"><span class="built_in">print</span>(indexed_dataset)</span><br></pre></td></tr></table></figure><blockquote><p>Result</p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[[2013, 3615, 269, 3616, 3617, 1426, 717, 86], [1069, 339, 2014, 2015, 44, 2016], ...] </span></span><br></pre></td></tr></table></figure><p>Base on the above, we can wrap the above code into a function, which will be convenient for us to convert the sentence into an index format later during training:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># for sentence to sequence </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_sentence_sequence</span>(<span class="params">seq, to_ix</span>):</span><br><span class="line">    idx = []</span><br><span class="line">    <span class="comment"># use spacy to tokenize the sentence </span></span><br><span class="line">    <span class="keyword">for</span> token <span class="keyword">in</span> nlp(seq):</span><br><span class="line">        <span class="comment"># filter out the punctuation and stop words and space </span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> token.is_punct <span class="keyword">and</span> <span class="keyword">not</span> token.is_stop <span class="keyword">and</span> <span class="keyword">not</span> token.is_space:</span><br><span class="line">            word = token.text</span><br><span class="line">            <span class="comment"># if the token is in the top 5000 words in the vocab, add its index to the list</span></span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">in</span> to_ix:</span><br><span class="line">                idx.append(to_ix[word])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># else add the index of the placeholder token</span></span><br><span class="line">                idx.append(placeholder_index)</span><br><span class="line">    <span class="keyword">return</span> torch.tensor(idx, dtype=torch.long) <span class="comment"># list convert to tensor </span></span><br></pre></td></tr></table></figure><h2 id="將標籤轉換成-tensor">將標籤轉換成 tensor</h2><p>接下來，我們要處理標籤，標籤也需要轉換成向量，這樣 model 的 ouput 才可以與 正確解答 做比較：</p><ul><li>通常我們預期 model 的 output 會長這樣：<code>[0.1, 0.2, 0.3, 0.4]</code><ul><li>分別代表 <code>&#123;0: 'anger', 1: 'joy', 2: 'optimism', 3: 'sadness'&#125;</code>的機率</li></ul></li><li>當解答是 <code>anger</code> 時，我們希望 model 的 output 越接近 <code>[1, 0, 0, 0]</code> 越好<ul><li>也就是說，我們需要把 label 進行 one-hot-encoding 轉換成向量的形式，才可以進行比較</li><li>為了可以把「模型產生的結果」 <code>[0.1, 0.2, 0.3, 0.4]</code> 和 「正確解答」<code>[1,0,0,0]</code> 放入 loss function 中計算 loss</li><li>因此我們需要一個函式，把標籤轉換成向量的形式，這個函示就是 <code>one_hot_encode</code>。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># val is the index of the label (e.g. 2); to_ix is the dictionary of the label (e.g. &#123;0:&#x27;angry&#x27;, 1:&#x27;happy&#x27;&#125;)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">one_hot_encode</span>(<span class="params">val, to_ix</span>): </span><br><span class="line">    <span class="comment"># create an empty list to store the result</span></span><br><span class="line">    result = [] </span><br><span class="line">    <span class="comment"># iterate over the dictionary of the label</span></span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> to_ix.items(): </span><br><span class="line">        <span class="comment"># if the index of the label is the same as the index of the dictionary, we found the correct label</span></span><br><span class="line">        <span class="keyword">if</span> val == k: </span><br><span class="line">            <span class="comment"># append 1 to the list</span></span><br><span class="line">            result.append(<span class="number">1</span>)  </span><br><span class="line">        <span class="keyword">else</span>: </span><br><span class="line">            <span class="comment"># append 0 to the list if the index is not the same</span></span><br><span class="line">            result.append(<span class="number">0</span>)  </span><br><span class="line">    <span class="keyword">return</span> torch.tensor(result, dtype=torch.float32) <span class="comment"># convert list to tensor</span></span><br></pre></td></tr></table></figure><p>After the above, we can wrap the above code into a function, which will be convenient for us to convert the sentence into an index format later during training:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Because the label is a number, we need to convert it to a vector  </span></span><br><span class="line">mapping = <span class="built_in">dict</span>(<span class="built_in">zip</span>(mapping_pd[<span class="number">0</span>], mapping_pd[<span class="number">1</span>])) <span class="comment"># Return  &#123;0:&#x27;angry&#x27;, 1:&#x27;happy&#x27;, 2:&#x27;optimism&#x27;, 3:&#x27;sadness&#x27;&#125; </span></span><br><span class="line"><span class="built_in">print</span>(mapping)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;ans=2; vector=<span class="subst">&#123;one_hot_encode(<span class="number">2</span>, tag_to_ix)&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><blockquote><p>Result: We successfully converted 2 into the vector <code>[0, 0, 1, 0]</code>!</p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="number">0</span>: <span class="string">&#x27;anger&#x27;</span>, <span class="number">1</span>: <span class="string">&#x27;joy&#x27;</span>, <span class="number">2</span>: <span class="string">&#x27;optimism&#x27;</span>, <span class="number">3</span>: <span class="string">&#x27;sadness&#x27;</span>&#125;</span><br><span class="line">ans=<span class="number">2</span>; vector=tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">0.</span>])</span><br></pre></td></tr></table></figure><h1 id="Task-4-Train-the-Model-and-Calculate-Accuracy">Task 4: Train the Model and Calculate Accuracy</h1><div class="note info flat"><ol start="4"><li><strong>Train the Model and Calculate Accuracy</strong>: Evaluate the accuracy on the test set. (Note: If the training takes too long, try to use only a fraction of the training data.)</li></ol></div><h2 id="Try-Your-Hand">Try Your Hand</h2><p>Before starting to train the model, <strong>we need to first understand what our model’s input and output look like</strong>. Let’s see what the model predicts before it’s trained!</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># See what the scores are before training</span></span><br><span class="line"><span class="comment"># Here we don&#x27;t need to train, so the code is wrapped in torch.no_grad()</span></span><br><span class="line"><span class="comment"># Take the first sentence as an example </span></span><br><span class="line">sentence_idx = <span class="number">1</span></span><br><span class="line"><span class="comment"># Print out：My roommate: it&#x27;s okay that we can&#x27;t spell because we have autocorrect. #terrible #firstworldprobs </span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;First Sentense = <span class="subst">&#123;train_dataset[sentence_idx]&#125;</span>&#x27;</span>) </span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="comment"># Convert the first sentence into index format, and convert it to tensor </span></span><br><span class="line">    inputs = prepare_sentence_sequence(train_dataset[sentence_idx], word_to_ix)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Sentense to tensor = <span class="subst">&#123;inputs&#125;</span>&#x27;</span>) <span class="comment"># 印出：tensor([1070,  340, 2015, 2016,   45, 2017])</span></span><br><span class="line">    <span class="comment"># Then convert the answer to tensor </span></span><br><span class="line">    labels = one_hot_encode(train_label_pd[<span class="number">0</span>][sentence_idx], tag_to_ix)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Sentense of result to tensor = <span class="subst">&#123;labels&#125;</span>&#x27;</span>) <span class="comment"># 印出：tensor([1., 0., 0., 0.])</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Send the inputs to the model and get the model&#x27;s prediction </span></span><br><span class="line">    outputs = model(inputs)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;tag_scores = <span class="subst">&#123;outputs&#125;</span>&#x27;</span>) <span class="comment"># Print：tensor([[-1.3280, -1.4272, -1.4998, -1.3026]])</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Take the maximum probability value and take out the index </span></span><br><span class="line">    _, preds = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>) </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;preds = <span class="subst">&#123;preds&#125;</span>&#x27;</span>) <span class="comment"># Print out： preds = tensor([3])  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Take out the index of the maximum probability value </span></span><br><span class="line">    result_idx = torch.argmax(outputs).item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;result = <span class="subst">&#123;result_idx&#125;</span>, ans = <span class="subst">&#123;train_label_pd[<span class="number">0</span>][sentence_idx]&#125;</span>&#x27;</span>) <span class="comment"># 印出：result = 3, ans = 0 </span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculate loss to see the difference between output and label. Here output[0] is because we found that output has one more layer </span></span><br><span class="line">    loss = loss_function(outputs[<span class="number">0</span>], labels)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;loss = <span class="subst">&#123;loss&#125;</span>&#x27;</span>) </span><br></pre></td></tr></table></figure><blockquote><p>Result</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">First Sentense = My roommate: it<span class="string">&#x27;s okay that we can&#x27;</span>t spell because we have autocorrect. <span class="comment">#terrible #firstworldprobs </span></span><br><span class="line">Sentense to tensor = tensor([<span class="number">1070</span>,  <span class="number">340</span>, <span class="number">2015</span>, <span class="number">2016</span>,   <span class="number">45</span>, <span class="number">2017</span>])</span><br><span class="line">Sentense of result to tensor = tensor([<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>])</span><br><span class="line">tag_scores = tensor([[-<span class="number">1.3280</span>, -<span class="number">1.4272</span>, -<span class="number">1.4998</span>, -<span class="number">1.3026</span>]])</span><br><span class="line">loss = <span class="number">1.32795250415802</span></span><br><span class="line">preds = tensor([<span class="number">3</span>])</span><br><span class="line">result = <span class="number">3</span>, ans = <span class="number">0</span></span><br></pre></td></tr></table></figure><p>Looks like it’s running pretty smoothly, right?<br>Here we go!</p><h1 id="Task-4-Train-the-Model-and-Calculate-Accuracy-2">Task 4: Train the Model and Calculate Accuracy</h1><div class="note info flat"><ol start="4"><li><strong>Train the Model and Calculate Accuracy</strong>: Evaluate the accuracy on the test set. (Note: If the training takes too long, try to use only a fraction of the training data.)</li></ol></div><h2 id="Try-Your-Hand-2">Try Your Hand</h2><p>Before starting to train the model, <strong>we need to first understand what our model’s input and output look like</strong>. Let’s see what the model predicts before it’s trained!</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Epoch <span class="number">0</span>/<span class="number">29</span> </span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">1.2157</span> Acc: <span class="number">0.4642</span> Time elapsed: <span class="number">25</span> sec. </span><br><span class="line">test Loss: <span class="number">1.2095</span> Acc: <span class="number">0.4553</span> Time elapsed: <span class="number">32</span> sec. </span><br><span class="line"></span><br><span class="line">Epoch <span class="number">1</span>/<span class="number">29</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">1.1019</span> Acc: <span class="number">0.5333</span> Time elapsed: <span class="number">58</span> sec.</span><br><span class="line">test Loss: <span class="number">1.1816</span> Acc: <span class="number">0.4708</span> Time elapsed: <span class="number">65</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">2</span>/<span class="number">29</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">1.0151</span> Acc: <span class="number">0.5812</span> Time elapsed: <span class="number">92</span> sec.</span><br><span class="line">test Loss: <span class="number">1.1603</span> Acc: <span class="number">0.4898</span> Time elapsed: <span class="number">99</span> sec.</span><br><span class="line">...</span><br><span class="line">Training complete <span class="keyword">in</span> <span class="number">17</span>m <span class="number">5</span>s </span><br><span class="line">Best val Acc: <span class="number">0.599578</span> # </span><br></pre></td></tr></table></figure><div class="note info flat"><p>Does the above code look familiar? Yes, it does! If you have followed this article <a href="https://shannonhung.github.io/posts/flower102-transfer-learning.html">Flower102 Dataset - Training with Transfer Learning + Batch Normalization for CNN</a> it uses the same kind of training. , the same kind of training is used.<br>It is possible to observe both the training results and the testing results to see if there is any overfitting.<br>Even if there is overfitting, this method can still preserve the best model.</p></div><p>So let’s get started with the <code>train_model</code> function, and I’ll indicate where we need to change it by <code>!!!! </code> to indicate where we need to make changes:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">model, criterion, optimizer, scheduler, num_epochs=<span class="number">1</span></span>):</span><br><span class="line">    <span class="comment"># The time when training starts</span></span><br><span class="line">    since = time.time()</span><br><span class="line">    <span class="comment"># Create a temporary folder to store the best model</span></span><br><span class="line">    <span class="keyword">with</span> TemporaryDirectory() <span class="keyword">as</span> tempdir:</span><br><span class="line">        <span class="comment"># The path where the best model is stored</span></span><br><span class="line">        best_model_params_path = os.path.join(tempdir, <span class="string">&#x27;best_model_params.pt&#x27;</span>)</span><br><span class="line">        <span class="comment"># Initially store the best model</span></span><br><span class="line">        torch.save(model.state_dict(), best_model_params_path)</span><br><span class="line">        <span class="comment"># The current best accuracy, which will be updated if a better accuracy is found</span></span><br><span class="line">        best_acc = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Start training for n epochs</span></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;Epoch <span class="subst">&#123;epoch&#125;</span>/<span class="subst">&#123;num_epochs - <span class="number">1</span>&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Each epoch has a training and validation phase</span></span><br><span class="line">            <span class="keyword">for</span> phase <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;test&#x27;</span>]:</span><br><span class="line">                <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                    model.train()</span><br><span class="line">                <span class="keyword">else</span>: </span><br><span class="line">                    model.<span class="built_in">eval</span>()</span><br><span class="line">                </span><br><span class="line">                running_loss = <span class="number">0.0</span></span><br><span class="line">                running_corrects = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># Iterate over data.</span></span><br><span class="line">                <span class="keyword">for</span> <span class="built_in">input</span>, label <span class="keyword">in</span> <span class="built_in">zip</span>(dataloaders[phase], resultloaders[phase]):</span><br><span class="line">                    <span class="comment"># ===== !!! Here !!! ====== </span></span><br><span class="line">                    <span class="comment"># Here we will use the functions created in Task 2+3 to convert sentences to indices and labels to vectors</span></span><br><span class="line">                    <span class="comment"># e.g., tensor([1070,  340, 2015, 2016,   45, 2017])</span></span><br><span class="line">                    inputs_vector = prepare_sentence_sequence(<span class="built_in">input</span>, word_to_ix) </span><br><span class="line">                    <span class="comment"># e.g., tensor([1., 0., 0., 0.])</span></span><br><span class="line">                    labels_vector = one_hot_encode(label, tag_to_ix) </span><br><span class="line">                    <span class="comment"># ===== !!! End !!! ====== </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                    <span class="comment"># zero the parameter gradients </span></span><br><span class="line">                    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># forward</span></span><br><span class="line">                    <span class="comment"># track history if only in train</span></span><br><span class="line">                    <span class="keyword">with</span> torch.set_grad_enabled(phase == <span class="string">&#x27;train&#x27;</span>):</span><br><span class="line">                        <span class="comment"># Similar to the earlier test</span></span><br><span class="line">                        <span class="comment"># Get the predicted result tensor for each emotion</span></span><br><span class="line">                        outputs = model(inputs_vector) <span class="comment"># (e.g., tensor([[-1.3948, -1.4476, -1.3804, -1.3261]]))</span></span><br><span class="line"></span><br><span class="line">                        <span class="comment"># ===== !!! Here !!! ====== </span></span><br><span class="line">                        <span class="comment"># Get the index of the maximum value</span></span><br><span class="line">                        pred = torch.argmax(outputs).item() <span class="comment"># (e.g., 2)</span></span><br><span class="line">                        <span class="comment"># For the outer layer, only need to calculate the loss between the inner layer [-1.3948, -1.4476, -1.3804, -1.3261] and [0, 0, 1, 0]</span></span><br><span class="line">                        loss = criterion(outputs[<span class="number">0</span>], labels_vector) <span class="comment">#</span></span><br><span class="line">                        <span class="comment"># ===== !!! End !!! ====== </span></span><br><span class="line"></span><br><span class="line">                        <span class="comment"># backward + optimize only if in training phase</span></span><br><span class="line">                        <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                            loss.backward()</span><br><span class="line">                            optimizer.step()</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># statistics</span></span><br><span class="line">                    running_loss += loss.item()</span><br><span class="line">                    <span class="keyword">if</span> pred == label:</span><br><span class="line">                        running_corrects += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                    scheduler.step()</span><br><span class="line">                <span class="comment"># Calculate the loss and accuracy for each epoch</span></span><br><span class="line">                epoch_loss = running_loss / dataset_sizes[phase]</span><br><span class="line">                epoch_acc = running_corrects / dataset_sizes[phase]</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;phase&#125;</span> Loss: <span class="subst">&#123;epoch_loss:<span class="number">.4</span>f&#125;</span> Acc: <span class="subst">&#123;epoch_acc:<span class="number">.4</span>f&#125;</span> Time elapsed: <span class="subst">&#123;<span class="built_in">round</span>((time.time() - since))&#125;</span> sec.&#x27;</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># If a better accuracy is found, save the model</span></span><br><span class="line">                <span class="keyword">if</span> phase == <span class="string">&#x27;test&#x27;</span> <span class="keyword">and</span> epoch_acc &gt; best_acc:</span><br><span class="line">                    best_acc = epoch_acc</span><br><span class="line">                    torch.save(model.state_dict(), best_model_params_path)</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line">        time_elapsed = time.time() - since</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Training complete in <span class="subst">&#123;time_elapsed // <span class="number">60</span>:<span class="number">.0</span>f&#125;</span>m <span class="subst">&#123;time_elapsed % <span class="number">60</span>:<span class="number">.0</span>f&#125;</span>s&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Best val Acc: <span class="subst">&#123;best_acc:4f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Load best model weights then proceed to the next epoch</span></span><br><span class="line">        model.load_state_dict(torch.load(best_model_params_path))</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><p>You will find that there are not many places to change… at most:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">        <span class="comment"># the input and label conversion </span></span><br><span class="line">        inputs_vector = prepare_sentence_sequence(<span class="built_in">input</span>, word_to_ix) </span><br><span class="line">        labels_vector = one_hot_encode(label, tag_to_ix) </span><br><span class="line">        ...</span><br><span class="line">        <span class="comment"># Then get the prediction result tensor for each emotion </span></span><br><span class="line">        pred = torch.argmax(outputs).item()</span><br><span class="line">        <span class="comment"># Calculate the loss </span></span><br><span class="line">        loss = criterion(outputs[<span class="number">0</span>], labels_vector)</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>Now we can start training the model!</p><h2 id="Training">Training</h2><p>Let’s first prepare the dataset for training:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Before we do that, let&#x27;s prepare the dataset for the model to use </span></span><br><span class="line">dataloaders = &#123;<span class="string">&#x27;train&#x27;</span>: train_dataset, <span class="string">&#x27;test&#x27;</span>: test_dataset&#125;</span><br><span class="line">resultloaders = &#123;<span class="string">&#x27;train&#x27;</span>: train_label_pd[<span class="number">0</span>].tolist(), <span class="string">&#x27;test&#x27;</span>: test_label_pd[<span class="number">0</span>].tolist()&#125;</span><br><span class="line">dataset_sizes = &#123;x: <span class="built_in">len</span>(dataloaders[x]) <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;test&#x27;</span>]&#125;</span><br></pre></td></tr></table></figure><p>Firstly, let’s build the LSTM model!</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Build the model </span></span><br><span class="line"><span class="comment"># vocab_size need to add 1 because if there are words in the sentence that are not in the vocab, use 5000 to replace them, so you need to add 1 </span></span><br><span class="line">model_LSTM = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, <span class="built_in">len</span>(word_to_ix)+<span class="number">1</span>, <span class="built_in">len</span>(tag_to_ix), dropout=<span class="number">0.5</span>)</span><br><span class="line">loss_function_LSTM = nn.CrossEntropyLoss()</span><br><span class="line">optimizer_LSTM = optim.SGD(model_LSTM.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">exp_lr_scheduler_LSTM = lr_scheduler.StepLR(optimizer_LSTM, step_size=<span class="number">7</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start training </span></span><br><span class="line">modelLSTM = train_model(model_LSTM, loss_function_LSTM, optimizer_LSTM, exp_lr_scheduler_LSTM, num_epochs=<span class="number">30</span>)</span><br></pre></td></tr></table></figure><blockquote><p>Result</p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Epoch <span class="number">2</span>/<span class="number">29</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">0.9885</span> Acc: <span class="number">0.5840</span> Time elapsed: <span class="number">97</span> sec.</span><br><span class="line">test Loss: <span class="number">1.1279</span> Acc: <span class="number">0.5236</span> Time elapsed: <span class="number">104</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">3</span>/<span class="number">29</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">0.8893</span> Acc: <span class="number">0.6371</span> Time elapsed: <span class="number">132</span> sec.</span><br><span class="line">test Loss: <span class="number">1.1053</span> Acc: <span class="number">0.5369</span> Time elapsed: <span class="number">139</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">4</span>/<span class="number">29</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">0.7683</span> Acc: <span class="number">0.7003</span> Time elapsed: <span class="number">168</span> sec.</span><br><span class="line">test Loss: <span class="number">1.0772</span> Acc: <span class="number">0.5658</span> Time elapsed: <span class="number">175</span> sec.</span><br><span class="line">...</span><br><span class="line">test Loss: <span class="number">1.1330</span> Acc: <span class="number">0.6059</span> Time elapsed: <span class="number">1040</span> sec.</span><br><span class="line"></span><br><span class="line">Training complete <span class="keyword">in</span> <span class="number">17</span>m <span class="number">20</span>s</span><br><span class="line">Best val Acc: <span class="number">0.610134</span></span><br></pre></td></tr></table></figure><p>Then let’s build the GRU model!</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vocab_size need to add 1 because if there are words in the sentence that are not in the vocab, use 5000 to replace them, so you need to add 1 </span></span><br><span class="line">modelGRU = GRUTagger(EMBEDDING_DIM, HIDDEN_DIM, <span class="built_in">len</span>(word_to_ix)+<span class="number">1</span>, <span class="built_in">len</span>(tag_to_ix), dropout=<span class="number">0.5</span>)</span><br><span class="line">loss_function_gru = nn.CrossEntropyLoss()</span><br><span class="line">optimizer_gru = optim.SGD(modelGRU.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">exp_lr_scheduler_gru = lr_scheduler.StepLR(optimizer_gru, step_size=<span class="number">7</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start training </span></span><br><span class="line">modelGRU = train_model(modelGRU, loss_function_gru, optimizer_gru, exp_lr_scheduler_gru, num_epochs=<span class="number">30</span>)</span><br></pre></td></tr></table></figure><blockquote><p>Result</p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Epoch <span class="number">3</span>/<span class="number">29</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">0.8445</span> Acc: <span class="number">0.6702</span> Time elapsed: <span class="number">131</span> sec.</span><br><span class="line">test Loss: <span class="number">1.1211</span> Acc: <span class="number">0.5327</span> Time elapsed: <span class="number">138</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">4</span>/<span class="number">29</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">0.6843</span> Acc: <span class="number">0.7393</span> Time elapsed: <span class="number">166</span> sec.</span><br><span class="line">test Loss: <span class="number">1.1305</span> Acc: <span class="number">0.5707</span> Time elapsed: <span class="number">173</span> sec.</span><br><span class="line">...</span><br><span class="line">test Loss: <span class="number">1.3237</span> Acc: <span class="number">0.6073</span> Time elapsed: <span class="number">1003</span> sec.</span><br><span class="line"></span><br><span class="line">Training complete <span class="keyword">in</span> <span class="number">16</span>m <span class="number">43</span>s</span><br><span class="line">Best val Acc: <span class="number">0.608726</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Code </category>
          
          <category> Mechine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mechine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>COCO Dataset - use Faster RCNN + MobileNet to conduct Object Detection</title>
      <link href="/en/posts/coco-object-diagnoise/"/>
      <url>/en/posts/coco-object-diagnoise/</url>
      
        <content type="html"><![CDATA[<h1 id="Introduction">Introduction</h1><p>Recently I took an AI course, the main content is the following topics:</p><ol><li>Learn about Coco dataset</li><li>User pre-trained version of Faster R-CNN to predict the bounding box</li><li>Calculate IoU</li></ol><h1 id="Homework-Requirement">Homework Requirement</h1><ol><li><strong>Download the Coco Collection</strong>*: download the files “2017 Val images [5/1GB]” and “2017 Train/Val annotations [241MB]” from the Coco page.<br>Download from Coco page. You can load them into your notebook using the pycocotools library.</li><li><strong>Randomly select ten from the dataset</strong>: 10 images are randomly selected from this dataset.</li><li><strong>Predict the box using the pre-trained model FasterR-CNN</strong>: use a pre-trained version of the Faster R-CNN (Resnet50 backbone) to predict the bounding box of the object on the 10 images. of the bounding box. Only regions with scores greater than 0.8 are retained.</li><li><strong>isualize the model together with the answer visualization</strong>*: Visualize the predicted bounding boxes and label together with the ground truth bounding<br>boxes and label. Show all 10 pairs of images side by side in the jupyter notebook.</li><li><strong>Use another pre-trained model Mobilnet</strong>: Repeat the above steps using the Mobilenet backbone of the Faster R-CNN.</li><li><strong>Calculate IoU Compare Models</strong>: Which backbone provides better results? Calculate the IoU for both methods.</li></ol><h1 id="Task-1-Downloading-the-COCO-Dataset">Task 1: Downloading the COCO Dataset</h1><div class="note info flat"><p><strong>Task 1</strong></p><ol><li><strong>Download the COCO Dataset</strong>: Obtain the files “2017 Val images [5/1GB]” and “2017 Train/Val annotations [241MB]” from the Coco page. Utilize the pycocotools library to import them into your notebook.</li></ol></div><p>You can follow this guide to proceed with the download: <a href="https://jason-chen-1992.weebly.com/home/coco-dataset">Download COCO Dataset</a><br><img src="https://i.imgur.com/BieHtLG.png" alt=""></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── annotations <span class="comment"># These are annotation files</span></span><br><span class="line">│   ├── captions_train2017.json</span><br><span class="line">│   ├── captions_val2017.json</span><br><span class="line">│   ├── instances_train2017.json</span><br><span class="line">│   ├── instances_val2017.json</span><br><span class="line">│   ├── person_keypoints_train2017.json</span><br><span class="line">│   └── person_keypoints_val2017.json</span><br><span class="line">└── val2017 <span class="comment"># This is the image set </span></span><br><span class="line">    ├── 000000000139.jpg</span><br><span class="line">    ├── 000000000285.jpg</span><br><span class="line">    ├── 000000000632.jpg</span><br><span class="line">    ├── 000000000724.jpg</span><br><span class="line">    ├── 000000000776.jpg</span><br><span class="line">    ├── 000000000785.jpg</span><br><span class="line">    ├── 000000000802.jpg</span><br><span class="line">    ... </span><br></pre></td></tr></table></figure><ul><li>Download these two files as shown in the image.</li><li>After downloading, the folder structure upon extraction will resemble the one above.</li></ul><h1 id="Task-2-Randomly-Select-Ten-Images">Task 2: Randomly Select Ten Images</h1><div class="note info flat"><p><strong>Task 2</strong><br>2. <strong>Randomly Select Ten Images from the Dataset</strong>: Pick 10 images randomly from this dataset.</p></div><p>Here, we’ll primarily do a few things:</p><ul><li>Import necessary libraries.</li><li>Set up the COCO API to allow it to access relevant information from our dataset, such as bounding box positions, label locations, and image information.</li><li>Visualize images and perform annotations.</li><li>Randomly select ten images.</li></ul><p>Let’s begin by importing the necessary libraries.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># CNN </span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> lr_scheduler</span><br><span class="line"><span class="keyword">import</span> torch.backends.cudnn <span class="keyword">as</span> cudnn</span><br><span class="line"></span><br><span class="line"><span class="comment"># others</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> tempfile <span class="keyword">import</span> TemporaryDirectory</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment"># torchvision</span></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="comment"># dataset </span></span><br><span class="line"><span class="keyword">from</span> pycocotools.coco <span class="keyword">import</span> COCO</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cudnn.benchmark = <span class="literal">True</span></span><br><span class="line">plt.ion()   <span class="comment"># interactive mode</span></span><br></pre></td></tr></table></figure><h2 id="Setting-up-the-COCO-API">Setting up the COCO API</h2><p>COCO provides an API to access datasets. By providing it with a JSON file, we can easily retrieve the necessary information such as images, labels, bounding boxes, and more.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Specify dataset location</span></span><br><span class="line">cocoRoot = <span class="string">&quot;../../Data/Coco/&quot;</span></span><br><span class="line">dataType = <span class="string">&quot;val2017&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set annotation file location</span></span><br><span class="line">annFile = os.path.join(cocoRoot, <span class="string">f&#x27;annotations/instances_<span class="subst">&#123;dataType&#125;</span>.json&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Annotation file: <span class="subst">&#123;annFile&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="comment"># # initialize COCO api for instance annotations</span></span><br><span class="line">coco=COCO(annFile)</span><br><span class="line">coco </span><br></pre></td></tr></table></figure><blockquote><p>Result</p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Annotation file: ../../Data/Coco/annotations/instances_val2017.json</span><br><span class="line"><span class="comment">-- Indicates successful annotation file read</span></span><br><span class="line">loading annotations into memory...</span><br><span class="line">Done (t=<span class="number">0.35</span>s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br></pre></td></tr></table></figure><h2 id="Annotation-Visualization">Annotation Visualization</h2><p>To ensure familiarity with the COCO-provided API, here’s an exercise focusing on the following:</p><ul><li>Obtaining image info by ID</li><li>Retrieving annotation info by ID</li><li>Learning to draw bounding boxes and labels on images</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.patches <span class="keyword">import</span> Rectangle</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a function that, given an image ID, plots the image with bounding boxes and labels</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_image_with_annotations</span>(<span class="params">coco, cocoRoot, dataType, imgId, ax=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># Get image information</span></span><br><span class="line">    imgInfo = coco.loadImgs(imgId)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># Get image location for visualization</span></span><br><span class="line">    imPath = os.path.join(cocoRoot, dataType, imgInfo[<span class="string">&#x27;file_name&#x27;</span>])    </span><br><span class="line">    <span class="comment"># Read the image</span></span><br><span class="line">    im = cv2.imread(imPath)</span><br><span class="line">    <span class="comment"># Convert color space: OpenCV defaults to BGR, but matplotlib to RGB, so conversion is needed</span></span><br><span class="line">    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Find all annotations (bounding boxes) for the image</span></span><br><span class="line">    annIds = coco.getAnnIds(imgIds=imgInfo[<span class="string">&#x27;id&#x27;</span>])</span><br><span class="line">    <span class="comment"># Load all annotation information: bounding box coordinates, labels, accuracies</span></span><br><span class="line">    anns = coco.loadAnns(annIds)</span><br><span class="line">    all_labels = <span class="built_in">set</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Extract bounding box coordinates, labels, accuracies</span></span><br><span class="line">    <span class="keyword">for</span> ann <span class="keyword">in</span> anns:</span><br><span class="line">        <span class="comment"># Specifically select information related to the bounding box: returns (x, y) of the lower-left corner, width, height</span></span><br><span class="line">        x, y, w, h = ann[<span class="string">&#x27;bbox&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Get label text information: load category name by category ID</span></span><br><span class="line">        label = coco.loadCats(ann[<span class="string">&#x27;category_id&#x27;</span>])[<span class="number">0</span>][<span class="string">&quot;name&quot;</span>]</span><br><span class="line">        all_labels.add(label)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Draw bounding boxes using provided coordinates</span></span><br><span class="line">        rect = Rectangle((x, y), w, h, linewidth=<span class="number">2</span>, edgecolor=<span class="string">&#x27;r&#x27;</span>, facecolor=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># Draw the image: if sorting of images is needed, ax parameter specifies the position</span></span><br><span class="line">        <span class="keyword">if</span> ax <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            plt.gca().add_patch(rect) </span><br><span class="line">            plt.text(x, y, <span class="string">f&#x27;<span class="subst">&#123;label&#125;</span>&#x27;</span>, fontsize=<span class="number">10</span>, color=<span class="string">&#x27;w&#x27;</span>, backgroundcolor=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            ax.add_patch(rect)</span><br><span class="line">            ax.text(x, y, <span class="string">f&#x27;<span class="subst">&#123;label&#125;</span>&#x27;</span>, fontsize=<span class="number">10</span>, color=<span class="string">&#x27;w&#x27;</span>, backgroundcolor=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Display the image with a title</span></span><br><span class="line">    <span class="keyword">if</span> ax <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        plt.imshow(im)</span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">f&#x27;Annotations: <span class="subst">&#123;all_labels&#125;</span>&#x27;</span>, color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ax.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        ax.set_title(<span class="string">f&#x27;Annotations: <span class="subst">&#123;all_labels&#125;</span>&#x27;</span>, color=<span class="string">&#x27;r&#x27;</span>, loc=<span class="string">&#x27;center&#x27;</span>, pad=<span class="number">20</span>)</span><br><span class="line">        ax.imshow(im)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the tenth image</span></span><br><span class="line">imgIds = coco.getImgIds()</span><br><span class="line">imgId = imgIds[<span class="number">10</span>]</span><br><span class="line"><span class="comment"># Plot the image with annotations</span></span><br><span class="line">plot_image_with_annotations(coco, cocoRoot, dataType, imgId)</span><br></pre></td></tr></table></figure><blockquote><p>Result</p></blockquote><p><img src="https://i.imgur.com/C0nZWY9.png" alt=""></p><h2 id="Randomly-Select-Ten-Images">Randomly Select Ten Images</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">random_select</span>(<span class="params">coco, cocoRoot, dataType, num_images=<span class="number">10</span></span>):</span><br><span class="line">    <span class="comment"># Get IDs for all images</span></span><br><span class="line">    imgIds = coco.getImgIds()</span><br><span class="line">    <span class="comment"># Randomly select num_images IDs from this set</span></span><br><span class="line">    selected_imgIds = random.sample(imgIds, num_images)</span><br><span class="line">    <span class="comment"># Call the plot_image_with_annotations function for each selected ID</span></span><br><span class="line">    <span class="keyword">for</span> imgId <span class="keyword">in</span> selected_imgIds:</span><br><span class="line">        <span class="comment"># Plot images based on their IDs</span></span><br><span class="line">        plot_image_with_annotations(coco, cocoRoot, dataType, imgId)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Print out all selected IDs</span></span><br><span class="line">    <span class="keyword">return</span> selected_imgIds</span><br><span class="line">    </span><br><span class="line">valid_ids = random_select(coco, cocoRoot, dataType, num_images=<span class="number">10</span>)</span><br><span class="line">valid_ids</span><br></pre></td></tr></table></figure><blockquote><p>Result</p></blockquote><p><img src="https://i.imgur.com/TUiI82h.png" alt=""></p><h1 id="Task-3-5-FasterR-CNN-v-s-Mobilnet">Task 3+5: FasterR-CNN v.s Mobilnet</h1><div class="note info flat"><p><strong>Task 3 &amp; 5</strong><br>3. <strong>Predicting bboxes using the pre-trained model FasterR-CNN</strong>：Use a pre-trained version of Faster R-CNN (Resnet50 backbone) to predict the bounding box<br>of objects on the 10 images. Only keep regions that have a score &gt; 0.8.<br>5. <strong>Using another pre-trained model Mobilnet</strong>：Repeat the steps from above using a Mobilenet backbone for the Faster R-CNN.</p></div><h2 id="Using-pre-train-model">Using pre-train model</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># using pre-train model (FasterR-CNN)</span></span><br><span class="line">model_res = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=<span class="string">&quot;FasterRCNN_ResNet50_FPN_Weights.DEFAULT&quot;</span>)</span><br><span class="line">model_res.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># using pre-train model  (Mobilenet)</span></span><br><span class="line">model_mobile = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(weights=torchvision.models.detection.FasterRCNN_MobileNet_V3_Large_FPN_Weights)</span><br><span class="line">model_mobile.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure><h2 id="Convert-image-to-tensor">Convert image to tensor</h2><p>We need to be able to take the image out of the picture based on the position of the image. Then we need to convert the image read from the book into a tensor before we can put it into the model for prediction. So we made two functions:</p><ul><li>One is to read the picture</li><li>One is to convert the picture to a tensor.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_image</span>(<span class="params">imgIdx</span>):</span><br><span class="line">    <span class="comment"># Get image information</span></span><br><span class="line">    imgInfo = coco.loadImgs(imgIdx)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># Get image location for visualization</span></span><br><span class="line">    imPath = os.path.join(cocoRoot, dataType, imgInfo[<span class="string">&#x27;file_name&#x27;</span>])    </span><br><span class="line">    <span class="comment"># Read the image path </span></span><br><span class="line">    <span class="built_in">print</span>(imPath)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># Read the image </span></span><br><span class="line">        <span class="keyword">return</span> Image.<span class="built_in">open</span>(imPath)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert the picture to a tensor </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pil2tensor</span>(<span class="params">pil_image</span>):</span><br><span class="line">    <span class="comment"># Use unsqueeze(0) because the model still contains the batch size dimension, a total of four dimensions (batch_size, channel-RGB, height, width)</span></span><br><span class="line">    <span class="comment"># But the picture has only one picture without batch size, the picture is converted to tensor will only have three dimensions (channel-RGB, height, width), so we need to add a dimensions </span></span><br><span class="line">    <span class="comment"># /255 is because the input of the model is a number between 0 and 1, and the value of the picture is 0~255, so it needs to be divided by 255 for normalization </span></span><br><span class="line">    <span class="keyword">return</span> torchvision.transforms.PILToTensor()(pil_image).unsqueeze(<span class="number">0</span>) / <span class="number">255.0</span></span><br></pre></td></tr></table></figure><h2 id="Training-the-model">Training the model</h2><p>After the pre-training model is loaded, we need to train the model. The training process is as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Save the prediction result </span></span><br><span class="line">predictions_res = []</span><br><span class="line">predictions_mobile = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># Recursively call each id, these ids are the 10 ids we randomly selected above</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> valid_ids:</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br><span class="line">    <span class="comment"># transform to tensor from PIL image</span></span><br><span class="line">    img_as_tensor = pil2tensor(load_image(i))</span><br><span class="line">    <span class="comment"># put the tensor to resnet model</span></span><br><span class="line">    prediction = model_res(img_as_tensor)</span><br><span class="line">    <span class="comment"># Save the prediction result: the prediction result is a dictionary, which contains the predicted bounding box, label, and accuracy </span></span><br><span class="line">    predictions_res.append(prediction)</span><br><span class="line">    <span class="comment"># put the tensor to mobilenet model</span></span><br><span class="line">    prediction = model_mobile(img_as_tensor)</span><br><span class="line">    <span class="comment"># Save the prediction result: the prediction result is a dictionary, which contains the predicted bounding box, label, and accuracy</span></span><br><span class="line">    predictions_mobile.append(prediction)</span><br></pre></td></tr></table></figure><h2 id="Only-select-the-prediction-results-0-8">Only select the prediction results &gt; 0.8</h2><p>After the model is trained, we need to select the prediction results that are greater than 0.8. The reason is that the model will predict a lot of bounding boxes, but we only need the bounding boxes with high accuracy. So we need to filter out the bounding boxes with low accuracy. The code is as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">filter_valid_boxes</span>(<span class="params">predictions, threshold=<span class="number">0.8</span></span>):</span><br><span class="line">    <span class="comment"># Used to store the filtered prediction results </span></span><br><span class="line">    valid_boxes_list = []</span><br><span class="line">    <span class="comment"># Recursively call each prediction result </span></span><br><span class="line">    <span class="keyword">for</span> prediction <span class="keyword">in</span> predictions:</span><br><span class="line">        valid_boxes_for_this_prediction = []</span><br><span class="line">        <span class="comment"># Recursively call each bounding box </span></span><br><span class="line">        <span class="keyword">for</span> box, label, score <span class="keyword">in</span> <span class="built_in">zip</span>(prediction[<span class="number">0</span>][<span class="string">&quot;boxes&quot;</span>], prediction[<span class="number">0</span>][<span class="string">&quot;labels&quot;</span>], prediction[<span class="number">0</span>][<span class="string">&quot;scores&quot;</span>]):</span><br><span class="line">            <span class="comment"># Only keep the predicted bounding box with accuracy greater than threshold </span></span><br><span class="line">            <span class="keyword">if</span> score &gt;= threshold: </span><br><span class="line">                <span class="comment"># Save the predicted bounding box, label, and accuracy </span></span><br><span class="line">                valid_boxes_for_this_prediction.append((box, label, score))</span><br><span class="line">        <span class="comment"># If none of the predicted boxes in this picture have an accuracy greater than threshold, store an empty list </span></span><br><span class="line">        valid_boxes_list.append(valid_boxes_for_this_prediction)</span><br><span class="line">    <span class="comment"># Return the filtered prediction result </span></span><br><span class="line">    <span class="keyword">return</span> valid_boxes_list</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set threshold to 0.8 and get the prediction results of resnet and mobilenet </span></span><br><span class="line">valid_boxes_res = filter_valid_boxes(predictions_res, threshold=<span class="number">0.8</span>)</span><br><span class="line">valid_boxes_mobile = filter_valid_boxes(predictions_mobile, threshold=<span class="number">0.8</span>)</span><br></pre></td></tr></table></figure><h1 id="Task-4-6-Visualization-IoU">Task 4+6: Visualization + IoU</h1><div class="note info flat"><p><strong>Tasks 4 &amp; 6</strong></p><ol><li><strong>Visualize the model together with the solution</strong>: Visualize the predicted bounding boxes and label together with the ground truth bounding</li><li><strong>CalculateIoU to compare models</strong>: Which backbone delivers the better results? Calculate the IoU for both approaches.</li></ol></div><p>There are a few important points in visual dialog, the steps are as follows:</p><ul><li>We need to know the id of the image first, and get the annotation information based on the id, then we can Calculate the IoU.</li><li>We take the annotation information and the model information to conduct the IoU Calculate.</li><li>We read the location of the image in the computer, and according to the path of the image, we draw the image through plt first.</li><li>We read the location of the picture in the computer, and based on the path of the picture, we draw the picture through plt first, and then based on the picture, we can draw the prediction box and label on it, as well as the average value of the IoU.</li></ul><p>The following program is the procedure described above, we will draw the results of both models and calculate the average of the IoU.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Can put the results of different models into this function, and it will return the average value of IoU </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">display_annotated_results</span>(<span class="params">imgId, valid_boxes, model_name, color=<span class="string">&#x27;g&#x27;</span>, ax=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># Load the image</span></span><br><span class="line">    imgInfo = coco.loadImgs(imgId)[<span class="number">0</span>]</span><br><span class="line">    image_path = os.path.join(cocoRoot, dataType, imgInfo[<span class="string">&#x27;file_name&#x27;</span>])</span><br><span class="line">    image = Image.<span class="built_in">open</span>(image_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get the correct bounding box results </span></span><br><span class="line">    annIds = coco.getAnnIds(imgIds=imgInfo[<span class="string">&#x27;id&#x27;</span>])</span><br><span class="line">    anns = coco.loadAnns(annIds)</span><br><span class="line">    bbox_tlist_anns = torch.tensor([ann[<span class="string">&quot;bbox&quot;</span>] <span class="keyword">for</span> ann <span class="keyword">in</span> anns]) <span class="comment"># tensor.shape[2,4]</span></span><br><span class="line">    <span class="comment"># because our bounding box is x,y,w,h which is the coordinate of the lower left corner of the box (x,y) + the length and width of the box </span></span><br><span class="line">    <span class="comment"># But torchvision Calculate the box_iou must give the coordinates of the lower left corner (x,y) and the coordinates of the upper right corner (x2,y2), so we need to Calculate (x2,y2) through (x+w, y+h) to get the coordinates of the upper right corner </span></span><br><span class="line">    <span class="comment"># x,y,w,h -&gt; x1,y1,x2,y2 = x,y,x+w,y+h </span></span><br><span class="line">    bbox_tlist_anns[:, <span class="number">2</span>] = bbox_tlist_anns[:, <span class="number">0</span>] + bbox_tlist_anns[:, <span class="number">2</span>]</span><br><span class="line">    bbox_tlist_anns[:, <span class="number">3</span>] = bbox_tlist_anns[:, <span class="number">1</span>] + bbox_tlist_anns[:, <span class="number">3</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># From resultsvalid_boxes, we only need the box part, so we use (box, _, _)  </span></span><br><span class="line">    <span class="comment"># Use stack because we want to stack all the boxes together to become a tensor </span></span><br><span class="line">    bbox_tlist_model = torch.stack([box <span class="keyword">for</span> box, _, _ <span class="keyword">in</span> valid_boxes]) <span class="comment"># turn [4] to tensor.shape[2,4]</span></span><br><span class="line">    <span class="comment"># use box_iou 來Calculate IoU </span></span><br><span class="line">    iou = torchvision.ops.box_iou(bbox_tlist_anns, bbox_tlist_model) <span class="comment"># get IoU </span></span><br><span class="line">    <span class="comment"># Get the maximum value of each predicted box in ann, and then Calculate the average value of IoU </span></span><br><span class="line">    avg_iou = np.mean([t.cpu().detach().numpy().<span class="built_in">max</span>() <span class="keyword">for</span> t <span class="keyword">in</span> iou]) <span class="comment"># calculate the mean of IoU</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># display image label </span></span><br><span class="line">    all_labels = <span class="built_in">set</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Start drawing the prediction box </span></span><br><span class="line">    <span class="keyword">for</span> boxes <span class="keyword">in</span> valid_boxes:</span><br><span class="line">        <span class="comment"># Get the information of the prediction box, including box, label, and accuracy </span></span><br><span class="line">        box, label, score = boxes</span><br><span class="line">        <span class="comment"># Get the text information of the label: load category name by category ID</span></span><br><span class="line">        label = coco.loadCats(label.item())[<span class="number">0</span>][<span class="string">&quot;name&quot;</span>]</span><br><span class="line">        <span class="comment"># Save the label for later display </span></span><br><span class="line">        all_labels.add(label)</span><br><span class="line">        <span class="comment"># Because the results returned by the model are two coordinates, the lower left corner and the upper right corner, so we need to convert them into x,y,w,h form and put them into Rectangle </span></span><br><span class="line">        x, y, x2, y2 = box.detach().numpy() <span class="comment"># x,y,w,h -&gt; x,y,x2-x,y2-y</span></span><br><span class="line">        rect = Rectangle((x, y), x2 - x, y2 - y, linewidth=<span class="number">2</span>, edgecolor=color, facecolor=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Draw the picture: if you need to sort the picture, you can specify where to draw the picture through ax </span></span><br><span class="line">        <span class="keyword">if</span> ax <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># gca can get the current axes, if not, it will automatically create one, and then draw the prediction box through add_patch </span></span><br><span class="line">            plt.gca().add_patch(rect) </span><br><span class="line">            <span class="comment"># Draw the label on the prediction box </span></span><br><span class="line">            plt.text(x, y, <span class="string">f&#x27;<span class="subst">&#123;label&#125;</span>&#x27;</span>, fontsize=<span class="number">10</span>, color=<span class="string">&#x27;w&#x27;</span>, backgroundcolor=color)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># add_patch can add a patch to the current axes, and then draw the prediction box on the ax </span></span><br><span class="line">            ax.add_patch(rect)</span><br><span class="line">            <span class="comment"># Draw the label on the prediction box </span></span><br><span class="line">            ax.text(x, y, <span class="string">f&#x27;<span class="subst">&#123;label&#125;</span>&#x27;</span>, fontsize=<span class="number">10</span>, color=<span class="string">&#x27;w&#x27;</span>, backgroundcolor=color)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># display image and give it a title, the title is the label that appears in this picture, and the average value of IoU </span></span><br><span class="line">    <span class="keyword">if</span> ax <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">f&#x27;<span class="subst">&#123;model_name&#125;</span>: <span class="subst">&#123;all_labels&#125;</span> \n IoU: <span class="subst">&#123;avg_iou:<span class="number">.4</span>f&#125;</span>&#x27;</span>, color=color)</span><br><span class="line">        plt.imshow(image)</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ax.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        ax.set_title(<span class="string">f&#x27;<span class="subst">&#123;model_name&#125;</span>: <span class="subst">&#123;all_labels&#125;</span> \n I0U: <span class="subst">&#123;avg_iou:<span class="number">.4</span>f&#125;</span>&#x27;</span>, color=color)</span><br><span class="line">        ax.imshow(image)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> avg_iou</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">res_iou = []</span><br><span class="line">mobile_iou = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># Recursively call each id, where id is one of the 10 random ids we selected above</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(valid_ids)):</span><br><span class="line">    <span class="comment"># Create a 1x3 grid of images, each image sized 15x5</span></span><br><span class="line">    fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize=(<span class="number">15</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Draw the truth image and display it in the center</span></span><br><span class="line">    plot_image_with_annotations(coco, cocoRoot, dataType, valid_ids[i], ax=axs[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Draw the predicted results from two different models on the left and right sides respectively, and return the IoU</span></span><br><span class="line">    i_mobil_iou = display_annotated_results(valid_ids[i], valid_boxes_mobile[i], <span class="string">&quot;mobile&quot;</span>, color=<span class="string">&#x27;g&#x27;</span>, ax=axs[<span class="number">0</span>])</span><br><span class="line">    i_res_iou = display_annotated_results(valid_ids[i], valid_boxes_res[i], <span class="string">&quot;ResNet&quot;</span>, color=<span class="string">&#x27;b&#x27;</span>, ax=axs[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Store the IoU of each image to assess the overall performance of the model</span></span><br><span class="line">    mobile_iou.append(i_mobil_iou)</span><br><span class="line">    res_iou.append(i_res_iou)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Organize the layout</span></span><br><span class="line">    plt.tight_layout()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the mean of the IoU list</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;ResNet: Avg.&quot;</span>, np.mean(res_iou), <span class="string">&quot;; each IoU:&quot;</span>, res_iou)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MobileNet: Avg.&quot;</span>, np.mean(mobile_iou), <span class="string">&quot;; each IoU:&quot;</span>, mobile_iou)</span><br></pre></td></tr></table></figure><blockquote><p>Result</p></blockquote><p><img src="https://i.imgur.com/LjCVWdY.png" alt=""></p><h1 id="Supplement-IoU">Supplement: IoU</h1><ul><li>Ref: <a href="https://blog.csdn.net/IAMoldpan/article/details/78799857">https://blog.csdn.net/IAMoldpan/article/details/78799857</a></li><li>Ref: <a href="https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/">https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/</a></li></ul><div class="note info flat"><p>IoU (Intersection over Union) is a metric used to evaluate object detection algorithms. It is defined as the <code>intersection area</code> of the <code>predicted box</code> and the <code>true box</code> divided by their <code>union area</code>. The value ranges between 0 and 1, where a higher value indicates a greater overlap between the predicted and true boxes, signifying more accurate predictions.</p></div><p><img src="https://i.imgur.com/VzMudvr.png" alt=""><br><img src="https://i.imgur.com/OKroIoL.png" alt=""><br>Source: <a href="https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/">https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/</a></p><div class="note info flat"><p><strong>From the example above, you might be wondering, what exactly does the following code segment do?</strong></p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torchvision.ops.box_iou(bbox_tlist_anns, bbox_tlist_model) </span><br></pre></td></tr></table></figure><ul><li>Essentially, it calculates the Intersection over Union (IoU) between all predicted bounding boxes of the ground truth and all predicted bounding boxes of the model. This process returns a tensor with the shape (number of ground truth bounding boxes, number of model’s predicted bounding boxes). Refer to the images below.<br><img src="https://i.imgur.com/kQ6IVMY.png" alt=""><br><img src="https://i.imgur.com/lnjmgeD.png" alt=""></li></ul><p><strong>Here, we only need to obtain the maximum IoU for each ground truth bounding box and calculate the average value, so we use the following code</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># After obtaining the maximum value for each predicted box of the annotation (see supplementary IoU for details), calculate the average IoU</span></span><br><span class="line">avg_iou = np.mean([t.cpu().detach().numpy().<span class="built_in">max</span>() <span class="keyword">for</span> t <span class="keyword">in</span> iou]) <span class="comment"># calculate the mean of IoU</span></span><br></pre></td></tr></table></figure><div class="note warning flat"><p>You might be curious whether using functions like <code>max()</code>, <code>mean()</code>, <code>sum()</code> will affect our results?</p></div><p><img src="https://i.imgur.com/lnQtu1r.png" alt=""><br><strong>As we can see from the above image</strong></p><ul><li>Using <code>sum()</code>, you may find that the value can exceed 1, which is not a reasonable range for IoU values.</li><li>Using <code>max()</code>, it chooses, for each ground truth bounding box, the closest predicted bounding box from the model as its IoU. Then, we can obtain the maximum IoU values for <code>all predicted bounding boxes</code> of the ground truth and calculate the average to determine the overall IoU.</li><li>Using <code>mean()</code> poses a problem as the IoU calculation will never be 1. This is because it considers the IoUs of other bounding boxes, which lowers the overall IoU. For instance, if the ground truth has two bounding boxes <code>[A1,A2]</code>, and the model also predicts two <code>[B1,B2]</code>, it’s clear that B1 predicts A1, and B2 predicts A2, and the model predicts accurately. However, using mean will incorrectly consider B1 as A2 and B2 as A1, which is wrong, and these pairs have low IoUs. Thus, using <code>mean()</code> in this way will unjustly lower the IoU, making it unreasonable.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Code </category>
          
          <category> Mechine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mechine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flower102 Dataset - Using Transfer Learning to train + Using Batch Normalization in CNN</title>
      <link href="/en/posts/flower102-transfer-learning/"/>
      <url>/en/posts/flower102-transfer-learning/</url>
      
        <content type="html"><![CDATA[<h1 id="Preface">Preface</h1><p>I recently took an ai course, this is the fourth assignment and the main topics taught are the following.</p><ol><li>selecting a dataset and training a model on it.</li><li>migration learning - fine tuning.</li><li>batch normalization in CNN.</li></ol><p>The main references are the following websites: 1.</p><ol><li><a href="https://pytorch.org/vision/stable/generated/torchvision.datasets.Flowers102.html#torchvision.datasets.Flowers102">Flower102 dataset</a></li><li><a href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html">Migration Learning</a></li><li><a href="https://pytorch.org/vision/stable/datasets.html">Pytorch dataset</a></li><li><a href="https://pytorch.org/vision/stable/models.html">Migration Learning Model</a></li><li><a href="/posts/ML.html#Transfer-Learning">Shannon’s Transfer Learning Blog</a></li><li><a href="https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet18.html#torchvision.models.resnet18">Resnet18</a></li></ol><h1 id="Assignment-Requirements">Assignment Requirements</h1><p>Tasks</p><ol><li><strong>Choose a dataset</strong>*: Look at torchvision <a href="https://pytorch.org/vision/stable/datasets.html">Pytorch’s dataset</a> and decide which dataset you want to use (excluding<br>CIFAR, ImageNet, FashionMNIST).</li><li><strong>Print images and profile sizes</strong>: show some sample images of the dataset in your notebook and print the size of the dataset.</li><li><strong>Construct a CNN using batch normalization</strong>: design a CNN to make predictions on the dataset. Use a similar architecture as last time, but this time<br>also includes a batch normalization layer.</li><li><strong>Train a model using a dataset and print out the accuracy of the test</strong>: train a model on a dataset and measure the accuracy on retained test data.</li><li><strong>Use ResNet18 for Migration Learning</strong>: now use migration learning to use a pre-trained ResNet18 on the dataset as follows:</li><li><strong>Without changing the trained weights of other people’s models</strong>: ResNet18 is used as a fixed feature extractor.</li><li><strong>Fine-tuning using RestNet</strong> : ResNet18 is fine-tuned on the training data.</li><li><strong>Fine-tuning using EfficientNet_B5</strong>: Repeat step 4 but now use EfficientNet_B5 instead of RestNet18.<br><strong>Compare these different methods and print out the accuracy</strong>: Compare the accuracy of the different methods on the test data and print out the training time for each method.<br>Training time for each method.</li></ol><h1 id="Task-0-Importing-Packages">Task 0 - Importing Packages</h1><p>Let’s start by importing the required package: # Task 0 - import package</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CNN </span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> lr_scheduler</span><br><span class="line"><span class="keyword">import</span> torch.backends.cudnn <span class="keyword">as</span> cudnn</span><br><span class="line"></span><br><span class="line"><span class="comment"># others</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> tempfile <span class="keyword">import</span> TemporaryDirectory</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># dataset </span></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, models, transforms</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> Flowers102</span><br><span class="line"></span><br><span class="line"><span class="comment"># label </span></span><br><span class="line"><span class="keyword">from</span> scipy.io <span class="keyword">import</span> loadmat</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">cudnn.benchmark = <span class="literal">True</span></span><br><span class="line">plt.ion()   <span class="comment"># interactive mode</span></span><br></pre></td></tr></table></figure><h1 id="Task-1-Selecting-a-DataSet">Task 1 - Selecting a DataSet</h1><ul><li>Ref: <a href="https://www.geeksforgeeks.org/how-to-normalize-images-in-pytorch/">Why [0.485, 0.456, 0.406] for Normalization</a></li></ul><div class="note info flat"><p><strong>Select a DataSet</strong>: Check out the torchvision <a href="https://pytorch.org/vision/stable/datasets.html">DataSet of Pytorch</a> and decide one dataset that you want to use (no<br>CIFAR, no ImageNet, no FashionMNIST).</p></div><p>In order to experience Transfer Learning and train it quickly, we use flower102 here. We use flower102 as our dataset. Since flower102 doesn’t provide Chinese labels, most of my searching on the web is done by reading the <code>.json</code> or <code>.txt</code> files that are already written, which describes each label index in Chinese.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Specify the data you want to download, the path and btach size, and the amount of training to do at once.</span></span><br><span class="line">batch_size = <span class="number">4</span></span><br><span class="line">data_dir = <span class="string">&#x27;... /... /Data/flowers-102&#x27;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Build the classes_name of the dataset</span></span><br><span class="line">json_data = <span class="string">&#x27;&#123;&quot;21&quot;: &quot;fire lily&quot;, &quot;3&quot;: &quot;canterbury bells&quot;, &quot;45&quot;: &quot;bolero deep blue&quot;, &quot;1&quot;: &quot;pink primrose&quot;, &quot;34&quot;: &quot;mexican aster&quot;, &quot;27&quot;: &quot;prince of wales feathers&quot;, &quot;7&quot;: &quot;moon orchid&quot;, &quot;16&quot;: &quot;globe-flower&quot;, &quot;25&quot;: &quot;grape hyacinth&quot;, &quot;26&quot;: &quot;corn poppy&quot;, &quot;79&quot;: &quot;toad lily&quot;, &quot;39&quot;: &quot;siam tulip&quot;, &quot;24&quot;: &quot;red ginger&quot;, &quot;67&quot;: &quot;spring crocus&quot;, &quot;35&quot;: &quot;alpine sea holly&quot;, &quot;32&quot;: &quot;garden phlox&quot;, &quot;10&quot;: &quot;globe thistle&quot;, &quot;6&quot;: &quot;tiger lily&quot;, &quot;93&quot;: &quot;ball moss&quot;, &quot;33&quot;: &quot;love in the mist&quot;, &quot;9&quot;: &quot;monkshood&quot;, &quot;102&quot;: &quot;blackberry lily&quot;, &quot;14&quot;: &quot;spear thistle&quot;, &quot;19&quot;: &quot;balloon flower&quot;, &quot;100&quot;: &quot;blanket flower&quot;, &quot;13&quot;: &quot;king protea&quot;, &quot;49&quot;: &quot;oxeye daisy&quot;, &quot;15&quot;: &quot;yellow iris&quot;, &quot;61&quot;: &quot;cautleya spicata&quot;, &quot;31&quot;: &quot;carnation&quot;, &quot;64&quot;: &quot;silverbush&quot;, &quot;68&quot;: &quot;bearded iris&quot;, &quot;63&quot;: &quot;black-eyed susan&quot;, &quot;69&quot;: &quot;windflower&quot;, &quot;62&quot;: &quot;japanese anemone&quot;, &quot;20&quot;: &quot;giant white arum lily&quot;, &quot;38&quot;: &quot;great masterwort&quot;, &quot;4&quot;: &quot;sweet pea&quot;, &quot;86&quot;: &quot;tree mallow&quot;, &quot;101&quot;: &quot;trumpet creeper&quot;, &quot;42&quot;: &quot;daffodil&quot;, &quot;22&quot;: &quot;pincushion flower&quot;, &quot;2&quot;: &quot;hard-leaved pocket orchid&quot;, &quot;54&quot;: &quot;sunflower&quot;, &quot;66&quot;: &quot;osteospermum&quot;, &quot;70&quot;: &quot;tree poppy&quot;, &quot;85&quot;: &quot;desert-rose&quot;, &quot;99&quot;: &quot;bromelia&quot;, &quot;87&quot;: &quot;magnolia&quot;, &quot;5&quot;: &quot;english marigold&quot;, &quot;92&quot;: &quot;bee balm&quot;, &quot;28&quot;: &quot;stemless gentian&quot;, &quot;97&quot;: &quot;mallow&quot;, &quot;57&quot;: &quot;gaura&quot;, &quot;40&quot;: &quot;lenten rose&quot;, &quot;47&quot;: &quot;marigold&quot;, &quot;59&quot;: &quot;orange dahlia&quot;, &quot;48&quot;: &quot;buttercup&quot;, &quot;55&quot;: &quot;pelargonium&quot;, &quot;36&quot;: &quot;ruby-lipped cattleya&quot;, &quot;91&quot;: &quot;hippeastrum&quot;, &quot;29&quot;: &quot;artichoke&quot;, &quot;71&quot;: &quot;gazania&quot;, &quot;90&quot;: &quot;canna lily&quot;, &quot;18&quot;: &quot;peruvian lily&quot;, &quot;98&quot;: &quot;mexican petunia&quot;, &quot;8&quot;: &quot;bird of paradise&quot;, &quot;30&quot;: &quot;sweet william&quot;, &quot;17&quot;: &quot;purple coneflower&quot;, &quot;52&quot;: &quot;wild pansy&quot;, &quot;84&quot;: &quot;columbine&quot;, &quot;12&quot;: &quot;colt\&#x27;s foot&quot;, &quot;11&quot;: &quot;snapdragon&quot;, &quot;96&quot;: &quot;camellia&quot;, &quot;23&quot;: &quot;fritillary&quot;, &quot;50&quot;: &quot;common dandelion&quot;, &quot;44&quot;: &quot;poinsettia&quot;, &quot;53&quot;: &quot;primula&quot;, &quot;72&quot;: &quot;azalea&quot;, &quot;65&quot;: &quot;californian poppy&quot;, &quot;80&quot;: &quot;anthurium&quot;, &quot;76&quot;: &quot;morning glory&quot;, &quot;37&quot;: &quot;cape flower&quot;, &quot;56&quot;: &quot;bishop of llandaff&quot;, &quot;60&quot;: &quot;pink-yellow dahlia&quot;, &quot;82&quot;: &quot;clematis&quot;, &quot;58&quot;: &quot;geranium&quot;, &quot;75&quot;: &quot;thorn apple&quot;, &quot;41&quot;: &quot;barbeton daisy&quot;, &quot;95&quot;: &quot;bougainvillea&quot;, &quot;43&quot;: &quot;sword lily&quot;, &quot;83&quot;: &quot;hibiscus&quot;, &quot;78&quot;: &quot;lotus lotus&quot;, &quot;88&quot;: &quot;cyclamen&quot;, &quot;94&quot;: &quot;foxglove&quot;, &quot;81&quot;: &quot;frangipani&quot;, &quot;74&quot;: &quot;rose&quot;, &quot;89&quot;: &quot;watercress&quot;, &quot;73&quot;: &quot;water lily&quot;, &quot;46&quot;: &quot;wallflower&quot;, &quot;77&quot;: &quot;passion flower&quot;, &quot;51&quot;: &quot;petunia&quot;&#125;&#x27;</span></span><br><span class="line"><span class="comment"># load data </span></span><br><span class="line">cat_to_name = json.loads(json_data)</span><br><span class="line"><span class="comment"># Turn the key into an int, because the label of the dataset starts from 0. But this json starts from 1, so we have to -1 </span></span><br><span class="line">cat_to_name = &#123;<span class="built_in">int</span>(k)-<span class="number">1</span>:v <span class="keyword">for</span> k,v <span class="keyword">in</span> cat_to_name.items()&#125;</span><br><span class="line"><span class="comment"># sort and print </span></span><br><span class="line">class_names = <span class="built_in">dict</span>(<span class="built_in">sorted</span>(cat_to_name.items()))</span><br><span class="line"><span class="built_in">print</span>(class_names)</span><br></pre></td></tr></table></figure><blockquote><p>Result</p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="number">0</span>: <span class="string">&#x27;pink primrose&#x27;</span>, <span class="number">1</span>: <span class="string">&#x27;hard-leaved pocket orchid&#x27;</span>, <span class="number">2</span>: <span class="string">&#x27;canterbury bells&#x27;</span>, <span class="number">3</span>: <span class="string">&#x27;sweet pea&#x27;</span>, <span class="number">4</span>: <span class="string">&#x27;english marigold&#x27;</span>, <span class="number">5</span>: <span class="string">&#x27;tiger lily&#x27;</span>, <span class="number">6</span>: <span class="string">&#x27;moon orchid&#x27;</span>, <span class="number">7</span>: <span class="string">&#x27;bird of paradise&#x27;</span>, <span class="number">8</span>: <span class="string">&#x27;monkshood&#x27;</span>, <span class="number">9</span>: <span class="string">&#x27;globe thistle&#x27;</span>, <span class="number">10</span>: <span class="string">&#x27;snapdragon&#x27;</span>, <span class="number">11</span>: <span class="string">&quot;colt&#x27;s foot&quot;</span>, <span class="number">12</span>: <span class="string">&#x27;king protea&#x27;</span>, <span class="number">13</span>: <span class="string">&#x27;spear thistle&#x27;</span>, <span class="number">14</span>: <span class="string">&#x27;yellow iris&#x27;</span>, <span class="number">15</span>: <span class="string">&#x27;globe-flower&#x27;</span>, <span class="number">16</span>: <span class="string">&#x27;purple coneflower&#x27;</span>, <span class="number">17</span>: <span class="string">&#x27;peruvian lily&#x27;</span>, <span class="number">18</span>: <span class="string">&#x27;balloon flower&#x27;</span>, <span class="number">19</span>: <span class="string">&#x27;giant white arum lily&#x27;</span>, <span class="number">20</span>: <span class="string">&#x27;fire lily&#x27;</span>, <span class="number">21</span>: <span class="string">&#x27;pincushion flower&#x27;</span>, <span class="number">22</span>: <span class="string">&#x27;fritillary&#x27;</span>, <span class="number">23</span>: <span class="string">&#x27;red ginger&#x27;</span>, <span class="number">24</span>: <span class="string">&#x27;grape hyacinth&#x27;</span>, <span class="number">25</span>: <span class="string">&#x27;corn poppy&#x27;</span>, <span class="number">26</span>: <span class="string">&#x27;prince of wales feathers&#x27;</span>, <span class="number">27</span>: <span class="string">&#x27;stemless gentian&#x27;</span>, <span class="number">28</span>: <span class="string">&#x27;artichoke&#x27;</span>, <span class="number">29</span>: <span class="string">&#x27;sweet william&#x27;</span>, <span class="number">30</span>: <span class="string">&#x27;carnation&#x27;</span>, <span class="number">31</span>: <span class="string">&#x27;garden phlox&#x27;</span>, <span class="number">32</span>: <span class="string">&#x27;love in the mist&#x27;</span>, <span class="number">33</span>: <span class="string">&#x27;mexican aster&#x27;</span>, <span class="number">34</span>: <span class="string">&#x27;alpine sea holly&#x27;</span>, <span class="number">35</span>: <span class="string">&#x27;ruby-lipped cattleya&#x27;</span>, <span class="number">36</span>: <span class="string">&#x27;cape flower&#x27;</span>, <span class="number">37</span>: <span class="string">&#x27;great masterwort&#x27;</span>, <span class="number">38</span>: <span class="string">&#x27;siam tulip&#x27;</span>, <span class="number">39</span>: <span class="string">&#x27;lenten rose&#x27;</span>, <span class="number">40</span>: <span class="string">&#x27;barbeton daisy&#x27;</span>, <span class="number">41</span>: <span class="string">&#x27;daffodil&#x27;</span>, <span class="number">42</span>: <span class="string">&#x27;sword lily&#x27;</span>, <span class="number">43</span>: <span class="string">&#x27;poinsettia&#x27;</span>, <span class="number">44</span>: <span class="string">&#x27;bolero deep blue&#x27;</span>, <span class="number">45</span>: <span class="string">&#x27;wallflower&#x27;</span>, <span class="number">46</span>: <span class="string">&#x27;marigold&#x27;</span>, <span class="number">47</span>: <span class="string">&#x27;buttercup&#x27;</span>, <span class="number">48</span>: <span class="string">&#x27;oxeye daisy&#x27;</span>, <span class="number">49</span>: <span class="string">&#x27;common dandelion&#x27;</span>, <span class="number">50</span>: <span class="string">&#x27;petunia&#x27;</span>, <span class="number">51</span>: <span class="string">&#x27;wild pansy&#x27;</span>, <span class="number">52</span>: <span class="string">&#x27;primula&#x27;</span>, <span class="number">53</span>: <span class="string">&#x27;sunflower&#x27;</span>, <span class="number">54</span>: <span class="string">&#x27;pelargonium&#x27;</span>, <span class="number">55</span>: <span class="string">&#x27;bishop of llandaff&#x27;</span>, <span class="number">56</span>: <span class="string">&#x27;gaura&#x27;</span>, <span class="number">57</span>: <span class="string">&#x27;geranium&#x27;</span>, <span class="number">58</span>: <span class="string">&#x27;orange dahlia&#x27;</span>, <span class="number">59</span>: <span class="string">&#x27;pink-yellow dahlia&#x27;</span>, <span class="number">60</span>: <span class="string">&#x27;cautleya spicata&#x27;</span>, <span class="number">61</span>: <span class="string">&#x27;japanese anemone&#x27;</span>, <span class="number">62</span>: <span class="string">&#x27;black-eyed susan&#x27;</span>, <span class="number">63</span>: <span class="string">&#x27;silverbush&#x27;</span>, <span class="number">64</span>: <span class="string">&#x27;californian poppy&#x27;</span>, <span class="number">65</span>: <span class="string">&#x27;osteospermum&#x27;</span>, <span class="number">66</span>: <span class="string">&#x27;spring crocus&#x27;</span>, <span class="number">67</span>: <span class="string">&#x27;bearded iris&#x27;</span>, <span class="number">68</span>: <span class="string">&#x27;windflower&#x27;</span>, <span class="number">69</span>: <span class="string">&#x27;tree poppy&#x27;</span>, <span class="number">70</span>: <span class="string">&#x27;gazania&#x27;</span>, <span class="number">71</span>: <span class="string">&#x27;azalea&#x27;</span>, <span class="number">72</span>: <span class="string">&#x27;water lily&#x27;</span>, <span class="number">73</span>: <span class="string">&#x27;rose&#x27;</span>, <span class="number">74</span>: <span class="string">&#x27;thorn apple&#x27;</span>, <span class="number">75</span>: <span class="string">&#x27;morning glory&#x27;</span>, <span class="number">76</span>: <span class="string">&#x27;passion flower&#x27;</span>, <span class="number">77</span>: <span class="string">&#x27;lotus lotus&#x27;</span>, <span class="number">78</span>: <span class="string">&#x27;toad lily&#x27;</span>, <span class="number">79</span>: <span class="string">&#x27;anthurium&#x27;</span>, <span class="number">80</span>: <span class="string">&#x27;frangipani&#x27;</span>, <span class="number">81</span>: <span class="string">&#x27;clematis&#x27;</span>, <span class="number">82</span>: <span class="string">&#x27;hibiscus&#x27;</span>, <span class="number">83</span>: <span class="string">&#x27;columbine&#x27;</span>, <span class="number">84</span>: <span class="string">&#x27;desert-rose&#x27;</span>, <span class="number">85</span>: <span class="string">&#x27;tree mallow&#x27;</span>, <span class="number">86</span>: <span class="string">&#x27;magnolia&#x27;</span>, <span class="number">87</span>: <span class="string">&#x27;cyclamen&#x27;</span>, <span class="number">88</span>: <span class="string">&#x27;watercress&#x27;</span>, <span class="number">89</span>: <span class="string">&#x27;canna lily&#x27;</span>, <span class="number">90</span>: <span class="string">&#x27;hippeastrum&#x27;</span>, <span class="number">91</span>: <span class="string">&#x27;bee balm&#x27;</span>, <span class="number">92</span>: <span class="string">&#x27;ball moss&#x27;</span>, <span class="number">93</span>: <span class="string">&#x27;foxglove&#x27;</span>, <span class="number">94</span>: <span class="string">&#x27;bougainvillea&#x27;</span>, <span class="number">95</span>: <span class="string">&#x27;camellia&#x27;</span>, <span class="number">96</span>: <span class="string">&#x27;mallow&#x27;</span>, <span class="number">97</span>: <span class="string">&#x27;mexican petunia&#x27;</span>, <span class="number">98</span>: <span class="string">&#x27;bromelia&#x27;</span>, <span class="number">99</span>: <span class="string">&#x27;blanket flower&#x27;</span>, <span class="number">100</span>: <span class="string">&#x27;trumpet creeper&#x27;</span>, <span class="number">101</span>: <span class="string">&#x27;blackberry lily&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><p>Here I mainly refer to the official website <a href="hhttps://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html">Transfer Learning</a> to change the writing style to the dataSet I want, and start to download the file:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Data augmentation and normalization for training</span></span><br><span class="line"><span class="comment"># Just normalization for validation</span></span><br><span class="line">data_transforms = &#123;</span><br><span class="line">    <span class="string">&#x27;train&#x27;</span>: transforms.Compose([</span><br><span class="line">        <span class="comment"># First, the image is randomly cropped and then resized. A random rectangular area is chosen and the image is cropped.</span></span><br><span class="line">        <span class="comment"># The cropped image is then resized to the specified size of 224x224 pixels.</span></span><br><span class="line">        transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">        <span class="comment"># Set the probability of image flipping, usually a number from 0 to 1, for example, 0.5, which means there&#x27;s a 50% chance of flipping the image. Default value is 0.5</span></span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        <span class="comment"># Convert the image into a Tensor</span></span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        <span class="comment"># Normalize the image values using numerical normalization, where the first parameter is mean, and the second parameter is the standard deviation (std)</span></span><br><span class="line">        <span class="comment"># The reason for setting [0.485, 0.456, 0.406] can be referred from: https://www.geeksforgeeks.org/how-to-normalize-images-in-pytorch/</span></span><br><span class="line">        transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">    ]),</span><br><span class="line">    <span class="string">&#x27;val&#x27;</span>: transforms.Compose([</span><br><span class="line">        <span class="comment"># This doesn&#x27;t randomly select an area but directly resizes the entire image to fit the specified size.</span></span><br><span class="line">        transforms.Resize(<span class="number">256</span>),</span><br><span class="line">        <span class="comment"># Keep the central part of the image, then resize to meet the specified size.</span></span><br><span class="line">        <span class="comment"># Used for validation or test data to ensure that the test images have similar features, and don&#x27;t have the randomness like RandomResizedCrop.</span></span><br><span class="line">        transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">    ]),</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># We download the training data into the data_dir/train folder, and use the data_transforms[&quot;train&quot;] function for data transformation.</span></span><br><span class="line">train_datasets = Flowers102(root=data_dir+<span class="string">&quot;/train&quot;</span>, split=<span class="string">&quot;train&quot;</span>, download=<span class="literal">True</span>, transform=data_transforms[<span class="string">&quot;train&quot;</span>])</span><br><span class="line"><span class="comment"># We download the validation data into the data_dir/val folder, and use the data_transforms[&quot;val&quot;] function for data transformation.</span></span><br><span class="line">val_datasets = Flowers102(root=data_dir+<span class="string">&quot;/val&quot;</span>, split=<span class="string">&quot;val&quot;</span>, download=<span class="literal">True</span>, transform=data_transforms[<span class="string">&quot;val&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Specify to download the flowers102 dataset, downloading both train and val datasets.</span></span><br><span class="line">image_datasets = &#123;x: Flowers102(root=data_dir, split=x, download=<span class="literal">True</span>, transform=data_transforms[x])</span><br><span class="line">                    <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert to DataLoader format, and specify batch_size</span></span><br><span class="line">dataloaders = &#123;x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,</span><br><span class="line">                                             shuffle=<span class="literal">True</span>, num_workers=<span class="number">4</span>)</span><br><span class="line">              <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;mps&quot;</span> <span class="keyword">if</span> torch.backends.mps.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;device: &quot;</span>,device)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;image_datasets function call: &quot;</span>, <span class="built_in">dir</span>(image_datasets[<span class="string">&quot;train&quot;</span>]))</span><br></pre></td></tr></table></figure><div class="note info flat"><p>This completes the first Task, which is to download the dataset we want.</p></div><h1 id="Task-2-Printing-out-images-and-profile-sizes">Task 2 - Printing out images and profile sizes</h1><div class="note info flat"><ol start="2"><li><em><strong>Print images and profile size</strong></em>: display some sample images of the dataset in the notebook and print the dataset size.</li></ol></div><p>Referring to the official website <a href="hhttps://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html">Transfer Learning</a> for the writeup, we first create the</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">imshow</span>(<span class="params">inp, title=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Display image for Tensor.&quot;&quot;&quot;</span></span><br><span class="line">    inp = inp.numpy().transpose((<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line">    mean = np.array([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>])</span><br><span class="line">    std = np.array([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">    inp = std * inp + mean</span><br><span class="line">    inp = np.clip(inp, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    plt.imshow(inp)</span><br><span class="line">    <span class="keyword">if</span> title <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    plt.pause(<span class="number">0.001</span>)  <span class="comment"># pause a bit so that plots are updated</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get a batch of training data</span></span><br><span class="line">inputs, classes = <span class="built_in">next</span>(<span class="built_in">iter</span>(dataloaders[<span class="string">&#x27;train&#x27;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make a grid from batch</span></span><br><span class="line">out = torchvision.utils.make_grid(inputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># x.item() takes the value of the tensor, usually a number, and finds the English equivalent of that number in the class_names dic</span></span><br><span class="line">imshow(out, title=[class_names[x.item()] <span class="keyword">for</span> x <span class="keyword">in</span> classes])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(inputs.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;dataset_sizes: &quot;</span>,dataset_sizes)</span><br></pre></td></tr></table></figure><blockquote><p>Result</p></blockquote><p><img src="https://i.imgur.com/dPGyFvN.png" alt=""></p><h1 id="Task-3-4-CNN-Batch-Normalization">Task 3 &amp; 4 - CNN + Batch Normalization</h1><div class="note info flat"><ol start="3"><li><strong>Construct a CNN using Batch Normalization</strong>: Design a CNN to predict on the dataset. Use a similar architecture like last time, but this time also include batch normalization layers.</li><li>**Train the model on the dataset and measure the accuracy on hold out test data.</li></ol></div><p><strong>According to Prof. Hongyi Li in Transfer Learning, he mentioned…</strong><br>Usually, <code>Batch Normalization</code> is performed before <code>Activation Function</code>, you can refer to this <a href="/posts/ML.html#Feature-Normalization">section</a> if you are interested. <code>Batch Normalization</code> is simply to run <code>feature normalization</code> in the same way as <code>Batch</code>.</p><p><strong>Why do we need to do feature normalization?  Why do we do feature normalization?</strong><br>It is to let different features have similar value ranges, so that when the model performs Gradient Descent, the effect of w1 and w2 on the loss will not be too big, and they have similar value ranges, so that they can affect the loss evenly, instead of a certain w1 affecting the loss much more than w2.</p><blockquote><p>Instead of a w1 having a much larger effect on loss than w2, the effect will be something like the following.</p></blockquote><p>! <a href="https://i.imgur.com/RB51XXy.png">Origin</a></p><h2 id="Build-the-Network">Build the Network</h2><div class="note warning flat"><p>Note that depending on the size of the dataset and the number of hidden layers, you have to make two adjustments!</p><ol><li>In the fully connection layer, the input is determined by the number of times your hidden layer performs <code>max-pooling</code> and <code>convolution</code>. 2.</li><li>Then you have to adjust the number of outputs in the last output layer according to the number of categories in your dataset.</li></ol><p>Please note the part of the code labeled with the comment arrow <code>&lt;====</code>.</p></div><p>So our CNN architecture is as follows, <code>You can decide whether you want to run a dropout to unpack the annotations or not</code>.<br>But in my case, I tested that the dropout didn’t result in higher accuracy.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NewNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(NewNet, self).__init__()</span><br><span class="line">        <span class="comment"># Layer 1: 3x3 kernel, depth = 32, 224-3+1=222 =&gt; 222x222 pixel</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">3</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(<span class="number">32</span>)</span><br><span class="line">        <span class="comment"># self.dropout1 = nn.Dropout(0.5) # Apply dropout as needed</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Layer 2: Max pooling with 2x2 kernel, 222/2=111 =&gt; 111x111 pixel</span></span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Layer 3: 3x3 kernel, depth = 64, 111-3+1=109 =&gt; 109x109 pixel</span></span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">3</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(<span class="number">64</span>)</span><br><span class="line">        <span class="comment"># self.dropout2 = nn.Dropout(0.5) # Apply dropout as needed</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Layer 4: Max pooling with 2x2 kernel, 109/2=54 =&gt; 54x54 pixel</span></span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Layer 5: 3x3 kernel, depth = 128, 54-3+1=52 =&gt; 52x52 pixel</span></span><br><span class="line">        self.conv3 = nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, <span class="number">3</span>)</span><br><span class="line">        self.bn3 = nn.BatchNorm2d(<span class="number">128</span>)</span><br><span class="line">        <span class="comment"># self.dropout3 = nn.Dropout(0.5) # Apply dropout as needed</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Layer 6: Max pooling with 2x2 kernel, 52/2=26 =&gt; 26x26 pixel</span></span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Final input is 512, pixel is 26*26 =&gt; 128*26*26</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">128</span> * <span class="number">26</span> * <span class="number">26</span>, <span class="number">2048</span>) <span class="comment"># &lt;==== Adjust according to the hidden layer, 128 * 26 * 26</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">2048</span>, <span class="number">1024</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">1024</span>, <span class="number">512</span>)</span><br><span class="line">        self.fc4 = nn.Linear(<span class="number">512</span>, <span class="number">102</span>) <span class="comment"># &lt;==== 102 according to the number of classes in the dataset</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># We put the batch normalization before the activation function. </span></span><br><span class="line">        x = F.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        x = self.pool(x)</span><br><span class="line">        <span class="comment"># x = self.dropout1(x) # Apply dropout as needed</span></span><br><span class="line">        x = F.relu(self.bn2(self.conv2(x)))</span><br><span class="line">        x = self.pool(x)</span><br><span class="line">        <span class="comment"># x = self.dropout2(x) # Apply dropout as needed</span></span><br><span class="line">        x = F.relu(self.bn3(self.conv3(x)))</span><br><span class="line">        x = self.pool(x)</span><br><span class="line">        <span class="comment"># x = self.dropout3(x) # Apply dropout as needed</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">128</span> * <span class="number">26</span> * <span class="number">26</span>) <span class="comment"># &lt;==== Adjust according to the hidden layer, 128 * 26 * 26</span></span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = F.relu(self.fc3(x))</span><br><span class="line">        x = self.fc4(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">net = NewNet()</span><br><span class="line">net.to(device)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>and specify the optimizer and loss function:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><h2 id="Create-a-Training-Func">Create a Training Func</h2><p>We need to create a funcntion to execute the training model as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">epoch, start_time</span>):</span><br><span class="line">    net.train()</span><br><span class="line">    cur_count = <span class="number">0</span> </span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloaders[<span class="string">&quot;train&quot;</span>], <span class="number">0</span>):</span><br><span class="line">        cur_count += <span class="built_in">len</span>(data)</span><br><span class="line">        inputs, labels = data[<span class="number">0</span>].to(device), data[<span class="number">1</span>].to(device)</span><br><span class="line">        <span class="comment"># zero the parameter gradients</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward + backward + optimize</span></span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        outputs.to(device)</span><br><span class="line">        </span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.to(device)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">100</span> == <span class="number">99</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;[<span class="subst">&#123;epoch&#125;</span>, <span class="subst">&#123;batch_idx + <span class="number">1</span>:5d&#125;</span>] loss: <span class="subst">&#123;running_loss / <span class="number">100</span>:<span class="number">.3</span>f&#125;</span> time elapsed: <span class="subst">&#123;<span class="built_in">round</span>((time.time() - start_time))&#125;</span> sec.&#x27;</span>)</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br></pre></td></tr></table></figure><h2 id="Build-Testing-Func">Build Testing Func</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(): </span><br><span class="line">    net.<span class="built_in">eval</span>()  <span class="comment"># set model to evaluation mode</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    class_correct = [<span class="number">0</span>] * <span class="built_in">len</span>(class_names)  </span><br><span class="line">    class_total = [<span class="number">0</span>] * <span class="built_in">len</span>(class_names)  </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> dataloaders[<span class="string">&quot;val&quot;</span>]:</span><br><span class="line">            images, labels = data[<span class="number">0</span>].to(device), data[<span class="number">1</span>].to(device)</span><br><span class="line">            outputs = net(images) </span><br><span class="line"></span><br><span class="line">            <span class="comment"># select top 3 predictions</span></span><br><span class="line">            _, predicted = torch.topk(outputs, <span class="number">1</span>, dim=<span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># check if predicted labels are in true labels</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(labels)):</span><br><span class="line">                total += <span class="number">1</span></span><br><span class="line">                class_total[labels[i]] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> labels[i] <span class="keyword">in</span> predicted[i]:</span><br><span class="line">                    correct += <span class="number">1</span></span><br><span class="line">                    class_correct[labels[i]] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    class_accuracies = [class_correct[i] / class_total[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(class_names))]</span><br><span class="line">    accuracy = correct / total</span><br><span class="line">    <span class="keyword">return</span> accuracy, class_accuracies</span><br></pre></td></tr></table></figure><h2 id="Run-Training">Run Training</h2><p>In order for us to see the status of the training during the training process, we print the status of the training every 100 batches and the status of the test every 5 epochs.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">num_epochs = <span class="number">100</span> </span><br><span class="line">start_time = time.time()</span><br><span class="line"></span><br><span class="line">accuracy, class_accuracies = test()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Accuracy on test data (top-1): <span class="subst">&#123;<span class="number">100</span> * accuracy:<span class="number">.2</span>f&#125;</span>%&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_epochs - <span class="number">1</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;============ Epoch: <span class="subst">&#123;epoch&#125;</span> ==========&quot;</span>)</span><br><span class="line">    train(epoch, start_time)</span><br><span class="line">    <span class="comment"># every 5 epoch is completed, we will perform validation on the test set </span></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">        accuracy, class_accuracies = test()</span><br><span class="line">        <span class="comment"># print accuracies</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Accuracy on test data (top-1): <span class="subst">&#123;<span class="number">100</span> * accuracy:<span class="number">.2</span>f&#125;</span>%&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Finished Training. Total elapsed time: <span class="subst">&#123;<span class="built_in">round</span>((time.time() - start_time) / <span class="number">60</span>, <span class="number">1</span>)&#125;</span> min&#x27;</span>)</span><br></pre></td></tr></table></figure><blockquote><p>Result</p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Accuracy on test data (top<span class="number">-1</span>): <span class="number">0.0019</span>%</span><br><span class="line">============ Epoch: <span class="number">0</span> ==========</span><br><span class="line">[<span class="number">0</span>,   <span class="number">100</span>] loss: <span class="number">4.984</span> <span class="built_in">time</span> elapsed: <span class="number">40</span> sec.</span><br><span class="line">[<span class="number">0</span>,   <span class="number">200</span>] loss: <span class="number">4.876</span> <span class="built_in">time</span> elapsed: <span class="number">47</span> sec.</span><br><span class="line">...</span><br><span class="line">Accuracy on test data (top<span class="number">-1</span>): <span class="number">35.59</span>%</span><br><span class="line">Finished Training. Total elapsed <span class="built_in">time</span>: <span class="number">67</span> <span class="built_in">min</span></span><br></pre></td></tr></table></figure><h1 id="Task-5-4-Transfer-Learning：Resnet18">Task 5 &amp; 4 - Transfer Learning：Resnet18</h1><div class="note info flat"><ol start="4"><li><strong>Train a model using a dataset and print out the accuracy of the test</strong>: train a model on a dataset and measure the accuracy on retained test data.</li><li><strong>Use ResNet18 for Migration Learning</strong>: now use migration learning to use a pre-trained ResNet18 on the dataset as follows:<br><strong>Without changing the trained weights of other people’s models</strong>: ResNet18 is used as a fixed feature extractor.<ol><li><strong>Fix the parameters</strong>: Fix the parameters of the ResNet18 model and only train the last layer.</li><li><strong>Fine-tuning</strong>: Fine-tune the ResNet18 model.</li></ol></li></ol></div><h2 id="Build-up-Trainning-Testing-Func">Build up Trainning &amp; Testing Func</h2><p>Refer to the official website <a href="hhttps://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html">Transfer Learning</a> for the writeup, we first create the</p><figure class="highlight python"><figcaption><span>def train_model(model, criterion, optimizer, scheduler, num_epochs</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set the start time for logging to monitor the training time for each epoch</span></span><br><span class="line">since = time.time()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a temporary folder to store the best model parameters</span></span><br><span class="line"><span class="keyword">with</span> TemporaryDirectory() <span class="keyword">as</span> tempdir:</span><br><span class="line">    best_model_params_path = os.path.join(tempdir, <span class="string">&#x27;best_model_params.pt&#x27;</span>)</span><br><span class="line">    <span class="comment"># Haven&#x27;t started training yet, but we first save the current model</span></span><br><span class="line">    torch.save(model.state_dict(), best_model_params_path)</span><br><span class="line">    best_acc = <span class="number">0.0</span>  <span class="comment"># Set the current best accuracy to 0, it will be updated if a higher value is found to determine the best model</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Epoch <span class="subst">&#123;epoch&#125;</span>/<span class="subst">&#123;num_epochs - <span class="number">1</span>&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># After training each epoch, proceed with validation</span></span><br><span class="line">        <span class="keyword">for</span> phase <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]:</span><br><span class="line">            <span class="comment"># Determine whether it&#x27;s training or validation phase</span></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                model.train()  <span class="comment"># Set model to training mode</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                model.<span class="built_in">eval</span>()   <span class="comment"># Set model to evaluate mode</span></span><br><span class="line"></span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">            running_corrects = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Iterate over data.</span></span><br><span class="line">            <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> dataloaders[phase]:</span><br><span class="line">                <span class="comment"># Move to GPU</span></span><br><span class="line">                inputs = inputs.to(device)</span><br><span class="line">                labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Zero the parameter gradients</span></span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Forward propagation</span></span><br><span class="line">                <span class="comment"># track history if only in train</span></span><br><span class="line">                <span class="keyword">with</span> torch.set_grad_enabled(phase == <span class="string">&#x27;train&#x27;</span>):</span><br><span class="line">                    outputs = model(inputs)</span><br><span class="line">                    _, preds = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>) <span class="comment"># Select the number with the highest prediction as the label</span></span><br><span class="line">                    loss = criterion(outputs, labels) <span class="comment"># Calculate the difference between the answer and prediction</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment"># backward + optimize only if in training phase</span></span><br><span class="line">                    <span class="comment"># Perform backward propagation</span></span><br><span class="line">                    <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                        loss.backward()</span><br><span class="line">                        optimizer.step()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Since batch_size is 4, multiply loss by 4 to get the loss for a batch</span></span><br><span class="line">                running_loss += loss.item() * inputs.size(<span class="number">0</span>)</span><br><span class="line">                <span class="comment"># Calculate how many are correct in a batch</span></span><br><span class="line">                running_corrects += torch.<span class="built_in">sum</span>(preds == labels.data)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Adjust the learning rate only during training</span></span><br><span class="line">            <span class="comment"># scheduler is a learning rate (lr) adjuster used to modify the lr value during model training</span></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                scheduler.step()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># After an entire epoch of training, calculate the loss and accuracy for that epoch</span></span><br><span class="line">            <span class="comment"># Avg. loss = total loss / size of the entire dataset</span></span><br><span class="line">            epoch_loss = running_loss / dataset_sizes[phase]</span><br><span class="line">            <span class="comment"># Avg. Acc = total number of correct answers / size of the entire dataset</span></span><br><span class="line">            epoch_acc = running_corrects.<span class="built_in">float</span>() / dataset_sizes[phase]</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;phase&#125;</span> Loss: <span class="subst">&#123;epoch_loss:<span class="number">.4</span>f&#125;</span> Acc: <span class="subst">&#123;epoch_acc:<span class="number">.4</span>f&#125;</span> Time elapsed: <span class="subst">&#123;<span class="built_in">round</span>((time.time() - since))&#125;</span> sec.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># If during validation, and accuracy is found to be better than the current best, save the model parameters</span></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;val&#x27;</span> <span class="keyword">and</span> epoch_acc &gt; best_acc:</span><br><span class="line">                <span class="comment"># Update the current best accuracy</span></span><br><span class="line">                best_acc = epoch_acc</span><br><span class="line">                <span class="comment"># Deep copy the model</span></span><br><span class="line">                torch.save(model.state_dict(), best_model_params_path)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line">    time_elapsed = time.time() - since</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Training complete in <span class="subst">&#123;time_elapsed // <span class="number">60</span>:<span class="number">.0</span>f&#125;</span>m <span class="subst">&#123;time_elapsed % <span class="number">60</span>:<span class="number">.0</span>f&#125;</span>s&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Best val Acc: <span class="subst">&#123;best_acc:4f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load the best model weights</span></span><br><span class="line">    <span class="comment"># Take out the best model so far to continue with the next epoch of training</span></span><br><span class="line">    model.load_state_dict(torch.load(best_model_params_path))</span><br><span class="line"><span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><h2 id="Use-Transfer-Learning">Use Transfer Learning</h2><p>According to the teacher’s request, I want to use resnet18 for Transfer Learning, currently according to the [official description](<a href="https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet18">https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet18</a>. html#torchvision.models.ResNet18_Weights), <code>resent18</code> is <code>IMAGENET1K_V1</code> by default if we don’t give the parameter, in order to make it clear which model’s parameter we are using, we still give the parameter.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">model_ft = models.resnet18(weights=<span class="string">&#x27;IMAGENET1K_V1&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># num_ftrs is the number of input features for the last layer. </span></span><br><span class="line"><span class="comment"># Retrieve the number of input features for the last layer</span></span><br><span class="line">num_ftrs = model_ft.fc.in_features</span><br><span class="line"></span><br><span class="line"><span class="comment"># Here the size of each output sample is set to 102.</span></span><br><span class="line"><span class="comment"># model_ft.fc is the final layer of the model, used for classification.</span></span><br><span class="line"><span class="comment"># Creating the final layer ourselves, setting the input number as num_ftrs, and output number as 102 (since there are 102 classes in this case)</span></span><br><span class="line">model_ft.fc = nn.Linear(num_ftrs, <span class="number">102</span>)</span><br><span class="line">model_ft = model_ft.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The loss function uses CrossEntropyLoss </span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Observe that all parameters are being optimized</span></span><br><span class="line"><span class="comment"># Optimizer uses SGD with learning rate = 0.001, momentum = 0.9</span></span><br><span class="line">optimizer_ft = optim.SGD(model_ft.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decay LR by a factor of 0.1 every 7 epochs</span></span><br><span class="line"><span class="comment"># Multiply the learning rate by 0.1 every 7 epochs to decay the lr</span></span><br><span class="line">exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=<span class="number">7</span>, gamma=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure><p><img src="https://i.imgur.com/rygK4KS.png" alt=""></p><div class="note warning flat"><p><strong>Why need to adjust lr?</strong><br>Adjusting the learning rate every certain epoch is a common learning rate adjustment strategy called learning rate decay or learning rate scheduling. The effect of this is to:</p><ol><li><p>Improve model stability: During training, ``using a relatively large learning rate at the beginning helps to converge quickly.‘’ However, when training <code>near the optimal solution, a larger learning rate may cause the model to oscillate or over-adjust near the optimal solution</code>. By periodically decreasing the learning rate, the model will be more stable and closer to the optimal solution in the later stages of training.</p></li><li><p>Preventing overfitting: `Periodically decreasing the learning rate helps prevent the model from overfitting on the training set.’ When the learning rate is reduced, the model adjusts its parameters more carefully and is less likely to fall into the noise in the training set.</p></li></ol><p>In practice, the specific settings of the learning rate tuning strategy (e.g., the values of <code>step_size</code> and <code>gamma</code>) are usually adjusted based on trials and experience to achieve optimal performance. Typically, the settings of these parameters depend on the size of your dataset, the model architecture, the difficulty of the problem, and other factors.</p></div><h2 id="Start-Training">Start Training</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,</span><br><span class="line">                       num_epochs=<span class="number">25</span>)</span><br></pre></td></tr></table></figure><blockquote><p>Result: Accuracy on test data (top-1): 89.41%</p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">Epoch <span class="number">0</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">4.4280</span> Acc: <span class="number">0.0657</span> Time elapsed: <span class="number">33</span> sec.</span><br><span class="line">val Loss: <span class="number">2.9901</span> Acc: <span class="number">0.3118</span> Time elapsed: <span class="number">58</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">1</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">3.3046</span> Acc: <span class="number">0.2353</span> Time elapsed: <span class="number">87</span> sec.</span><br><span class="line">val Loss: <span class="number">1.6604</span> Acc: <span class="number">0.5941</span> Time elapsed: <span class="number">112</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">2</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">2.5080</span> Acc: <span class="number">0.4029</span> Time elapsed: <span class="number">141</span> sec.</span><br><span class="line">val Loss: <span class="number">1.2243</span> Acc: <span class="number">0.6951</span> Time elapsed: <span class="number">166</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">3</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">1.9871</span> Acc: <span class="number">0.5196</span> Time elapsed: <span class="number">195</span> sec.</span><br><span class="line">val Loss: <span class="number">0.9578</span> Acc: <span class="number">0.7216</span> Time elapsed: <span class="number">219</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">4</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">1.5865</span> Acc: <span class="number">0.6225</span> Time elapsed: <span class="number">249</span> sec.</span><br><span class="line">val Loss: <span class="number">0.6911</span> Acc: <span class="number">0.8108</span> Time elapsed: <span class="number">273</span> sec.</span><br><span class="line">...</span><br><span class="line">val Loss: <span class="number">0.3919</span> Acc: <span class="number">0.8912</span> Time elapsed: <span class="number">1313</span> sec.</span><br><span class="line"></span><br><span class="line">Training complete <span class="keyword">in</span> <span class="number">21</span>m <span class="number">53</span>s</span><br><span class="line">Best val Acc: <span class="number">0.894118</span></span><br></pre></td></tr></table></figure><h2 id="Using-ResNet18-as-a-fixed-feature-extractor">Using ResNet18 as a fixed feature extractor</h2><p>Due to the requirements of the homework, ResNet18 is required to be used as a fixed feature extractor, so we need to set all the parameters to be untrainable, and only the parameters of the last layer can be trained. <strong>Simply put, don’t change the weights of other people’s models.</strong> The only thing we need to change is to set each parameter of the model’s <code>requires_grad</code> to False. This way, we can use ResNet18 as a fixed feature extractor.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">model_conv = torchvision.models.resnet18(weights=<span class="string">&#x27;IMAGENET1K_V1&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># !!! Add these two lines to set requires_grad to False, so that the parameters will not be updated </span></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model_conv.parameters():</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">num_ftrs = model_conv.fc.in_features</span><br><span class="line">model_conv.fc = nn.Linear(num_ftrs, <span class="number">102</span>)</span><br><span class="line">model_conv = model_conv.to(device)</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=<span class="number">7</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># We start to train </span></span><br><span class="line">model_conv_SGD = train_model(model_conv, criterion, optimizer_conv,</span><br><span class="line">                         exp_lr_scheduler, num_epochs=<span class="number">25</span>)</span><br></pre></td></tr></table></figure><blockquote><p>Result: Accuracy on test data: 79.11%</p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">Epoch <span class="number">0</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">4.6979</span> Acc: <span class="number">0.0176</span> Time elapsed: <span class="number">24</span> sec.</span><br><span class="line">val Loss: <span class="number">3.9863</span> Acc: <span class="number">0.1235</span> Time elapsed: <span class="number">48</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">1</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">4.0589</span> Acc: <span class="number">0.1137</span> Time elapsed: <span class="number">72</span> sec.</span><br><span class="line">val Loss: <span class="number">3.1125</span> Acc: <span class="number">0.3608</span> Time elapsed: <span class="number">95</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">2</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">3.4935</span> Acc: <span class="number">0.2304</span> Time elapsed: <span class="number">119</span> sec.</span><br><span class="line">val Loss: <span class="number">2.5003</span> Acc: <span class="number">0.4912</span> Time elapsed: <span class="number">142</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">3</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">3.1030</span> Acc: <span class="number">0.3422</span> Time elapsed: <span class="number">165</span> sec.</span><br><span class="line">val Loss: <span class="number">2.1583</span> Acc: <span class="number">0.5510</span> Time elapsed: <span class="number">189</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">4</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">2.7367</span> Acc: <span class="number">0.4402</span> Time elapsed: <span class="number">212</span> sec.</span><br><span class="line">val Loss: <span class="number">1.7064</span> Acc: <span class="number">0.6304</span> Time elapsed: <span class="number">236</span> sec.</span><br><span class="line">...</span><br><span class="line">val Loss: <span class="number">1.0910</span> Acc: <span class="number">0.7824</span> Time elapsed: <span class="number">1179</span> sec.</span><br><span class="line"></span><br><span class="line">Training complete <span class="keyword">in</span> <span class="number">19</span>m <span class="number">39</span>s</span><br><span class="line">Best val Acc: <span class="number">0.791176</span></span><br></pre></td></tr></table></figure><h1 id="Task-6-4-Transfer-Learning：EfficientNet-B5">Task 6 &amp; 4 - Transfer Learning：EfficientNet_B5</h1><div class="note info flat"><ol start="4"><li><em><strong>Train a model using a dataset and print out the accuracy of the test</strong></em>: train a model on a dataset and measure the accuracy on retained test data.</li><li><em><strong>Fine-tuning using RestNet</strong></em> : ResNet18 is fine-tuned on the training data.</li></ol></div><p>We need to install the <code>efficientnet_pytorch</code> package first:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install efficientnet_pytorch</span><br></pre></td></tr></table></figure><p>Then we can import the package and use it:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> efficientnet_pytorch <span class="keyword">import</span> EfficientNet</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the pre-trained EfficientNet-B5 model</span></span><br><span class="line">model_ft = EfficientNet.from_pretrained(<span class="string">&#x27;efficientnet-b5&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># We obtain the number of input features for the last layer</span></span><br><span class="line">num_ftrs = model_ft._fc.in_features</span><br><span class="line"><span class="comment"># build a new layer, the input number is num_ftrs, and the output number is 102 (because there are 102 classes in this case)</span></span><br><span class="line">model_ft.fc = nn.Linear(num_ftrs, <span class="number">102</span>)</span><br><span class="line"><span class="comment"># Put the model on the GPU</span></span><br><span class="line">model_ft = model_ft.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loss function</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Observe that all parameters are being optimized</span></span><br><span class="line">optimizer_ft = optim.SGD(model_ft.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decay LR by a factor of 0.1 every 7 epochs</span></span><br><span class="line">exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=<span class="number">7</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start training </span></span><br><span class="line">model_ft_effb5 = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,</span><br><span class="line">                       num_epochs=<span class="number">25</span>)</span><br></pre></td></tr></table></figure><blockquote><p>Result: Accuracy on test data: 82.15%</p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">Epoch <span class="number">0</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">6.2860</span> Acc: <span class="number">0.0157</span> Time elapsed: <span class="number">156</span> sec.</span><br><span class="line">val Loss: <span class="number">5.6637</span> Acc: <span class="number">0.0382</span> Time elapsed: <span class="number">200</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">1</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">4.8955</span> Acc: <span class="number">0.1039</span> Time elapsed: <span class="number">322</span> sec.</span><br><span class="line">val Loss: <span class="number">4.5101</span> Acc: <span class="number">0.2392</span> Time elapsed: <span class="number">365</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">2</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">3.8566</span> Acc: <span class="number">0.2422</span> Time elapsed: <span class="number">485</span> sec.</span><br><span class="line">val Loss: <span class="number">3.6194</span> Acc: <span class="number">0.4265</span> Time elapsed: <span class="number">529</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">3</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">3.0979</span> Acc: <span class="number">0.3637</span> Time elapsed: <span class="number">653</span> sec.</span><br><span class="line">val Loss: <span class="number">2.8613</span> Acc: <span class="number">0.5539</span> Time elapsed: <span class="number">696</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">4</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">2.4323</span> Acc: <span class="number">0.4725</span> Time elapsed: <span class="number">818</span> sec.</span><br><span class="line">val Loss: <span class="number">2.2894</span> Acc: <span class="number">0.6725</span> Time elapsed: <span class="number">863</span> sec.</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Epoch <span class="number">24</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">1.3168</span> Acc: <span class="number">0.7343</span> Time elapsed: <span class="number">4769</span> sec.</span><br><span class="line">val Loss: <span class="number">1.3167</span> Acc: <span class="number">0.8167</span> Time elapsed: <span class="number">4812</span> sec.</span><br><span class="line"></span><br><span class="line">Training complete <span class="keyword">in</span> <span class="number">80</span>m <span class="number">12</span>s</span><br><span class="line">Best val Acc: <span class="number">0.821569</span></span><br></pre></td></tr></table></figure><h1 id="Task-7-Discussion">Task 7 - Discussion</h1><div class="note info flat"><p><strong>Compare these different methods and print out the accuracy</strong>: Compare the accuracy of the different methods on the test data and print out the training time for each method.</p></div><p>From the results of the above experiments, we can see that the accuracy of the model is as follows:</p><ul><li><a href="#Task-3-4-CNN-Batch-Normalization">Use the CNN build by ourselves</a></li><li>[Using Transfer Learning Resnet18](#Task-5-4-Transfer Learning: Resnet18)</li><li>[Using Transfer Learning EfficientNet-B5](#Task-6-4-Transfer Learning: EfficientNet-B5)</li></ul><p>Their data are as follows:</p><table><thead><tr><th>Model</th><th>Accuracy</th><th>Training Time</th><th>Result</th></tr></thead><tbody><tr><td>Self-built CNN</td><td><code>35%</code></td><td><code>more than 1 hour</code></td><td>Worst</td></tr><tr><td>Resnet18</td><td><strong>89.41%</strong></td><td>21 minutes</td><td>highest accuracy</td></tr><tr><td>Resnet18 (fixed feature extractor)</td><td>79.11%</td><td><strong>19 minutes</strong></td><td>Shortest</td></tr><tr><td>EfficientNet-B5</td><td>82.15%</td><td>80 mins</td><td>PuPu</td></tr></tbody></table><div class="note warning flat"><p><strong>Conclusion</strong></p><ul><li>If we use Transfer Learning, we can obviously feel that the accuracy rate is significantly improved and the training time is greatly reduced.</li><li>Moreover, in the current case, the accuracy is better without fixed model parameters, although the matching time is longer because of the gradient descent.</li></ul></div>]]></content>
      
      
      <categories>
          
          <category> Code </category>
          
          <category> Mechine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mechine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CIFAR10 Dataset - Using Pytorch to build CNN + activate GPU + output the result to TensorBoard</title>
      <link href="/en/posts/pytorch-CNN-TensorBoard/"/>
      <url>/en/posts/pytorch-CNN-TensorBoard/</url>
      
        <content type="html"><![CDATA[<h1 id="Introduction">Introduction</h1><p>I recently enrolled in an AI course, and this is the third assignment. It mainly refers to the following websites:</p><ul><li>Teaching how to build a CNN using PyTorch: <a href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html">Pytorch Tutorial</a></li><li>Teaching how to use TensorBoard with PyTorch: <a href="https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html">Pytorch TensorBoard Tutorial</a></li><li>Tutorial on using TensorBoard in CoLab: <a href="https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks">TensorBoard in CoLab Tutorial</a></li></ul><p>The main purpose of this article is to understand CNNs, try to build a deeper network, use GPU to improve efficiency, and finally display the results of Loss and mispredicted results on TensorBoard.</p><h1 id="Environment-Setup-and-Homework-Requirements">Environment Setup and Homework Requirements</h1><blockquote><p>Environment setup:</p><ul><li>Python 3.10.9</li><li>Pytorch 2.0.1</li></ul></blockquote><h1 id="Homework-Requirements">Homework Requirements</h1><p>Task:</p><ol><li><strong>First build a CNN</strong>: Train the same network as in the PyTorch CNN tutorial.</li><li><strong>Build a CNN that meets the following requirements</strong>: Change the network architecture as follows and train the network:<ol><li>Conv layer with 3x3 kernel and depth = 8, ReLu activation</li><li>Conv layer with 3x3 kernel and depth = 16, ReLu activation</li><li>Max pooling with 2x2 kernel</li><li>Conv layer with 3x3 kernel and depth = 32, ReLu activation</li><li>Conv layer with 3x3 kernel and depth = 64, ReLu activation</li><li>Max pooling with 2x2 kernel</li><li>Fully connected with 4096 nodes, ReLu activation</li><li>Fully connected with 1000 nodes, ReLu activation</li><li>Fully connected with 10 nodes, no activation</li></ol></li><li><strong>Use GPU and compare with CPU results</strong>: Run the training on the GPU and compare the training time to CPU.</li><li><strong>Log Training Loss to TensorBoard</strong>: Log the training loss in TensorBoard.</li><li><strong>Modify the criterion for correctness to include predictions in the top three outputs</strong>: Change the test metric as follows: A prediction is considered „correct“ if the true label is within the top three outputs of the network. Print the accuracy on the test data (with respect to this new definition).</li><li><strong>Randomly select five examples of incorrect predictions and display them on TensorBoard</strong>: Randomly take 5 examples on which the network was wrong on the test data (according to the new definition of correct) and plot them to TensorBoard together with the true label.</li><li><strong>Display TensorBoard in the notebook</strong>: Show the TensorBoard widget at the end of your notebook.</li></ol><ul><li><strong>Bonus</strong>: See if you can improve results by using a deeper network (or another architecture).</li></ul><h1 id="Preliminary-Preparation">Preliminary Preparation</h1><ol><li>First, load the necessary packages</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># Store the TensorBoard results in ./board/assignment_3</span></span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;./board/result&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Download the training and testing datasets into a `/data` folder created in the current directory. To normalize, set the mean to 0.5 and the standard deviation to 0.5, indicating that the image range is between [0, 1] and is converted to [-1, 1].</span></span><br><span class="line">```python</span><br><span class="line"><span class="comment"># Define image transformation, converting images to tensors and normalizing them</span></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),  <span class="comment"># Convert images to PyTorch tensors</span></span><br><span class="line">    <span class="comment"># Since each pixel has three channels (red, green, blue) and channel values are typically in the [0, 1] range.</span></span><br><span class="line">    <span class="comment"># We normalize these three channels to bring their range to [-1, 1].</span></span><br><span class="line">    <span class="comment"># Since the mean of [0,1] is 0.5, setting mean to 0.5 means subtracting the mean of 0.5 to shift the original mean from 0.5 to 0</span></span><br><span class="line">    <span class="comment"># Since the standard deviation of [0,1] is 0.5, setting std to 0.5 means dividing by the standard deviation of 0.5 to change the original standard deviation from 0.5 to 1</span></span><br><span class="line">    <span class="comment"># Finally, as the mean becomes 0 and standard deviation is 1, we obtain the range [-1,1]</span></span><br><span class="line">    transforms.Normalize(mean=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), std=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))  <span class="comment"># Normalize image data</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define batch size for training</span></span><br><span class="line">batch_size = <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Download and load the CIFAR-10 training dataset</span></span><br><span class="line">trainset = torchvision.datasets.CIFAR10(</span><br><span class="line">    root=<span class="string">&#x27;./data&#x27;</span>,  <span class="comment"># Root directory for storing data</span></span><br><span class="line">    train=<span class="literal">True</span>,  <span class="comment"># Load training data</span></span><br><span class="line">    download=<span class="literal">True</span>,  <span class="comment"># Download data (if not already downloaded)</span></span><br><span class="line">    transform=transform  <span class="comment"># Apply previously defined image transformation</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a DataLoader for the training data for batch processing and data loading</span></span><br><span class="line">trainloader = torch.utils.data.DataLoader(</span><br><span class="line">    trainset,</span><br><span class="line">    batch_size=batch_size,  <span class="comment"># Set the size of each batch</span></span><br><span class="line">    shuffle=<span class="literal">True</span>,  <span class="comment"># Randomly shuffle data to increase the randomness of training</span></span><br><span class="line">    num_workers=<span class="number">2</span>  <span class="comment"># Use multiple worker processes to speed up data loading</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Download and load the CIFAR-10 test dataset, with the same data transformation and data loading settings</span></span><br><span class="line">testset = torchvision.datasets.CIFAR10(</span><br><span class="line">    root=<span class="string">&#x27;./data&#x27;</span>,</span><br><span class="line">    train=<span class="literal">False</span>,  <span class="comment"># Load test data</span></span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=transform</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a DataLoader for the test data</span></span><br><span class="line">testloader = torch.utils.data.DataLoader(</span><br><span class="line">    testset,</span><br><span class="line">    batch_size=batch_size,</span><br><span class="line">    shuffle=<span class="literal">False</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Place all class names in a tuple</span></span><br><span class="line">classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br></pre></td></tr></table></figure><h1 id="Task-1-2-Build-a-CNN">Task 1+2 Build a CNN</h1><div class="note info flat"><ol><li><strong>First build a CNN</strong>: Train the same network as in the PyTorch CNN tutorial.</li><li><strong>Build a CNN that meets the following requirements</strong>: Change the network architecture as follows and train the network.</li></ol></div><h2 id="Build-a-CNN">Build a CNN</h2><p><strong>Task 2. Build a CNN that meets the following requirements</strong>: Change the network architecture as follows and train the network:</p><ol><li>Conv layer with 3x3 kernel and depth = 8, ReLu activation</li><li>Conv layer with 3x3 kernel and depth = 16, ReLu activation</li><li>Max pooling with 2x2 kernel</li><li>Conv layer with 3x3 kernel and depth = 32, ReLu activation</li><li>Conv layer with 3x3 kernel and depth = 64, ReLu activation</li><li>Max pooling with 2x2 kernel</li><li>Fully connected with 4096 nodes, ReLu activation</li><li>Fully connected with 1000 nodes, ReLu activation</li><li>Fully connected with 10 nodes, no activation</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NewNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(NewNet, self).__init__()</span><br><span class="line">        <span class="comment"># The input is the depth of the previous layer, which is the color 3 RGB, 32*32 pixel</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">8</span>, <span class="number">3</span>)  <span class="comment"># Layer 1: 3x3 kernel and depth = 8</span></span><br><span class="line">        <span class="comment"># The input is the depth of the previous layer, which is the requested 8, 32-3+1=30, thus 30*30 pixel</span></span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">8</span>, <span class="number">16</span>, <span class="number">3</span>)  <span class="comment"># Layer 2: 3x3 kernel and depth = 16</span></span><br><span class="line">        <span class="comment"># 30/2=15, thus 15*15 pixel</span></span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)  <span class="comment"># Layer 3: Max pooling with 2x2 kernel</span></span><br><span class="line">        <span class="comment"># The input is the depth of the previous layer, which is the requested 16, 15-3+1=13, thus 13*13 pixel</span></span><br><span class="line">        self.conv3 = nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, <span class="number">3</span>)  <span class="comment"># Layer 4: 3x3 kernel and depth = 32</span></span><br><span class="line">        <span class="comment"># The input is the depth of the previous layer, which is the requested 32, 13-3+1=11, thus 11*11 pixel</span></span><br><span class="line">        self.conv4 = nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">3</span>)  <span class="comment"># Layer 5: 3x3 kernel and depth = 64</span></span><br><span class="line">        <span class="comment"># Another Max pooling is needed, 11/2=5, thus 5*5 pixel</span></span><br><span class="line">        <span class="comment"># Therefore, the final input is 64, and the pixel is 5*5, hence 64*5*5</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">64</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">4096</span>)  <span class="comment"># Layer 6: Fully connected with 4096 nodes</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">4096</span>, <span class="number">1000</span>)  <span class="comment"># Layer 7: Fully connected with 1000 nodes</span></span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">1000</span>, <span class="number">10</span>)  <span class="comment"># Layer 8: Fully connected with 10 nodes</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.conv1(x))  <span class="comment"># ReLu activation</span></span><br><span class="line">        x = F.relu(self.conv2(x))</span><br><span class="line">        x = self.pool(x)</span><br><span class="line">        x = F.relu(self.conv3(x))</span><br><span class="line">        x = F.relu(self.conv4(x))</span><br><span class="line">        x = self.pool(x)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">64</span> * <span class="number">5</span> * <span class="number">5</span>)  <span class="comment"># Flatten the tensor</span></span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h1 id="Task-3-4-GPU-and-Loss-on-TensorBoard">Task 3 + 4 GPU and Loss on TensorBoard</h1><div class="note info flat"><ol start="3"><li><strong>Use GPU and Compare CPU Results</strong>: Run the training on the GPU and compare the training time to CPU.</li><li><strong>Log Training Loss on TensorBoard</strong>: Log the training loss in TensorBoard.</li></ol></div><h2 id="Accelerate-Network-Using-GPU">Accelerate Network Using GPU</h2><p>Since I am using a Mac, I input <code>mps</code>, but if you are using a Windows system, please input <code>cuda</code>.<br>Initialize function and optimizer.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># device = torch.device(&quot;cuda&quot; if torch.backends.mps.is_available() else &quot;cpu&quot;)</span></span><br><span class="line">device = torch.device(<span class="string">&quot;mps&quot;</span> <span class="keyword">if</span> torch.backends.mps.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">net = NewNet()</span><br><span class="line">net.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Let&#x27;s use a Classification Cross-Entropy loss and SGD with momentum.</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><h2 id="Build-Training-Model">Build Training Model</h2><p>Start writing the training model, and log the results to TensorBoard.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">start_time = time.time()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):  <span class="comment"># loop over the dataset multiple times</span></span><br><span class="line"></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainloader, <span class="number">0</span>):</span><br><span class="line">        <span class="comment"># get the inputs; data is a list of [inputs, labels]</span></span><br><span class="line">        <span class="comment"># inputs, labels = data, put the inputs and labels on the device (cpu or gpu) </span></span><br><span class="line">        inputs, labels = data[<span class="number">0</span>].to(device), data[<span class="number">1</span>].to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># zero the parameter gradients</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward + backward + optimize</span></span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        outputs.to(device)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.to(device)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">200</span> == <span class="number">199</span>:    <span class="comment"># print every 2000 mini-batches</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;[<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>, <span class="subst">&#123;i + <span class="number">1</span>:5d&#125;</span>] loss: <span class="subst">&#123;running_loss / <span class="number">200</span>:<span class="number">.3</span>f&#125;</span> time elapsed: <span class="subst">&#123;<span class="built_in">round</span>((time.time() - start_time) / <span class="number">60</span>)&#125;</span> min&#x27;</span>)</span><br><span class="line">            <span class="comment"># ...log the running loss</span></span><br><span class="line">            <span class="comment"># put the loss into tensorBoard, because it only writes every 200, so / 200 is the real loss </span></span><br><span class="line">            writer.add_scalar(<span class="string">&#x27;training loss&#x27;</span>,</span><br><span class="line">                            running_loss / <span class="number">200</span>,</span><br><span class="line">                            epoch * <span class="built_in">len</span>(trainloader) + i)</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># calculate the total time for training, and round it to 1 decimal place </span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Finished Training. Total elapsed time: <span class="subst">&#123;<span class="built_in">round</span>((time.time() - start_time) / <span class="number">60</span>, <span class="number">1</span>)&#125;</span> min&#x27;</span>)</span><br></pre></td></tr></table></figure><blockquote><p>Result</p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1</span>,  <span class="number">3600</span>] loss: <span class="number">1.977</span> <span class="built_in">time</span> elapsed: <span class="number">1</span> <span class="built_in">min</span></span><br><span class="line">[<span class="number">1</span>,  <span class="number">3800</span>] loss: <span class="number">2.021</span> <span class="built_in">time</span> elapsed: <span class="number">1</span> <span class="built_in">min</span></span><br><span class="line">[<span class="number">1</span>,  <span class="number">4000</span>] loss: <span class="number">1.933</span> <span class="built_in">time</span> elapsed: <span class="number">1</span> <span class="built_in">min</span></span><br><span class="line">[<span class="number">1</span>,  <span class="number">4200</span>] loss: <span class="number">1.922</span> <span class="built_in">time</span> elapsed: <span class="number">1</span> <span class="built_in">min</span></span><br><span class="line">[<span class="number">1</span>,  <span class="number">4400</span>] loss: <span class="number">1.902</span> <span class="built_in">time</span> elapsed: <span class="number">1</span> <span class="built_in">min</span></span><br><span class="line">[<span class="number">1</span>,  <span class="number">4600</span>] loss: <span class="number">1.836</span> <span class="built_in">time</span> elapsed: <span class="number">1</span> <span class="built_in">min</span></span><br><span class="line">[<span class="number">1</span>,  <span class="number">4800</span>] loss: <span class="number">1.788</span> <span class="built_in">time</span> elapsed: <span class="number">1</span> <span class="built_in">min</span></span><br><span class="line">[<span class="number">1</span>,  <span class="number">5000</span>] loss: <span class="number">1.818</span> <span class="built_in">time</span> elapsed: <span class="number">1</span> <span class="built_in">min</span></span><br><span class="line">...</span><br><span class="line">[<span class="number">1</span>, <span class="number">12000</span>] loss: <span class="number">1.479</span> <span class="built_in">time</span> elapsed: <span class="number">2</span> <span class="built_in">min</span></span><br><span class="line">[<span class="number">1</span>, <span class="number">12200</span>] loss: <span class="number">1.469</span> <span class="built_in">time</span> elapsed: <span class="number">2</span> <span class="built_in">min</span></span><br><span class="line">[<span class="number">1</span>, <span class="number">12400</span>] loss: <span class="number">1.485</span> <span class="built_in">time</span> elapsed: <span class="number">2</span> <span class="built_in">min</span></span><br><span class="line">Finished Training. Total elapsed <span class="built_in">time</span>: <span class="number">2.2</span> <span class="built_in">min</span></span><br></pre></td></tr></table></figure><p>Then you can write a cpu to compare the time</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Use CPU </span></span><br><span class="line">device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">net.to(device)</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">start_time = time.time()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):  <span class="comment"># loop over the dataset multiple times</span></span><br><span class="line"></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainloader, <span class="number">0</span>):</span><br><span class="line">        <span class="comment"># get the inputs; data is a list of [inputs, labels]</span></span><br><span class="line">        <span class="comment"># inputs, labels = data, put the inputs and labels on the device (cpu or gpu)</span></span><br><span class="line">        inputs, labels = data[<span class="number">0</span>].to(device), data[<span class="number">1</span>].to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># zero the parameter gradients</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward + backward + optimize</span></span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        outputs.to(device)</span><br><span class="line"></span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.to(device) </span><br><span class="line">        loss.backward() </span><br><span class="line"></span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">200</span> == <span class="number">199</span>:    <span class="comment"># print every 2000 mini-batches</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;[<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>, <span class="subst">&#123;i + <span class="number">1</span>:5d&#125;</span>] loss: <span class="subst">&#123;running_loss / <span class="number">2000</span>:<span class="number">.3</span>f&#125;</span> time elapsed: <span class="subst">&#123;<span class="built_in">round</span>((time.time() - start_time) / <span class="number">60</span>)&#125;</span> min&#x27;</span>)</span><br><span class="line">            </span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Finished Training. Total elapsed time: <span class="subst">&#123;<span class="built_in">round</span>((time.time() - start_time) / <span class="number">60</span>, <span class="number">1</span>)&#125;</span> min&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://i.imgur.com/GW04dzw.png" alt=""></p><h2 id="Save-Training-Results">Save Training Results</h2><p>I am currently saving the model in <code>./model/cifar_net.pth</code>, and then reading it back later, so that I don’t have to retrain next time.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PATH = <span class="string">&#x27;./model/cifar_net.pth&#x27;</span></span><br><span class="line">torch.save(net.state_dict(), PATH)</span><br><span class="line">net = NewNet()</span><br><span class="line">net.load_state_dict(torch.load(PATH)) <span class="comment"># load the weights from the saved file</span></span><br></pre></td></tr></table></figure><h2 id="Evaluate-the-Model-Using-Test-Data">Evaluate the Model Using Test Data</h2><div class="note info flat"><p><strong>Task 5. Modify the Criterion for Correctness to Include Predictions in the Top Three Outputs</strong>: Change the test metric as follows: A prediction is considered „correct“ if the true label is within the top three outputs of the network. Print the accuracy on the test data (with respect to this new definition).</p></div><p>According to the assignment requirements, we need to do the following:</p><ol><li>TODO 1 Adjust the definition of accuracy to consider a prediction correct if the answer is among the top three outputs.</li><li>TODO 2 Print the accuracy, here I print out the accuracy “for each category” and “overall accuracy.”</li><li>TODO 3 Since we need to record the wrong images, outputs, and labels, we first record them and then randomly select five wrong ones for later use.</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">correct = <span class="number">0</span></span><br><span class="line">total = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">class_correct = [<span class="number">0</span>] * <span class="built_in">len</span>(classes)  <span class="comment"># Used to record the number of correct predictions for each class</span></span><br><span class="line">class_total = [<span class="number">0</span>] * <span class="built_in">len</span>(classes)    <span class="comment"># Used to record the total number of samples for each class</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Used to store all the misclassified images, outputs, and labels</span></span><br><span class="line">all_errors = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># Since we are not training, we don&#x27;t need to compute gradients of the outputs</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">        images, labels = data </span><br><span class="line">        outputs = net(images) </span><br><span class="line"></span><br><span class="line">        <span class="comment"># We use _, predicted because we don&#x27;t need the values, but we need the indices of the results</span></span><br><span class="line">        _, predicted = torch.topk(outputs, <span class="number">3</span>, dim=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Since testloader is a batch, we need to loop through individual samples (in this case, 4 samples)</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(labels)):</span><br><span class="line">            <span class="comment"># Example Print out =&gt; Predicted: tensor([3, 5, 2]) Actual: 3 Correct: True</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;Predicted: <span class="subst">&#123;predicted[i]&#125;</span> Actual: <span class="subst">&#123;labels[i]&#125;</span> \t Correct: <span class="subst">&#123;labels[i] <span class="keyword">in</span> predicted[i]&#125;</span>&#x27;</span>)</span><br><span class="line">            total += <span class="number">1</span></span><br><span class="line">            <span class="comment"># Increment class_total for the class with key labels[i]</span></span><br><span class="line">            class_total[labels[i]] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Check if labels[i] is in predicted[i] since labels has four values, we use i to access them</span></span><br><span class="line">            <span class="keyword">if</span> labels[i] <span class="keyword">in</span> predicted[i]:</span><br><span class="line">                correct += <span class="number">1</span></span><br><span class="line">                class_correct[labels[i]] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># Record the misclassified image, output, and label</span></span><br><span class="line">                all_errors.append((images[i], outputs[i], labels[i]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate the accuracy for each class</span></span><br><span class="line">class_accuracies = [class_correct[i] / class_total[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(classes))]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate and print the new overall accuracy</span></span><br><span class="line">accuracy = correct / total</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>Result</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Predicted: tensor([3, 5, 2]) Actual: 3  Correct: True</span><br><span class="line">Predicted: tensor([8, 0, 1]) Actual: 8  Correct: True</span><br><span class="line">Predicted: tensor([8, 1, 9]) Actual: 8  Correct: True</span><br><span class="line">Predicted: tensor([8, 0, 1]) Actual: 0  Correct: True</span><br><span class="line">Predicted: tensor([4, 2, 6]) Actual: 6  Correct: True</span><br><span class="line">Predicted: tensor([6, 3, 5]) Actual: 6  Correct: True</span><br><span class="line">Predicted: tensor([1, 9, 5]) Actual: 1  Correct: True</span><br><span class="line">Predicted: tensor([2, 6, 4]) Actual: 6  Correct: True</span><br><span class="line">Predicted: tensor([3, 5, 2]) Actual: 3  Correct: True</span><br><span class="line">Predicted: tensor([1, 8, 9]) Actual: 1  Correct: True</span><br><span class="line">...</span><br><span class="line">Predicted: tensor([5, 7, 2]) Actual: 5  Correct: True</span><br><span class="line">Predicted: tensor([4, 2, 3]) Actual: 1  Correct: False</span><br><span class="line">Predicted: tensor([7, 4, 2]) Actual: 7  Correct: True</span><br></pre></td></tr></table></figure><h2 id="Print-Accuracy">Print Accuracy</h2><p>Now we can print the accuracy. We can see that the accuracy is 0.1 because we have only 10 classes, so the random guessing accuracy is 0.1.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Accuracy on test data (top-3): <span class="subst">&#123;<span class="number">100</span> * accuracy:<span class="number">.2</span>f&#125;</span>%&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print each class accuracy</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(classes)):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Accuracy for class <span class="subst">&#123;classes[i]&#125;</span>: <span class="subst">&#123;<span class="number">100</span> * class_accuracies[i]:<span class="number">.2</span>f&#125;</span>%&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print the number of misclassified images</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Total misclassified images: <span class="subst">&#123;<span class="built_in">len</span>(all_errors)&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><blockquote><p>Result</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Accuracy on test data (top-3): 91.60%</span><br><span class="line">Accuracy for class plane: 89.50%</span><br><span class="line">Accuracy for class car: 96.30%</span><br><span class="line">Accuracy for class bird: 85.20%</span><br><span class="line">Accuracy for class cat: 91.80%</span><br><span class="line">Accuracy for class deer: 92.40%</span><br><span class="line">Accuracy for class dog: 91.40%</span><br><span class="line">Accuracy for class frog: 88.30%</span><br><span class="line">Accuracy for class horse: 91.50%</span><br><span class="line">Accuracy for class ship: 96.20%</span><br><span class="line">Accuracy for class truck: 93.40%</span><br><span class="line"></span><br><span class="line">Total misclassified images: 840</span><br></pre></td></tr></table></figure><h1 id="Task-6-Random-5-errors-img">Task 6 Random 5 errors img</h1><div class="note info flat"><p><strong>Task 6. Randomly select five examples that were incorrectly predicted by the model and display them in TensorBoard</strong>:<br>Randomly take 5 examples on which the network was wrong on the test data (according to the new definition of correct) and plot them to TensorBoard together with the true label.</p></div><h2 id="Setting-up-the-Image-Transformation-Function">Setting up the Image Transformation Function</h2><p>In order to display the images later, we need to create a function for displaying images. Since the output of torchvision datasets is PILImage images with a range of [0, 1], we need to convert them to tensors with a normalized range of [-1, 1]. If we want to display the images, we need to perform the reverse normalization to go from the normalized range [-1, 1] back to [0, 1]. We can achieve this using the formula <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>x</mi><mn>2</mn></mfrac><mo>+</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\frac{x}{2} + 0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0404em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6954em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.5</span></span></span></span>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Functions to show an image</span></span><br><span class="line"><span class="comment"># If one_channel is True, the function assumes the input image is single-channel (usually grayscale) and displays it using a grayscale colormap.</span></span><br><span class="line"><span class="comment"># If one_channel is False, the function assumes the input image is three-channel (usually color) and displays it using a color colormap.</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matplotlib_imshow</span>(<span class="params">img, one_channel=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="keyword">if</span> one_channel:</span><br><span class="line">        img = img.mean(dim=<span class="number">0</span>)</span><br><span class="line">    img = img / <span class="number">2</span> + <span class="number">0.5</span>     <span class="comment"># unnormalize</span></span><br><span class="line">    npimg = img.numpy()</span><br><span class="line">    <span class="keyword">if</span> one_channel: </span><br><span class="line">        plt.imshow(npimg, cmap=<span class="string">&quot;Greys&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># Because the function used by matplotlib expects input as (height_1, depth_2, width_0)</span></span><br><span class="line">        <span class="comment"># while npimg defaults to (width_0, height_1, depth=RGB color_2)</span></span><br><span class="line">        <span class="comment"># We need to use np.transpose to change the channel order from (width_0, height_1, depth=RGB color_2) to (height_1, depth_2, width_0)</span></span><br><span class="line">        plt.imshow(np.transpose(npimg, (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)))</span><br></pre></td></tr></table></figure><h2 id="Randomly-Select-5-Errors">Randomly Select 5 Errors</h2><p>We have just collected all the images, predictions, and labels for errors. According to the task requirements, we need to randomly select 5 images with incorrect predictions and print them out.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_classes_preds</span>(<span class="params">all_errors</span>):</span><br><span class="line">    <span class="comment"># Randomly select five misclassified images</span></span><br><span class="line">    random_errors = random.sample(all_errors, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create a large matplotlib figure, the figsize parameter is used to specify the width and height of the figure in inches</span></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">12</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> idx, (image, output, label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(random_errors):</span><br><span class="line">        <span class="comment"># Parameters indicate: number of rows, number of columns, subplot index (starting from 1, placing five images in a 12-inch by 18-inch figure)</span></span><br><span class="line">        <span class="comment"># xticks and yticks are used to set coordinate parameters; if you don&#x27;t want to display coordinates, you can set them as empty lists</span></span><br><span class="line">        ax = fig.add_subplot(<span class="number">1</span>, <span class="number">5</span>, idx+<span class="number">1</span>, xticks=[], yticks=[])</span><br><span class="line">        <span class="comment"># Display the color image</span></span><br><span class="line">        matplotlib_imshow(image, one_channel=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># Since output is a 1x10 tensor, we use dim=0 to extract the top 3 columns</span></span><br><span class="line">        preds = torch.topk(output, <span class="number">3</span>, dim=<span class="number">0</span>).indices  <span class="comment"># See the explanation regarding dim in the notes</span></span><br><span class="line">        pred_classes = [classes[p] <span class="keyword">for</span> p <span class="keyword">in</span> preds] <span class="comment"># Convert indices to class names and store them in a list (there will be three strings)</span></span><br><span class="line">        <span class="comment"># Set the title for the current image, displaying the predicted class and the actual class</span></span><br><span class="line">        ax.set_title(<span class="string">&quot;\n(label: &#123;0&#125;)\n(&#123;1&#125;)&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">            classes[label],</span><br><span class="line">            <span class="string">&quot;, &quot;</span>.join(pred_classes)),</span><br><span class="line">            color=<span class="string">&quot;red&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Finally, return the entire set of prepared figures (there will be a total of 5 images)</span></span><br><span class="line">    <span class="keyword">return</span> fig</span><br><span class="line"></span><br><span class="line"><span class="comment"># Call the function</span></span><br><span class="line">plot_classes_preds(all_errors)</span><br></pre></td></tr></table></figure><blockquote><p>Result<br><img src="https://i.imgur.com/OY6EvGW.png" alt=""></p></blockquote><h2 id="Put-the-image-into-tensorBoard">Put the image into tensorBoard</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># put on tensorBoard</span></span><br><span class="line">fig = plot_classes_preds(all_errors)</span><br><span class="line">writer.add_figure(<span class="string">&quot;predictions vs. actuals&quot;</span>, fig)</span><br></pre></td></tr></table></figure><h1 id="Task-7-Show-tensorBoard-on-notebook">Task 7 Show tensorBoard on notebook</h1><div class="note info flat"><ol start="7"><li><strong>Display TensorBoard in the notebook</strong>: Show the TensorBoard widget at the end of your notebook.</li></ol></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Displaying TensorBoard in the notebook</span></span><br><span class="line">%load_ext tensorboard <span class="comment"># This line of code loads the TensorBoard extension so that you can run TensorBoard within the notebook.</span></span><br><span class="line">%tensorboard --logdir board <span class="comment"># This line of code starts TensorBoard and points it to your log folder.</span></span><br></pre></td></tr></table></figure><h1 id="Supplementary-Information">Supplementary Information</h1><h2 id="Normalization-vs-Standardization">Normalization vs. Standardization</h2><ul><li>Ref: <a href="https://medium.com/ai%E5%8F%8D%E6%96%97%E5%9F%8E/preprocessing-data-%E6%95%B8%E6%93%9A%E7%89%B9%E5%BE%B5%E6%A8%99%E6%BA%96%E5%8C%96%E5%92%8C%E6%AD%B8%E4%B8%80%E5%8C%96-9bd3e5a8f2fc">Preprocessing Data: Data Feature Normalization and Standardization</a></li></ul><blockquote><p><strong>Normalization vs. Standardization: What’s the Difference?</strong></p></blockquote><ul><li><code>Normalization</code>: Scaling data proportionally to fit into a small specific range, such as [0, 1] or [-1, 1].<ul><li>Formula: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><mi>m</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>m</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{x_i - min(x_i)}{max(x_i) - min(x_i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.53em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ma</span><span class="mord mathnormal mtight">x</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">min</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">min</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li></ul></li><li><code>Standardization</code>: Scaling data proportionally to fit into a distribution with a mean of 0 and a standard deviation of 1, so extreme values may not fall within [0, 1].<ul><li>Formula: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><mi>μ</mi></mrow><mrow><mi>s</mi><mi>d</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{x_i - \mu}{sd(x)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3744em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8544em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">d</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">μ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li></ul></li></ul><blockquote><p><strong>Common Standards for Both</strong></p></blockquote><ul><li>Both techniques scale individual features (columns) and not the feature vectors of individual samples (rows).</li></ul><blockquote><p><strong>Why Normalize Data?</strong></p></blockquote><ol><li><strong>Improved Precision</strong>: Many machine learning algorithms are based on objective functions that assume all features have zero mean and the same order of magnitude for variances. If the variance of a feature is orders of magnitude larger than that of other features, it will dominate the learning algorithm and prevent it from learning correctly. Therefore, normalization is done to <strong>make different dimensions of features comparable</strong>, significantly improving the classifier’s accuracy.</li><li><strong>Faster Convergence</strong>: After normalization, the process of finding the optimal solution is noticeably smoother, making it easier to converge to the optimal solution.</li></ol><h2 id="dim">dim?</h2><p>The <code>dim</code> parameter in PyTorch determines the dimension along which ranking and obtaining the maximum values occur. Let’s explain the differences using an example:</p><ul><li>If you set <code>dim=0</code>, it will look at the maximum values for the entire column.</li><li>If you set <code>dim=1</code>, it will look at the maximum values for the entire row.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create an example tensor</span></span><br><span class="line">output = torch.tensor([[<span class="number">0.2</span>, <span class="number">0.6</span>, <span class="number">0.9</span>, <span class="number">0.5</span>, <span class="number">0.3</span>],</span><br><span class="line">                       [<span class="number">0.4</span>, <span class="number">0.1</span>, <span class="number">0.8</span>, <span class="number">0.7</span>, <span class="number">0.2</span>],</span><br><span class="line">                       [<span class="number">0.5</span>, <span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">0.1</span>, <span class="number">0.2</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the top 3 maximum values and their indices per column</span></span><br><span class="line">top_values_col, top_indices_col = torch.topk(output, <span class="number">3</span>, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the top 3 maximum values and their indices per row</span></span><br><span class="line">top_values_row, top_indices_row = torch.topk(output, <span class="number">3</span>, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Output tensor:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Top 3 values and indices per column:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(top_values_col)</span><br><span class="line"><span class="built_in">print</span>(top_indices_col)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Top 3 values and indices per row:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(top_values_row)</span><br><span class="line"><span class="built_in">print</span>(top_indices_row)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">Output tensor:</span><br><span class="line">tensor([[<span class="number">0.2000</span>, <span class="number">0.6000</span>, <span class="number">0.9000</span>, <span class="number">0.5000</span>, <span class="number">0.3000</span>],</span><br><span class="line">        [<span class="number">0.4000</span>, <span class="number">0.1000</span>, <span class="number">0.8000</span>, <span class="number">0.7000</span>, <span class="number">0.2000</span>],</span><br><span class="line">        [<span class="number">0.5000</span>, <span class="number">0.8000</span>, <span class="number">0.9000</span>, <span class="number">0.1000</span>, <span class="number">0.2000</span>]])</span><br><span class="line">Top <span class="number">3</span> values <span class="keyword">and</span> indices per column:</span><br><span class="line"><span class="comment"># Already sorted from largest to smallest</span></span><br><span class="line">tensor([[<span class="number">0.5000</span>, <span class="number">0.8000</span>, <span class="number">0.9000</span>, <span class="number">0.7000</span>, <span class="number">0.3000</span>],</span><br><span class="line">        [<span class="number">0.4000</span>, <span class="number">0.6000</span>, <span class="number">0.9000</span>, <span class="number">0.5000</span>, <span class="number">0.2000</span>],</span><br><span class="line">        [<span class="number">0.2000</span>, <span class="number">0.1000</span>, <span class="number">0.8000</span>, <span class="number">0.1000</span>, <span class="number">0.2000</span>]])</span><br><span class="line"><span class="comment"># Printing the indices in each column from largest to smallest. For example, in the first column (0.2, 0.4, 0.5), 0.5 is the largest,</span></span><br><span class="line"><span class="comment"># so the indices in order are 2, 1, 0. This is why you see [[2...], [1...], [0...]] in the output.</span></span><br><span class="line">tensor([[<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>], </span><br><span class="line">        [<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>]])</span><br><span class="line">Top <span class="number">3</span> values <span class="keyword">and</span> indices per row:</span><br><span class="line"><span class="comment"># Already sorted from largest to smallest</span></span><br><span class="line">tensor([[<span class="number">0.9000</span>, <span class="number">0.6000</span>, <span class="number">0.5000</span>],</span><br><span class="line">        [<span class="number">0.8000</span>, <span class="number">0.7000</span>, <span class="number">0.4000</span>],</span><br><span class="line">        [<span class="number">0.9000</span>, <span class="number">0.8000</span>, <span class="number">0.5000</span>]])</span><br><span class="line"><span class="comment"># Printing the indices in each row from largest to smallest. For example, in the first row (0.2, 0.6, 0.9, 0.5, 0.3),</span></span><br><span class="line"><span class="comment"># 0.9 is the largest, so the indices in order are 2, 1, 3. This is why you see [[2, 1, 3] in the output.</span></span><br><span class="line">tensor([[<span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">3</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>]])</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Code </category>
          
          <category> Mechine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mechine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Titanic Dataset - Building a Neural Network with PyTorch + Testing for Overfitting</title>
      <link href="/en/posts/pytorch-titanic-nn/"/>
      <url>/en/posts/pytorch-titanic-nn/</url>
      
        <content type="html"><![CDATA[<h1 id="Reference">Reference</h1><ul><li>Ref: <a href="https://towardsdatascience.com/predicting-the-survival-of-titanic-passengers-30870ccc7e8">A Detailed Explanation of the Titanic Dataset Structure</a></li></ul><h1 id="Introduction">Introduction</h1><p>Recently, I enrolled in an AI course that included an assignment to build a Neural Network and use the Titanic Dataset for training. The task was to implement overfitting by increasing hidden layers and neurons and then mitigate overfitting using dropout or other methods.</p><p>This article documents the process of completing the assignment.</p><h1 id="Environment-Setup-and-Assignment-Requirements">Environment Setup and Assignment Requirements</h1><blockquote><p>Environment Setup:</p><ul><li>Python 3.10.9</li><li>PyTorch 2.0.1</li></ul></blockquote><h2 id="Assignment-Requirements">Assignment Requirements</h2><ol><li>Write a custom <strong>dataset class for the Titanic data</strong> (see the data folder on <a href="https://github.com/pabair/ki-lab-ss23">GitHub</a>). Use only the features: “Pclass,” “Age,” “SibSp,” “Parch,” “Fare,” “Sex,” and “Embarked.” <strong>Preprocess the features</strong> accordingly in that class (scaling, one-hot-encoding, etc.), and split the data into train and validation data (80% and 20%). The constructor of that class should look like this: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">titanic_train = TitanicDataSet(<span class="string">&#x27;titanic.csv&#x27;</span>, train=<span class="literal">True</span>)</span><br><span class="line">titanic_val = TitanicDataSet(<span class="string">&#x27;titanic.csv&#x27;</span>, train=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></li><li>Build a neural network with <strong>one hidden layer of size 3</strong> that predicts the survival of the passengers. Use a <strong>BCE loss</strong> (Hint: you need a <strong>sigmoid activation</strong> in the output layer). Use a data loader to train in batches of <strong>size 16</strong> and shuffle the data.</li><li><strong>Evaluate the performance</strong> of the model on the validation data using accuracy as a metric.</li><li><strong>Create the following plot</strong> that was introduced in the lecture.<ul><li><img src="https://i.imgur.com/yPNS7vc.png?x300" alt=""></li></ul></li><li>Increase the complexity of the network by <strong>adding more layers and neurons</strong> and see if you can overfit on the training data.</li><li>Try to remove overfitting by introducing a <strong><a href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html">dropout</a> layer</strong>.</li></ol><h2 id="In-Simple-Terms">In Simple Terms</h2><p>In simple terms, we will satisfy the above requirements through the following four steps:</p><ol><li><p><strong>Data Preprocessing</strong></p><ul><li><code>Task 1</code>: Build a class and import Titanic data.</li><li><code>Task 1</code>: Select specific columns as training features.</li><li><code>Task 1</code>: Data preprocessing (scaling, one-hot encoding, etc.) to convert non-numeric columns like “Sex” or “Embarked” into numeric values.</li><li><code>Task 1</code>: Split the data into train and validation data (80% and 20%).</li><li><code>Task 1</code>: Create a class and import the data.</li></ul></li><li><p><strong>Build a Neural Network</strong></p><ul><li><code>Task 2</code>: Build a three-layer network (1 input layer + 1 hidden layer + 1 output layer).</li><li><code>Task 2</code>: The size of the first hidden layer is 3.</li><li><code>Task 2</code>: Use BCE loss as the loss function.</li><li><code>Task 2</code>: Use sigmoid activation as the output layer’s activation function.</li></ul></li><li><p><strong>Model Training</strong></p><ul><li><code>Task 3</code>: Start training the model and record accuracy at each step.</li></ul></li><li><p><strong>Generate Results</strong></p><ul><li><code>Task 4</code>: Generate results and create plots.</li></ul></li><li><p><strong>Create Overfitting</strong></p><ul><li><code>Task 5</code>: Increase hidden layers and neurons to induce overfitting.</li></ul></li><li><p><strong>Use Dropout</strong></p><ul><li><code>Task 6</code>: Use dropout or other methods to mitigate the impact of overfitting.</li></ul></li></ol><h1 id="Step-1-Data-Preprocessing">Step 1: Data Preprocessing</h1><div class="note info flat"><p>Let’s start with <strong>data preprocessing</strong>:</p><ul><li><code>Task 1</code>: Build a class and import Titanic data.</li><li><code>Task 1</code>: Select specific columns as training features.</li><li><code>Task 1</code>: Data preprocessing (scaling, one-hot encoding, etc.) to convert non-numeric columns like “Sex” or “Embarked” into numeric values.</li><li><code>Task 1</code>: Split the data into train data and validation data (80% and 20%).</li><li><code>Task 1</code>: Create a class and import the data.</li></ul></div><h2 id="1-1-Data-Preprocessing">1.1 Data Preprocessing</h2><ol><li><p>First, we’ll import all the necessary packages.</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># data process </span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io, transform</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, utils</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot </span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># neural network </span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># preprocessing</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler,OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.ion()   <span class="comment"># interactive mode</span></span><br></pre></td></tr></table></figure></li><li><p>Before we start, I’d like to place all the parameters we’ll use at the top for easier modification:</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Shared variables</span></span><br><span class="line">D_in, D_out = <span class="number">10</span>, <span class="number">1</span> </span><br><span class="line">num_epochs = <span class="number">250</span> </span><br><span class="line">log_interval = <span class="number">100</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># Batch size: the amount of data for each training iteration</span></span><br><span class="line">batch_size = <span class="number">30</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Learning rate: Since we will create two different networks, we set two different learning rates</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line">multi_learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Hidden layers</span></span><br><span class="line">multi_num_layers = <span class="number">6</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Hidden neurons: Since we will create two different networks, we set two different numbers of hidden neurons</span></span><br><span class="line">neurons = <span class="number">3</span> </span><br><span class="line">multi_neurons = <span class="number">1024</span> </span><br></pre></td></tr></table></figure></li><li><p>Next, we’ll create a class based on the requirements and load the Titanic data, returning features:</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TitanicDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialization function for loading and preprocessing data</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root_dir, train=<span class="literal">True</span>, transform=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># The train parameter indicates whether it&#x27;s training data or test data</span></span><br><span class="line">        self.train = train</span><br><span class="line">        <span class="comment"># The transform parameter is used to define a transformation function if needed</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Create MinMaxScaler and OneHotEncoder for data preprocessing</span></span><br><span class="line">        minmax_scaler = MinMaxScaler()</span><br><span class="line">        onehot_enc = OneHotEncoder()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Read the Titanic data from the CSV file</span></span><br><span class="line">        titanic = pd.read_csv(root_dir)</span><br><span class="line">        <span class="comment"># Select specific columns from the data</span></span><br><span class="line">        titanic = titanic[[<span class="string">&quot;Pclass&quot;</span>, <span class="string">&quot;Age&quot;</span>, <span class="string">&quot;SibSp&quot;</span>, <span class="string">&quot;Parch&quot;</span>, <span class="string">&quot;Fare&quot;</span>, <span class="string">&quot;Sex&quot;</span>, <span class="string">&quot;Embarked&quot;</span>, <span class="string">&quot;Survived&quot;</span>]]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Fill missing values in the &quot;Age&quot; column with the mean and drop rows with missing values</span></span><br><span class="line">        titanic[<span class="string">&quot;Age&quot;</span>] = titanic[<span class="string">&quot;Age&quot;</span>].fillna(titanic[<span class="string">&quot;Age&quot;</span>].mean())</span><br><span class="line">        titanic = titanic.dropna()</span><br><span class="line">        titanic = titanic.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Split the data into categorical features, numerical features, and labels</span></span><br><span class="line">        categorical_features = titanic[titanic.select_dtypes(include=[<span class="string">&#x27;object&#x27;</span>]).columns.tolist()]</span><br><span class="line">        numerical_features = titanic[titanic.select_dtypes(exclude=[<span class="string">&#x27;object&#x27;</span>]).columns].drop(<span class="string">&#x27;Survived&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">        label_features = titanic[<span class="string">&#x27;Survived&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Normalize numerical features (MinMax scaling)</span></span><br><span class="line">        numerical_features_arr = minmax_scaler.fit_transform(numerical_features)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Perform one-hot encoding on categorical features</span></span><br><span class="line">        categorical_features_arr = onehot_enc.fit_transform(categorical_features).toarray()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Merge the normalized numerical features and one-hot encoded categorical features into one dataset</span></span><br><span class="line">        combined_features = pd.DataFrame(data=numerical_features_arr, columns=numerical_features.columns)</span><br><span class="line">        combined_features = pd.concat([combined_features, pd.DataFrame(data=categorical_features_arr)], axis=<span class="number">1</span>)</span><br><span class="line">        combined_features = pd.concat([combined_features, label_features], axis=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Split the dataset into training and test sets</span></span><br><span class="line">        train_data, test_data = train_test_split(combined_features, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Choose the data to use based on training or testing mode</span></span><br><span class="line">        <span class="keyword">if</span> train:</span><br><span class="line">            self.data = train_data</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.data = test_data</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Return the length of the dataset</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Function for training the neural network, returns features and labels</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="comment"># Get the data from the self.data DataFrame for the idx-th row</span></span><br><span class="line">        sample = self.data.iloc[idx]</span><br><span class="line">        <span class="comment"># Convert a data structure to a PyTorch tensor and specify the data type as float</span></span><br><span class="line">        features = torch.FloatTensor(sample[:-<span class="number">1</span>])</span><br><span class="line">        label = torch.FloatTensor([sample[<span class="string">&#x27;Survived&#x27;</span>]])</span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            features = self.transform(features)</span><br><span class="line">        <span class="keyword">return</span> features, label</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Return the entire dataset as a DataFrame</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getData</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.data</span><br></pre></td></tr></table></figure></li><li><p>After writing the function, you can use the following commands to test it:</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">titanic_train = TitanicDataset(<span class="string">&#x27;./data/titanic.csv&#x27;</span>, train=<span class="literal">True</span>)</span><br><span class="line">titanic_val = TitanicDataset(<span class="string">&#x27;./data/titanic.csv&#x27;</span>, train=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train_dataset len:&#x27;</span>, <span class="built_in">len</span>(titanic_train))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;val_dataset len:&#x27;</span>, <span class="built_in">len</span>(titanic_val))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;total_dataset len:&#x27;</span>, <span class="built_in">len</span>(titanic_train) + <span class="built_in">len</span>(titanic_val))</span><br><span class="line"><span class="comment"># Output </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">train_dataset len: 711</span></span><br><span class="line"><span class="string">val_dataset len: 178</span></span><br><span class="line"><span class="string">total_dataset len: 889</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></li><li><p>可以透過以下程式，列印出以下結果： Or using the following code to print the following results:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">titanic_val.getData()</span><br></pre></td></tr></table></figure></li></ol><p><img src="https://i.imgur.com/d2C0wTF.png" alt=""></p><h1 id="Step2-Building-the-Neural-Network">Step2. Building the Neural Network</h1><ol><li>Next, we will construct the following Neural Network, primarily performing the following tasks:<ul><li><code>__init__</code>: Create a three-layer network (1 input layer + 1 hidden layer + 1 output layer).<ul><li><code>D_in</code>: Neurons size of the input layer.</li><li><code>H</code>: Neurons size of the hidden layer.</li><li><code>D_out</code>: Neurons size of the output layer.</li></ul></li><li><code>forward</code>: The place for performing the forward pass, primarily performing the linear transformation of the first layer with the <code>relu</code> activation function, the linear transformation of the second layer with the <code>sigmoid</code> activation function, and finally returning the prediction.</li></ul> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TwoLayerNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, D_in, H, D_out</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        In the constructor we instantiate two nn.Linear modules and assign them as member variables.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(TwoLayerNet, self).__init__()</span><br><span class="line">        <span class="comment"># the weight and bias of linear1 will be initialized </span></span><br><span class="line">        <span class="comment"># you can access them by self.linear1.weight and self.linear1.bias</span></span><br><span class="line">        self.linear1 = nn.Linear(D_in, H) <span class="comment"># this will create weight, bias for linear1</span></span><br><span class="line">        self.linear2 = nn.Linear(H, D_out) <span class="comment"># this will create weight, bias for linear2</span></span><br><span class="line">        self.sigmoid = nn.Sigmoid() <span class="comment"># Sigmoid activation for binary classification</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        In the forward function we accept a Tensor of input data and we must return a Tensor of output data.</span></span><br><span class="line"><span class="string">        We can use Modules defined in the constructor as well as arbitrary operators on Tensors.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        h_relu = F.relu(self.linear1(x))</span><br><span class="line">        y_pred = self.sigmoid(self.linear2(h_relu))</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br></pre></td></tr></table></figure></li><li>Before training the model, we need to build the neural network. The following code sets the batch size to 16, which means we train with 16 samples at a time. We train on all 889 data points in a single epoch. The input layer has 10 neurons, the hidden layer has 3 neurons, the output layer has 1 neuron, and the learning rate is set to 0.001. We train for a total of 500 epochs.<ul><li>We create the network to construct the neural network.</li><li>We use Adam as the optimizer for gradient descent updates.</li><li>We use Binary Cross-Entropy Loss as the loss function.</li></ul> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">N, D_in, H, D_out = <span class="number">16</span>, <span class="number">10</span>, <span class="number">3</span>, <span class="number">1</span></span><br><span class="line">lr = <span class="number">0.001</span></span><br><span class="line">n_epochs = <span class="number">50</span></span><br><span class="line">log_interval = <span class="number">100</span> <span class="comment"># Print the training status every log_interval epoch</span></span><br><span class="line"></span><br><span class="line">network = TwoLayerNet(D_in, H, D_out)  <span class="comment"># H=3 for one hidden layer with 3 neurons</span></span><br><span class="line">optimizer = optim.Adam(network.parameters(), lr)</span><br><span class="line">criterion = nn.BCELoss() <span class="comment"># Define the loss function as Binary Cross-Entropy Loss</span></span><br></pre></td></tr></table></figure></li></ol><h1 id="Step3-Model-Training">Step3. Model Training</h1><ol><li><p>You can start by creating lists to keep track of the loss and accuracy for each training loop (epoch) of the neural network model during the training process:</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_losses = []  <span class="comment"># Save the loss value of each training loop (epoch) of the neural network model during the training process</span></span><br><span class="line">train_counter = []  <span class="comment"># Save the number of images for training so far</span></span><br><span class="line">test_losses = []   <span class="comment"># Save the loss value of each test loop (epoch) of the neural network model during the training process</span></span><br><span class="line">test_counter = [i * <span class="built_in">len</span>(titanic_train) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_epochs + <span class="number">1</span>)]  <span class="comment"># how many data for training so far</span></span><br></pre></td></tr></table></figure></li><li><p>Create a training function with the main purpose of training the model using the train dataset:</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">epoch</span>):  <span class="comment"># Indicates the current epoch being run</span></span><br><span class="line">    network.train()  <span class="comment"># Use the network created in the previous step for training</span></span><br><span class="line">    correct = <span class="number">0</span>  <span class="comment"># Record the current number of correct predictions</span></span><br><span class="line">    cur_count = <span class="number">0</span>  <span class="comment"># Record how many data points have been trained so far</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataloader):</span><br><span class="line">        optimizer.zero_grad()  <span class="comment"># Clear the gradient to start fresh for each batch because the gradient is updated after each batch</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Forward propagation</span></span><br><span class="line">        output = network(data)  <span class="comment"># Feed the data into the network for forward propagation</span></span><br><span class="line">        loss = criterion(output, target)  <span class="comment"># Calculate the loss</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Accuracy</span></span><br><span class="line">        pred = (output &gt;= <span class="number">0.5</span>).<span class="built_in">float</span>()  <span class="comment"># Since the answers are either 0 or 1, we need to set a threshold where &gt;= 0.5 is 1 and &lt; 0.5 is 0</span></span><br><span class="line">        correct += (pred == target).<span class="built_in">sum</span>().item()  <span class="comment"># Record the current number of correct predictions</span></span><br><span class="line">        cur_count += <span class="built_in">len</span>(data)  <span class="comment"># Record how many data points have been trained so far</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Backward propagation</span></span><br><span class="line">        loss.backward()  <span class="comment"># Calculate the gradient of the loss</span></span><br><span class="line">        optimizer.step()  <span class="comment"># Update the gradient</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> batch_idx % log_interval == <span class="number">0</span>:  <span class="comment"># Print the training status every log_interval</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;\t Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                epoch,</span><br><span class="line">                cur_count,</span><br><span class="line">                <span class="built_in">len</span>(train_dataloader.dataset),</span><br><span class="line">                <span class="number">100.</span> * cur_count / <span class="built_in">len</span>(train_dataloader.dataset),</span><br><span class="line">                loss.item(),</span><br><span class="line">                correct, <span class="built_in">len</span>(train_dataloader.dataset),</span><br><span class="line">                <span class="number">100.</span> * correct / <span class="built_in">len</span>(train_dataloader.dataset))</span><br><span class="line">            )</span><br><span class="line">            train_losses.append(loss.item())</span><br><span class="line">            train_counter.append((batch_idx * <span class="number">16</span>) + ((epoch - <span class="number">1</span>) * <span class="built_in">len</span>(train_dataloader.dataset)))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Return the current accuracy</span></span><br><span class="line">    <span class="keyword">return</span> correct / <span class="built_in">len</span>(train_dataloader.dataset)</span><br></pre></td></tr></table></figure></li><li><p>Constructing a test function, the main purpose is to test the trained model through validation dataset to see how accurate the model is when it is trained to detect unknown data.</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    network.<span class="built_in">eval</span>()  <span class="comment"># Use the network created in the previous step and indicate that it&#x27;s for evaluation</span></span><br><span class="line">    test_loss = <span class="number">0</span>  <span class="comment"># Record the current loss</span></span><br><span class="line">    correct = <span class="number">0</span>  <span class="comment"># Record the current number of correct predictions</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():  <span class="comment"># We don&#x27;t need to calculate gradients for evaluation, so we can use torch.no_grad() for speedup</span></span><br><span class="line">        <span class="keyword">for</span> data, target <span class="keyword">in</span> test_dataloader:  <span class="comment"># Get data through the test_dataloader</span></span><br><span class="line">            <span class="comment"># Forward propagation</span></span><br><span class="line">            output = network(data)  <span class="comment"># Feed the data into the trained network for forward propagation</span></span><br><span class="line">            test_loss += criterion(output, target).item()  <span class="comment"># Calculate the loss</span></span><br><span class="line">            <span class="comment"># Accuracy</span></span><br><span class="line">            pred = (output &gt;= <span class="number">0.5</span>).<span class="built_in">float</span>()  <span class="comment"># 0.5 is the threshold</span></span><br><span class="line">            correct += (pred == target).<span class="built_in">sum</span>().item()  <span class="comment"># Record the current number of correct predictions</span></span><br><span class="line"></span><br><span class="line">    test_loss /= <span class="built_in">len</span>(test_dataloader.dataset)  <span class="comment"># Calculate the average loss</span></span><br><span class="line">    test_losses.append(test_loss)  <span class="comment"># Add the current loss to the list</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        test_loss,</span><br><span class="line">        correct,</span><br><span class="line">        <span class="built_in">len</span>(test_dataloader.dataset),</span><br><span class="line">        <span class="number">1.</span> * correct / <span class="built_in">len</span>(test_dataloader.dataset))</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> correct / <span class="built_in">len</span>(test_dataloader.dataset)  <span class="comment"># Return the current accuracy</span></span><br></pre></td></tr></table></figure></li><li><p>Finally, we can train the model according to the number of epochs, and check the training status by <code>test()</code> after each epoch.</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">test()</span><br><span class="line">train_accuracy_list = []</span><br><span class="line">test_accuracy_list = []</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n_epochs + <span class="number">1</span>): <span class="comment"># Indicates the current epoch being run</span></span><br><span class="line">    train_accuracy_list.append(train(epoch)) <span class="comment"># After each epoch, we use the train() function to train the model</span></span><br><span class="line">    test_accuracy_list.append(test()) <span class="comment"># After each epoch, we use the test() function to test the model</span></span><br></pre></td></tr></table></figure></li></ol><h1 id="Step4-Generate-Results">Step4. Generate Results</h1><p>Finally, we can generate the results by using the following commands:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.plot(train_accuracy_list, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.plot(test_accuracy_list, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line"><span class="comment"># plt.ylim(0.5, 1)</span></span><br><span class="line">plt.legend([<span class="string">&#x27;Train Accuracy&#x27;</span>, <span class="string">&#x27;Test Accuracy&#x27;</span>, <span class="string">&#x27;Mutli Train Accuracy&#x27;</span>, <span class="string">&#x27;Mutli Test Accuracy&#x27;</span>], loc=<span class="string">&#x27;lower right&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Accuracy&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://i.imgur.com/8yHAk60.png" alt=""></p><h1 id="Step5-Make-Overfitting">Step5. Make Overfitting</h1><div class="note info flat"><p>Creating overfitting can mainly be achieved through a few methods:</p><ol><li><strong>Increasing the number of epochs</strong> can lead to some overfitting.</li><li><strong>Increasing the number of hidden layers</strong> or <strong>increasing the neuron size</strong> can also result in some overfitting.</li></ol></div><p>Since the task requires increasing the number of hidden layers and increasing the neuron size, let’s give it a try! The simplest way is to increase the number of hidden layers, increase the neuron size, and also increase the number of epochs to observe overfitting.</p><ol><li>Create a MultiLayerNet and increase the number of hidden layers and neuron size. <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MultiLayerNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, D_in, H, D_out, num_layers</span>):</span><br><span class="line">        <span class="built_in">super</span>(MultiLayerNet, self).__init__()</span><br><span class="line">        neurons = <span class="number">128</span></span><br><span class="line">        self.<span class="built_in">input</span> = nn.Linear(D_in, H)</span><br><span class="line">        self.linear1 = nn.Linear(H, <span class="number">128</span>)</span><br><span class="line">        self.linear2 = nn.Linear(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line">        self.linear3 = nn.Linear(<span class="number">64</span>, <span class="number">32</span>)</span><br><span class="line">        self.linear4 = nn.Linear(<span class="number">32</span>, <span class="number">16</span>)</span><br><span class="line">        self.output = nn.Linear(<span class="number">16</span>, D_out)</span><br><span class="line">        self.sigmoid = nn.Sigmoid() <span class="comment"># Sigmoid activation for binary classification</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        y_relu = F.relu(self.<span class="built_in">input</span>(x))</span><br><span class="line">        y_relu = F.relu(self.linear1(y_relu))</span><br><span class="line">        y_relu = F.relu(self.linear2(y_relu))</span><br><span class="line">        y_relu = F.relu(self.linear3(y_relu))</span><br><span class="line">        y_relu = F.relu(self.linear4(y_relu))</span><br><span class="line">        y_pred = self.sigmoid(self.output(y_relu))</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br></pre></td></tr></table></figure></li></ol><div class="note danger flat"><p>Note: If you simply add layers, you may not see much learning effect, and you will always see a flat line… and the accuracy won’t improve! Later, a classmate found that decreasing the number of neurons gradually would lead to better learning. So, we can set the neurons as 128, 64, 32, 16!<br>A classmate said: “It’s like an hourglass,” filtering out unimportant information step by step and leaving behind the important information!</p></div><ol><li><p>Create new <code>multi_train()</code> and <code>test_multi()</code> functions for the multi-network.</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_multi</span>(<span class="params">epoch</span>):</span><br><span class="line">    multi_network.train() <span class="comment"># Use the network created in the previous step for training</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    cur_count = <span class="number">0</span> </span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataloader):</span><br><span class="line">        multi_optimizer.zero_grad()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># forward propagation</span></span><br><span class="line">        <span class="comment"># You will find that we use multi_network here for forward propagation</span></span><br><span class="line">        output = multi_network(data) </span><br><span class="line">        loss = multi_criterion(output, target) </span><br><span class="line">                </span><br><span class="line">        <span class="comment"># Accuracy</span></span><br><span class="line">        pred = (output &gt;= <span class="number">0.5</span>).<span class="built_in">float</span>()  <span class="comment"># survival_rate is the threshold</span></span><br><span class="line">        correct += (pred == target).<span class="built_in">sum</span>().item()</span><br><span class="line">        cur_count += <span class="built_in">len</span>(data)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># backword propagation</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        multi_optimizer.step()</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> batch_idx % log_interval == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Muti Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;\t Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                epoch, </span><br><span class="line">                cur_count, </span><br><span class="line">                <span class="built_in">len</span>(train_dataloader.dataset),</span><br><span class="line">                <span class="number">100.</span> * cur_count / <span class="built_in">len</span>(train_dataloader.dataset), </span><br><span class="line">                loss.item(), </span><br><span class="line">                correct, <span class="built_in">len</span>(train_dataloader.dataset),</span><br><span class="line">                <span class="number">100.</span> * correct / <span class="built_in">len</span>(train_dataloader.dataset))</span><br><span class="line">            )</span><br><span class="line">            train_losses.append(loss.item())</span><br><span class="line">            train_counter.append((batch_idx*<span class="number">16</span>) + ((epoch-<span class="number">1</span>)*<span class="built_in">len</span>(train_dataloader.dataset)))</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> correct / <span class="built_in">len</span>(train_dataloader.dataset)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_multi</span>():</span><br><span class="line">    multi_network.<span class="built_in">eval</span>()</span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data, target <span class="keyword">in</span> test_dataloader:</span><br><span class="line">            <span class="comment"># forward propagation</span></span><br><span class="line">            output = multi_network(data)</span><br><span class="line">            test_loss += multi_criterion(output, target).item()</span><br><span class="line">            <span class="comment"># Accuracy</span></span><br><span class="line">            pred = (output &gt;= <span class="number">0.5</span>).<span class="built_in">float</span>()  <span class="comment"># 0.5 is the threshold</span></span><br><span class="line">            correct += (pred == target).<span class="built_in">sum</span>().item()</span><br><span class="line">    test_loss /= <span class="built_in">len</span>(test_dataloader.dataset)</span><br><span class="line">    test_losses.append(test_loss)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nMulti Test set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        test_loss, </span><br><span class="line">        correct, </span><br><span class="line">        <span class="built_in">len</span>(test_dataloader.dataset),</span><br><span class="line">        <span class="number">100.</span> * correct / <span class="built_in">len</span>(test_dataloader.dataset))</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> correct / <span class="built_in">len</span>(test_dataloader.dataset)</span><br></pre></td></tr></table></figure></li><li><p>Retrain model</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">test_multi()</span><br><span class="line"></span><br><span class="line">multi_train_accuracy_list = []</span><br><span class="line">multi_test_accuracy_list = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n_epochs + <span class="number">1</span>):</span><br><span class="line">    multi_train_accuracy_list.append(train_multi(epoch))</span><br><span class="line">    multi_test_accuracy_list.append(test_multi())</span><br></pre></td></tr></table></figure></li><li><p>Draw the plot again: You can try to increase the number of epochs to 500, and you will see the overfitting phenomenon!</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.plot(multi_train_accuracy_list, color=<span class="string">&#x27;orange&#x27;</span>)</span><br><span class="line">plt.plot(multi_test_accuracy_list, color=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">plt.ylim(<span class="number">0.5</span>, <span class="number">0.9</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;Train Accuracy&#x27;</span>, <span class="string">&#x27;Test Accuracy&#x27;</span>, <span class="string">&#x27;Mutli Train Accuracy&#x27;</span>, <span class="string">&#x27;Mutli Test Accuracy&#x27;</span>], loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Accuracy&#x27;</span>)</span><br></pre></td></tr></table></figure></li></ol><p><img src="https://i.imgur.com/eVxVkM6.png" alt=""></p><h2 id="Advanced-Version">Advanced Version</h2><p>If you wish to dynamically adjust the number of neurons and hidden layers, you can use the following approach:</p><ul><li><code>neurons</code>: The initial number of neurons. If set to 1024, it will decrease from 1024 to 16, dividing by 2 each time, until the number of neurons is less than 16.</li><li><code>num_layers</code>: The number of hidden layers.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">neurons = <span class="number">1024</span> </span><br><span class="line">num_layers = <span class="number">5</span> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiLayerNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, D_in, D_out, neurons, num_layers</span>):</span><br><span class="line">        <span class="built_in">super</span>(MultiLayerNet, self).__init__()</span><br><span class="line">        neurons = neurons</span><br><span class="line">        self.<span class="built_in">input</span> = nn.Linear(D_in, neurons)</span><br><span class="line">        self.linears = nn.ModuleList()  <span class="comment"># Note that if you want to create multiple layers with for loops, you have to use nn.ModuleList() to create</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_layers):</span><br><span class="line">            self.linears.append(nn.Linear(neurons, <span class="built_in">max</span>(neurons // <span class="number">2</span>, <span class="number">16</span>)))</span><br><span class="line">            neurons = <span class="built_in">max</span>(neurons // <span class="number">2</span>, <span class="number">16</span>) </span><br><span class="line">        self.output = nn.Linear(neurons, D_out)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()  <span class="comment"># Sigmoid activation for binary classification</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        y = F.relu(self.<span class="built_in">input</span>(x))</span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.linears:</span><br><span class="line">            y = F.relu(layer(y))</span><br><span class="line">        y_pred = self.sigmoid(self.output(y))</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br></pre></td></tr></table></figure><h1 id="Step6-Use-Dropout">Step6. Use Dropout</h1><p>Here we can use dropout to avoid overfitting, mainly by randomly turning off some neurons during forward propagation, so as to avoid overfitting.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiLayerNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, D_in, H, D_out, num_layers, dropout_prob</span>):</span><br><span class="line">        <span class="built_in">super</span>(MultiLayerNet, self).__init__()</span><br><span class="line">        self.<span class="built_in">input</span> = nn.Linear(D_in, H)</span><br><span class="line">        self.linear1 = nn.Linear(H, <span class="number">128</span>)</span><br><span class="line">        self.linear2 = nn.Linear(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line">        self.linear3 = nn.Linear(<span class="number">64</span>, <span class="number">32</span>)</span><br><span class="line">        self.linear4 = nn.Linear(<span class="number">32</span>, <span class="number">16</span>)</span><br><span class="line">        self.output = nn.Linear(<span class="number">16</span>, D_out)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line">        self.dropout = nn.Dropout(p=dropout_prob)  <span class="comment"># ======&gt; dropout layer</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        y_relu = F.relu(self.<span class="built_in">input</span>(x))</span><br><span class="line">        y_relu = F.relu(self.linear1(y_relu))</span><br><span class="line">        y_relu = F.relu(self.linear2(y_relu))</span><br><span class="line">        y_relu = F.relu(self.linear3(y_relu))</span><br><span class="line">        y_relu = F.relu(self.linear4(y_relu))</span><br><span class="line">        y_relu = self.dropout(y_relu)  <span class="comment"># ======&gt; dropout layer</span></span><br><span class="line">        y_pred = self.sigmoid(self.output(y_relu))</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>At this point, you will find that the overfitting phenomenon is not so serious! Here are the results when the epoch number is set to 200.</p><blockquote><p>Without Dropout<br><img src="https://i.imgur.com/BxmZNLL.png" alt=""></p></blockquote><blockquote><p>With Dropout<br><img src="https://i.imgur.com/wj5vFvt.png" alt=""></p></blockquote><h2 id="Advanced">Advanced</h2><p>The difference in the advanced version is that the number of dropout layers is the same as the number of hidden layers, and the number of dropout layers decreases with the number of hidden layers.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MultiLayerNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, D_in, D_out, neurons, num_layers, dropout_prob=<span class="number">0.8</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(MultiLayerNet, self).__init__()</span><br><span class="line">        neurons = neurons</span><br><span class="line">        self.<span class="built_in">input</span> = nn.Linear(D_in, neurons)</span><br><span class="line">        self.linears = nn.ModuleList()  </span><br><span class="line">        self.dropouts = nn.ModuleList() <span class="comment">#  ======&gt; dropout layer</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_layers):</span><br><span class="line">            self.linears.append(nn.Linear(neurons, <span class="built_in">max</span>(neurons // <span class="number">2</span>, <span class="number">16</span>)))</span><br><span class="line">            self.dropouts.append(nn.Dropout(p=dropout_prob)) <span class="comment"># ======&gt; dropout layer</span></span><br><span class="line">            neurons = <span class="built_in">max</span>(neurons // <span class="number">2</span>, <span class="number">16</span>) </span><br><span class="line">        self.output = nn.Linear(neurons, D_out) <span class="comment"># output layer</span></span><br><span class="line">        self.sigmoid = nn.Sigmoid()  <span class="comment"># Sigmoid activation for binary classification</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        y = F.relu(self.<span class="built_in">input</span>(x))</span><br><span class="line">        <span class="keyword">for</span> layer, dropout <span class="keyword">in</span> <span class="built_in">zip</span>(self.linears, self.dropouts):</span><br><span class="line">            y = F.relu(layer(y))</span><br><span class="line">            y = dropout(y) <span class="comment"># ======&gt; dropout layer</span></span><br><span class="line">        y_pred = self.sigmoid(self.output(y))</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Code </category>
          
          <category> Machine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MAC OS -  PyTorch on Mac OS with GPU support</title>
      <link href="/en/posts/PyTorch-Mac-GPU/"/>
      <url>/en/posts/PyTorch-Mac-GPU/</url>
      
        <content type="html"><![CDATA[<h1 id="References">References</h1><ul><li><a href="https://blog.csdn.net/DaydreamHippo/article/details/128094886">Installing GPU-supported PyTorch and TensorFlow on Mac M1/M2</a></li><li><a href="https://developer.apple.com/metal/pytorch/">Accelerated PyTorch training on Mac</a></li></ul><h1 id="Enabling-GPU-on-Mac-OS-for-PyTorch">Enabling GPU on Mac OS for PyTorch</h1><ol><li>Since I personally reinstalled GPU-supported PyTorch based on Anaconda, you can check whether Conda is installed by using the command <code>conda --version</code>. If it is installed, the output should confirm its presence. If not, you can download it from the <a href="https://www.anaconda.com/products/distribution">Anaconda official website</a>.</li><li>(Optional) If you want to create a separate environment specifically for Python with GPU support, you can use the following command:</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create an environment named &#x27;torch-gpu&#x27; using Python version 3.10.9</span></span><br><span class="line">conda create -n torch-gpu python=3.10.9</span><br><span class="line"></span><br><span class="line"><span class="comment"># Activate the created environment</span></span><br><span class="line">conda activate torch-gpu</span><br><span class="line"></span><br><span class="line"><span class="comment"># List all environments to verify the &#x27;torch-gpu&#x27; environment is created</span></span><br><span class="line">conda <span class="built_in">env</span> list</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check if the current Python version matches the Python version in the activated environment</span></span><br><span class="line">python --version</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="31"><li><p>According to the <a href="https://pytorch.org/">PyTorch official website</a>, choose the corresponding version and copy the installation command.<br><img src="https://i.imgur.com/i89otBb.png" alt=""></p></li><li><p>You can use a simple Python script to verify MPS (Multi-Process Service) support:</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">if</span> torch.backends.mps.is_available():</span><br><span class="line">    mps_device = torch.device(<span class="string">&quot;mps&quot;</span>)</span><br><span class="line">    x = torch.ones(<span class="number">1</span>, device=mps_device)</span><br><span class="line">    <span class="built_in">print</span>(x)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;MPS device not found.&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Or</span></span><br><span class="line"><span class="built_in">print</span>(torch.backends.mps.is_available()) <span class="comment"># True</span></span><br><span class="line"><span class="built_in">print</span>(torch.backends.mps.is_built()) <span class="comment"># True</span></span><br></pre></td></tr></table></figure><div class="note warning flat"><p>It’s important to note that if you’re using MPS on macOS, you should specify it as follows: <code>device = torch.device(&quot;mps)</code>.</p></div>]]></content>
      
      
      <categories>
          
          <category> Code </category>
          
          <category> Mechine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mechine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zero Trust Architecture (ZTA) Principles Applied to AP and DB</title>
      <link href="/en/posts/zta-survey/"/>
      <url>/en/posts/zta-survey/</url>
      
        <content type="html"><![CDATA[<h1 id="Reference-Links">Reference Links</h1><ul><li><a href="https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-207.pdf">In 2020, NIST released NIST SP 800-207</a></li><li><a href="https://dodcio.defense.gov/Portals/0/Documents/Library/(U)ZT_RA_v2.0(U)_Sep22.pdf">In 2021, the U.S. Defense Information Systems Agency published the Department of Defense Zero Trust Reference Architecture</a></li><li><a href="https://zerotrust.cyber.gov/federal-zero-trust-strategy/">In September 2021, the U.S. Office of Management and Budget released a formal document after seeking input on the Federal Zero Trust Strategy</a></li></ul><h1 id="Introduction">Introduction</h1><p>As a graduate student researching security between databases (DB) and applications (AP), understanding the requirements and architecture of Zero Trust (ZTA) is crucial. ZTA encompasses various aspects beyond just DB-AP security, such as user authentication. This article aims to categorize the requirements and architecture from the following three documents:</p><ul><li><a href="https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-207.pdf">NIST released NIST SP 800-207 in 2020</a>, which serves as the foundational framework for adopting ZTA.</li><li>The U.S. Defense Information Systems Agency published the <a href="https://dodcio.defense.gov/Portals/0/Documents/Library/(U)ZT_RA_v2.0(U)_Sep22.pdf">Department of Defense Zero Trust Reference Architecture in 2021</a>, outlining reference components for implementing ZTA.</li><li>The U.S. Office of Management and Budget released a formal document <a href="https://zerotrust.cyber.gov/federal-zero-trust-strategy/">in January 2022</a> after seeking input on the Federal Zero Trust Strategy, which sets goals for achieving ZTA in various aspects within federal government agencies by the fiscal year 2024.</li></ul><div class="note danger flat"><p>Since this article is based on my own research, the content may not be fully integrated. For a summary, please refer to <a href="/posts/ZTA-survey-AP-DB-summary">Zero Trust Architecture Methods</a>.</p></div><h1 id="NIST-Zero-Trust-Assumptions">NIST Zero Trust Assumptions</h1><blockquote><p>The following content is primarily derived from NIST SP 800-207 for reference.</p></blockquote><p>The assumptions underlying the Zero Trust architecture are as follows:</p><ol><li><strong>The entire enterprise private network is not considered an implicit trust zone.</strong><ul><li><code>The enterprise's internal network cannot be viewed as a trusted zone.</code></li></ul></li><li><strong>Devices on the network may not be owned or configurable by the enterprise.</strong><ul><li><code>Devices may not be owned or configured by the enterprise (e.g., BYOD).</code></li></ul></li><li><strong>No resource is inherently trusted.</strong><ul><li><code>No resource is inherently trusted; each asset must be assessed for its security posture before access is granted, relying on a Policy Enforcement Point (PEP).</code></li></ul></li><li><strong>Not all enterprise resources are on enterprise-owned infrastructure.</strong><ul><li><code>Not all enterprise resources are located on enterprise-owned infrastructure. Resources may include remote enterprise subjects and cloud services. Enterprise-owned or managed assets may require basic connectivity and network services (e.g., DNS resolution) via non-enterprise networks.</code></li></ul></li><li><strong>Remote enterprise subjects and assets cannot fully trust their local network connection.</strong><ul><li><code>Remote accessors must assume that the local network environment is untrusted. All traffic should be assumed to be monitored and potentially altered. All connections must be authenticated and authorized.</code></li></ul></li><li><strong>Assets and workflows moving between enterprise and non-enterprise infrastructure should have a consistent security policy and posture.</strong><ul><li><code>Assets and workflows moving between enterprise and non-enterprise infrastructure should maintain a consistent security policy and posture.</code></li></ul></li></ol><h1 id="NIST-Zero-Trust-Tenets-ZTA-Tenets">NIST Zero Trust Tenets (ZTA Tenets)</h1><blockquote><p>The following content is primarily from NIST SP 800-207.</p></blockquote><details class="toggle" ><summary class="toggle-button" style="">Tenet 1: All data sources and computing services within the enterprise must be treated as protected resources.</summary><div class="toggle-content"><p>Thoughts:</p><ul><li>For databases, <strong>databases can be considered protected resources</strong>.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Tenet 2: Trust should not be granted based solely on network location; the same security requirements should apply to internal access requests as well as external ones.</summary><div class="toggle-content"><p>Thoughts:</p><ul><li>No application should be inherently trusted; <strong>continuous authorization and authentication</strong> should be required for all applications accessing databases.</li></ul></div></details><details class="toggle" style="border: 1px solid  and access should be subject to the principle of least privilege."><summary class="toggle-button" style="background-color:  and access should be subject to the principle of least privilege.;">Tenet 3: Access to enterprise resources must be on a per-session basis</summary><div class="toggle-content"><p>Content:</p><ul><li>Before authorization is granted, requests should be measured and subject to the principle of least privilege (POLP).</li><li>It’s worth noting that authorization and authentication don’t necessarily have to occur right before the start of a session or transaction with a resource. Instead, an organization can assess a user’s identity and trustworthiness before the user even submits a request for access, granting permissions based on these assessments. This can streamline the access process and save time when users actually need to access resources.</li></ul><p>Thoughts:</p><ul><li>Applications accessing databases should be able to authenticate themselves when establishing a connection.</li><li>Ensure that the application’s access aligns with the scope of data it needs to work with, meaning that <strong>each application accessing the database should have a clear identity</strong> to distinguish what resources it can access.</li></ul></div></details><details class="toggle" style="border: 1px solid  request status"><summary class="toggle-button" style="background-color:  request status;color:  environmental attributes">Tenet 4: Resource requests should be determined by dynamic policies that include client identity</summary><div class="toggle-content"><p>Content:</p><ul><li>The requesting asset’s state may include attributes such as <strong>software versions, network location, request timestamp, observed historical behaviors, installed certificates</strong>.</li><li>Behavioral attributes may include but are not limited to automated <strong>accessor analysis, device profiling, usage pattern deviations</strong>.</li><li>Environmental attributes may include the requester’s <strong>network location, time, active attack reports</strong>.</li><li>Policies are sets of access rules based on attributes assigned to subjects, data assets, or applications.</li></ul><p>Thoughts:</p><ul><li>A <strong>comprehensive access control policy</strong> should be designed to include various attributes, as mentioned above.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Tenet 5: Trust is no longer assumed for any asset; continuous monitoring and assessment of the security posture of all assets are essential.</summary><div class="toggle-content"><p>Content:</p><ul><li>The enterprise should establish a Continuous Diagnostics and Mitigation (CDM) program to monitor the state of devices and applications, applying patches/remediations as needed.</li><li>Implement a robust monitoring and reporting system providing actionable data on the current state of enterprise resources.</li></ul><p>Thoughts:</p><ul><li>For applications accessing the database, there should be <strong>continuous monitoring of third-party package versions, patches, and the overall health of the application</strong>.</li><li>Additionally, monitor the application’s execution environment for normalcy.</li></ul></div></details><details class="toggle" style="border: 1px solid  and strict enforcement is required before granting access."><summary class="toggle-button" style="background-color:  and strict enforcement is required before granting access.;">Tenet 6: Resource authentication and authorization are dynamic</summary><div class="toggle-content"><p>Content:</p><ul><li>This is an ongoing process involving obtaining access, scanning and assessing threats, adapting to changes, and continuously reevaluating trust within communications.</li><li>This approach ensures that only authorized users can access enterprise resources at any given time.</li><li>Organizations implementing the Zero Trust architecture are expected to have Identity, Credential, and Access Management (ICAM) systems and asset management systems.</li><li>Throughout user transactions, continuous monitoring, and potentially reauthentication and reauthorization, <strong>policies (e.g., time-based reauthentication, new resource requests, resource modifications, detection of anomalous user activities) are defined and enforced</strong>.</li><li>Policies aim to balance security, availability, usability, and cost-effectiveness.</li></ul><p>Thoughts:</p><ul><li>Initially, <strong>any application accessing data in a database should undergo strict authentication and authorization processes</strong>, ensuring that only authorized applications can access the database.</li><li>During data access, <strong>continuous monitoring should be in place</strong> with the possibility of reauthentication and reauthorization based on the accessed resource.</li></ul></div></details><details class="toggle" style="border: 1px solid  network traffic"><summary class="toggle-button" style="background-color:  network traffic;color:  access requests">Tenet 7: Information about the security state of assets</summary><div class="toggle-content"><p>Thoughts:</p><ul><li>The security state of databases, applications, network traffic, request contents, and results should be <strong>logged and collected</strong>.</li><li>These <strong>collected data can be utilized to enhance policy creation and enforcement</strong>, improving security strategies.</li></ul></div></details><h1 id="Zero-Trust-Architecture-Methods">Zero Trust Architecture Methods</h1><div class="note warning flat"><p>In my personal opinion, if you want to implement Zero Trust Architecture (ZTA) between applications (AP) and databases (DB), you should <strong>adopt the “Using Enhanced Identity Governance” approach as the framework for your research</strong>.</p></div><p>NIST SP 800-207 outlines three primary methods for implementing ZTA:</p><ol><li><strong>Using Enhanced Identity Governance</strong><ul><li><strong>Explanation</strong>: This method focuses on <em>identity as the core</em> and formulates resource access policies based on identity and attributes.</li><li><strong>Thoughts</strong>: To implement this approach between applications and databases, <em>identify the requesting application’s identity</em>, health status, and potential security vulnerabilities in third-party packages. Authorization should be based on these assessments.</li></ul></li><li><strong>Using Micro-Segmentation</strong><ul><li><strong>Explanation</strong>: It involves placing resources within separate network segments protected by gateway security components to prevent unauthorized access.</li><li><strong>Thoughts</strong>: This method primarily relies on network security components such as firewalls to control and monitor network traffic. Since your research focuses on the interaction between applications and databases, using this method might not be suitable because it could hinder your ability to understand the details of data flows between them.</li></ul></li><li><strong>Using Network Infrastructure and Software Defined Perimeters</strong><ul><li><strong>Explanation</strong>: This method utilizes network infrastructure to implement ZTA. It may include concepts like software-defined networks (SDN) and intent-based networking, with a Perimeter Authority (PA) serving as a network controller to set up and reconfigure the network.</li><li><strong>Thoughts</strong>: This approach mainly operates at the network layer (Network Layer) of the OSI model, responsible for routing, forwarding between networks, and packet delivery between different networks. This layer may not provide sufficient visibility into application-level details. In your research, to ensure proper security and prevent data leakage or attacks, it’s crucial to establish connections that meet the security requirements of your applications.</li></ul></li></ol><h1 id="Types-of-NIST-Zero-Trust-Architecture-Deployments">Types of NIST Zero Trust Architecture Deployments</h1><p>From the following architectures, it can be seen that the Zero Trust Architecture in NIST SP 800-209 mainly focuses on user-centric access to resources through devices.</p><table><thead><tr><th>Comparison Item</th><th>Agent/Gateway</th><th>Enclave Gateway</th><th>Resource Portal</th><th>App Sandboxing</th></tr></thead><tbody><tr><td>Presence of Agent</td><td><code>Yes</code></td><td><code>Yes</code></td><td><code>No</code></td><td><code>No</code></td></tr><tr><td>PEP Location</td><td>At the front of a single resource</td><td>At the front/entrance of a resource set or private cloud</td><td>At the front/entrance of a resource set or private cloud</td><td>Installed on the resource</td></tr><tr><td>Applicability</td><td>Enterprises with a device management plan</td><td>Enterprises with legacy applications or on-premises data centers</td><td>Suitable for BYOD environments, no need for client-side software components</td><td>Suitable for applications unable to scan client assets (devices) for vulnerabilities</td></tr></tbody></table><h2 id="Device-Agent-Gateway-Model">Device Agent / Gateway Model</h2><p><img src="https://i.imgur.com/Z4IezQ5.png" alt=""></p><ul><li>In this model, the <em>PEP (Policy Enforcement Point) is divided into two part</em> located either on the “resource” or directly as a component at the “resource front.”<ul><li>The first part is the “Device Agent”: It is installed on assets provided by the enterprise and is used to coordinate connections. This agent is responsible for <em>routing some (or all) traffic to the appropriate PEP for request evaluation</em>.</li><li>The second part is the “Gateway”: It is placed at the front of each resource, allowing resources to communicate only with this gateway, essentially acting as an agent for the resource. This gateway communicates with policy administrators and allows only approved communication paths configured by policy administrators.</li></ul></li><li>Policy administrators (PA) and policy engines (PE) can be on-premises devices or cloud services.</li><li>Applicability:<ul><li>Suitable for use in enterprises that have established robust device management plans and have dedicated resources for communication with gateways. This model is also suitable for enterprises that do not wish to implement BYOD policies.</li><li><em>Access can only be obtained through device agents</em>, which can be installed on assets owned by the enterprise.</li></ul></li></ul><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  sequenceDiagram    participant A as Agent     participant PA as Policy Administrator     participant PE as Policy Engine    participant G as Gateway    A-&gt;&gt;+PA: Access request received by local agent, forwarded to Policy Administrator PA    PA-&gt;&gt;+PE: Policy Administrator PA forwards the request to Policy Engine PE for evaluation.    PE--&gt;&gt;-PA: Request is authorized, Policy Administrator configures communication channels between device agents and related resource gateways on the control plane.    A-&gt;&gt;+G: Device agent and gateway subsequently establish a connection, beginning encrypted application&#x2F;service data transmission.    G--&gt;&gt;-A: The connection between the device agent and resource gateway is terminated when the workflow is completed or when a security event is triggered by the Policy Administrator (e.g., session timeout, reauthentication failure).  </pre></div><h2 id="Enclave-Based-Deployment">Enclave-Based Deployment</h2><div class="note info flat"><p>“Enclave” is a secure isolated computing environment that can protect sensitive data and applications from unauthorized access or attacks.</p></div><p><img src="https://i.imgur.com/R85LkBO.png" alt=""></p><ul><li>It is a variant of the Device Agent / Gateway Model, where enterprise assets (devices) connect to the Enclave gateway using Agent device agents, and the connection process is essentially the same as the Device Agent / Gateway.</li><li>The gateway primarily protects not just a single resource but multiple resources.</li><li>The drawback is that the gateway protects a group of resources, which may not protect each resource individually, potentially allowing users to see resources they are not authorized to access.</li><li>Applicability:<ul><li>Suitable for enterprises with legacy applications or on-premises data centers where individual gateways cannot be set up for each resource.</li><li>Enterprises need to establish robust asset and configuration management to install/configure device agents, allowing subjects to see which permissions are available.</li></ul></li></ul><h2 id="Resource-Portal-Based-Deployment">Resource Portal-Based Deployment</h2><p><img src="https://i.imgur.com/wU864uN.png" alt=""></p><ul><li>The main advantage of this model over others is that <em>no software components need to be installed on all client devices</em>.</li><li>However, this model has some limitations:<ul><li>Since assets and devices can only be scanned and analyzed when they connect to the PEP gateway, <em>only limited information can be obtained from requesting devices</em>.</li><li>The model may <em>not be able to continuously monitor these devices</em>, detect malware, unpatched vulnerabilities, and proper configurations.</li><li>In this model, there is no local agent to handle requests, so the enterprise <em>may not have full visibility or control over assets</em>; they can only be seen/scanned when they connect to the gateway.</li></ul></li><li>Applicability:<ul><li>This makes the model more suitable for BYOD policies (Bring Your Own Device, where employees use their own devices for work) and cross-organizational collaboration projects.</li></ul></li></ul><h2 id="Device-Application-Sandboxing">Device Application Sandboxing</h2><p><img src="https://i.imgur.com/moNnJsX.png" alt=""></p><ul><li>It is a variant of the Device Agent / Gateway Model.</li><li>It allows approved applications or processes (Trusted App or Process) to run on the “asset” with isolation management.</li><li>Isolation can be implemented as virtual machines, containers, or other forms to protect applications from potential compromises on the host or other applications.</li><li>PEP can be local enterprise services or cloud services responsible for managing application access.</li><li>The advantage of this model is that it isolates individual applications from the rest of the asset, helping to prevent infections.</li><li>Disadvantages:<ul><li>Enterprises need to <em>maintain sandbox applications for all assets</em>, and they may <em>not have full insight into client assets</em>.</li><li>It also requires <em>ensuring the security of each application</em>, which may require more effort compared to other architectures.</li><li>It cannot understand client assets (devices).</li></ul></li><li>Applicability:<ul><li>Suitable for scenarios where assets (devices) cannot be scanned for vulnerabilities. This model can protect the application (AP) from potential malicious software on the host.</li></ul></li></ul><h1 id="OMB-5-Pillars">OMB - 5 Pillars</h1><p>The ZTA policy issued by the U.S. federal government is based on the maturity model of CISA, divided into 7 pillars, providing specific requirements for identity, devices, networks, applications, and data to meet the requirements of the Zero Trust Architecture.</p><div class="note warning flat"><p>Among these requirements, some apply to what applications should meet, such as ensuring the security of third-party components and having sufficient security posture. However, <em>specific requirements for government agency application services when accessing resources are not explicitly listed</em>, and <em>data security requirements are basic</em>, including labeling key data, automated classification, and automated security responses.</p></div><details class="toggle" ><summary class="toggle-button" style="">Identity Authentication</summary><div class="toggle-content"><h2 id="Identity">Identity</h2><p>A robust identity authentication system forms the foundation of ZTA, and government agencies should integrate identity authentication systems and, when necessary, establish federated access with other agencies. <em>Expanding the use of MFA to protect users from credential theft or phishing attacks is essential</em>. The requirements include:</p><ol><li>Establish Single Sign-On (SSO) authentication services.<ol><li>Provide SSO services to users that can integrate with applications and common platforms (cloud services).</li><li>Ensure consistent strong identity authentication across various platforms.</li><li>SSO should use recognized standards such as SAML or OpenID Connect.</li></ol></li><li>Strengthen MFA at the application layer.<ol><li>For agency staff, contractors, and partners, phishing-resistant MFA is required.</li><li>For public users, phishing-resistant MFA must be an option.</li><li>Phishing-resistant methods like registering a mobile phone for SMS or voice calls or WebAuthn with support for one-time codes must be used.</li></ol></li><li>Implement secure password policies and check if passwords can resist data breaches.</li></ol></div></details><details class="toggle" ><summary class="toggle-button" style="">Device Monitoring</summary><div class="toggle-content"><h2 id="Devices">Devices</h2><p>Detection and monitoring of assets:</p><ol><li>Provide a service to enhance the detection and monitoring of assets (devices) to gain a comprehensive understanding of users, devices, or any interactions within the system.</li><li>Implement Continuous Diagnostics and Mitigation (CDM) programs, which can refer to Cisco’s <a href="https://www.cisa.gov/resources-tools/programs/continuous-diagnostics-and-mitigation-cdm-program">CDM Program</a>.</li><li>There is a need for robust Endpoint Detection and Response (EDR) tools to deploy.</li></ol></div></details><details class="toggle" ><summary class="toggle-button" style="">Network Security</summary><div class="toggle-content"><h2 id="Networks">Networks</h2><ul><li>Encrypt DNS requests.</li><li>Use HTTPS connections.</li><li>Implement Domain-based Message Authentication, Reporting, and Conformance (DMARC) with strict enforcement.<ul><li>DMARC is used for email verification checks and encryption for email requests sent to your domain, enhancing the security of Gmail.</li><li>Sending servers support DMARC, and receiving servers have set up DMARC policies in enforced mode to secure SMTP connections for emails.</li></ul></li><li>Each application should operate in an isolated network environment and should be prepared to establish untrusted network security connections between different applications.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Application Security</summary><div class="toggle-content"><h2 id="Applications">Applications</h2><ul><li>Applications should undergo rigorous security testing.</li><li>Third-party components should be secure.</li><li>Vulnerabilities in applications should not be concealed but reported.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Data Security</summary><div class="toggle-content"><h2 id="Data">Data</h2><ul><li>Label key data and perform automated data classification or security responses.</li><li>There must be comprehensive and real-time complete logging.</li><li>Automated security responses:<ul><li>Organizations should strive to adopt machine learning-based data sensitivity classification and security automation as early candidates. These candidates don’t necessarily require immediate use of machine learning and can initially be applied using simple technologies like scripts or regular expressions.</li><li>Provide early warnings and detection processes for abnormal behavior as much as possible.</li></ul></li><li>Audit access to sensitive data in the cloud.<ul><li>Use encryption to protect static data.</li><li>Detection can be assisted through cloud-managed encryption and decryption operations and related logs.</li><li>In mature stages, organizations should integrate audit logs with other event data sources and employ more advanced security monitoring methods.</li><li>For example, comparing the time of data access with user-initiated events to identify database access that may not be caused by normal application activity.</li></ul></li></ul></div></details><h1 id="DOD-ZTA-Assumptions">DOD - ZTA Assumptions</h1><p>Here, we mainly refer to Chapter 2, “Pillars and Principles” in the DoD, which mentions the principles of zero trust security policy. If someone asks you, “What is the core concept of zero trust?” you can respond:</p><ul><li>In this context, it is mentioned that “<em>the core concept of a zero trust strategy is to require continuous verification or validation before accessing sensitive data or protected resources</em>.”</li><li>In the zero trust security model, “<em>we need to rethink how access to resources is secured, and decisions should be based on dynamic policies</em>”. Dynamic policies should consider factors beyond just credential validation and include:<ul><li>(1) Observable states of <code>user and endpoint identities</code>: Confidence levels are established from multiple attributes of the authenticated subject (identity, location, time, device security state).</li><li>(2) <code>Applications/services</code>.</li><li>(3) Assets of the <code>request</code>.</li><li>(4) Other <code>behavior</code> and <code>environmental attributes</code>.</li><li>(5) Allowing for a more comprehensive assessment of access requests.</li></ul></li></ul><p>In DoD, there are primarily <em>five key principles</em> for zero trust, which represent foundational elements and influence all aspects of zero trust.</p><details class="toggle" ><summary class="toggle-button" style="">1. Assume a Hostile Environment</summary><div class="toggle-content"><ul><li>Assume that there are malicious actors both <em>inside and outside the environment</em>.</li><li><em>All users, devices, applications, environments, and other non-human entities are treated as untrusted</em>.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">2. Presume Breach</summary><div class="toggle-content"><ul><li>There are hundreds of thousands of attempted network attacks against DoD environments every day.</li><li>When operating and protecting resources, one should assume that <em>adversaries have already entered your environment</em>.</li><li><em>Enhance the scrutiny of access and authorization decisions</em> to improve response outcomes.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">3. Never Trust / Always Verify</summary><div class="toggle-content"><ul><li><em>Deny access by default</em>.</li><li>Authenticate and explicitly authorize each device, user, application/workload, and data flow <em>based on multiple attributes</em> (dynamic and static).</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">4. Scrutinize Explicitly</summary><div class="toggle-content"><ul><li>All resources are accessed securely and consistently using <code>multiple attributes</code> (dynamic and static) to derive confidence levels.</li><li>Access to resources is conditional, and <code>access can change dynamically</code> based on the results of actions and confidence levels.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">5. Apply Unified Analytics</summary><div class="toggle-content"><ul><li>Apply unified analytics to data, applications, assets, and services (DAAS), including behavioral characteristics, and <em>log every transaction</em>.</li></ul></div></details><h1 id="DOD-ZTA-Tenets">DOD - ZTA Tenets</h1><p>The sections above seem to cover the essential components that should be included. Below are the guiding principles for the security architecture described in Chapter 2.4 Reference Architecture Principles:</p><details class="toggle" ><summary class="toggle-button" style="">Principle #1: Assume no implicit or explicit trusted zone in networks.</summary><div class="toggle-content"><p>This means not blindly trusting any zone within the network.</p></div></details><details class="toggle" style="border: 1px solid  data"><summary class="toggle-button" style="background-color:  data;color:  and services.">Principle #2: Identity-based authentication and authorization are strictly enforced for all connections and access to infrastructure</summary><div class="toggle-content"><p>Ensure that only authenticated and authorized users can access relevant resources.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Principle #3: Machine to machine (M2M) authentication and authorization are strictly enforced for communication between servers and the applications.</summary><div class="toggle-content"><p>This ensures secure and trusted communication between servers and applications.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Principle #4: Risk profiles generated in near-real-time from monitoring and assessment of both user and devices behaviors are used in authorizing users and devices to resources.</summary><div class="toggle-content"><p>This means authorizing users and devices to specific resources based on real-time risk values.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Principle #5: All sensitive data is encrypted both in transit and at rest.</summary><div class="toggle-content"><p>This ensures data security during transmission and storage.</p></div></details><details class="toggle" style="border: 1px solid  collected"><summary class="toggle-button" style="background-color:  collected;color:  stored">Principle #6: All events are to be continuously monitored</summary><div class="toggle-content"><p>This helps in real-time monitoring and assessment of system behavior.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Principle #7: Policy management and distribution is centralized.</summary><div class="toggle-content"><p>This means that all security policies are centrally managed and distributed, ensuring uniform security measures.</p></div></details><h1 id="DOD-7-Pillars">DOD - 7 Pillars</h1><p><img src="https://i.imgur.com/mh7I5x8.png" alt=""></p><p>The main focus is to list the description of each pillar, its relevance to the AP and DB, and personal observations.</p><details class="toggle" ><summary class="toggle-button" style="">User ⭐️⭐️⭐️</summary><div class="toggle-content"><ul><li><strong>Description</strong>: This pillar focuses on protecting and restricting access to (Data, Applications, Assets, Services) DAAS for both <code>personnel</code> and <code>non-personnel entities</code>. This includes identity authentication, such as MFA, Privileged Access Management (PAM), continuous <code>authentication, authorization, and monitoring of user activity patterns</code> to manage user access and privileges while securing all interactions.</li><li><strong>Observation</strong>: The User Pillar not only applies to users but also emphasizes continuous authentication of AP and monitoring of activity patterns.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Device ⭐️⭐️</summary><div class="toggle-content"><ul><li><strong>Description</strong>: Emphasizes <code>continuous real-time validation, inspection, assessment, and remediation of devices</code> in the enterprise. Solutions like Mobile Device Managers, Comply to Connect, or Trusted Platform Modules (TPM) can assist in device confidence assessment, determining if a device is trusted, and complying with organizational security standards. This data also provides the basis for authorization decisions, ensuring that only legitimate devices can access resources.<ul><li>Additional assessments, such as threat checks, software versions, security status, encryption enablement, and proper configurations, should be performed for each access request.</li><li>In a Zero Trust approach, it’s crucial to <code>identify, authenticate, monitor, authorize, isolate, protect, remediate, and control all devices</code>.</li></ul></li><li><strong>Observation</strong>: Validation of the security of devices that execute AP is important.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Network/Environment ⭐️</summary><div class="toggle-content"><ul><li><strong>Description</strong>: This pillar emphasizes <code>segmentation of networks/environments (both logical and physical)</code> to enforce fine-grained access and policy restrictions, whether inside or outside the premises. As boundaries become finer, micro-segmentation provides greater protection and control. The key here is to <code>control privileged access</code>, <code>manage internal and external data flows</code>, and prevent lateral movement.</li><li><strong>Observation</strong>: It seems to focus on network segmentation, ensuring controlled access both inside and outside the enterprise network.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Applications and Workload ⭐️</summary><div class="toggle-content"><ul><li><strong>Description</strong>: This pillar encompasses <code>applications and workloads</code> in both on-premises and cloud environments. Technologies related to Application Delivery can provide additional protection, such as auditing source code and libraries developed through DevSecOps practices to ensure application security from the start.</li><li><strong>Observation</strong>: It appears to be a one-sided security guideline for AP.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Data ⭐️⭐️⭐️⭐️</summary><div class="toggle-content"><ul><li><strong>Description</strong>: Understanding an organization’s data and its importance is crucial for the successful implementation of the ZT architecture. Organizations need to <code>classify their data based on mission criticality</code> and use this information to develop a comprehensive data management strategy as part of their overall ZT approach.<ul><li>Achieving this goal involves <code>data ingestion</code>, <code>data classification</code>, developing <code>architectures</code>, and <code>encrypting data</code> at rest and in transit.</li><li>Solutions like DRM, DLP, software-defined environments, and fine-grained data labeling support the protection of critical data.</li></ul></li><li><strong>Observation</strong>: This is essential to highlight the protection of databases to achieve Zero Trust.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Visibility and Analytics ⭐️⭐️</summary><div class="toggle-content"><ul><li><strong>Description</strong>: <code>Detailed context information</code> provides a deeper understanding of the performance, behavior, and activity baseline of other ZT pillars. This visibility improves the detection of <code>abnormal behavior</code> and enables dynamic changes in security policies and real-time <code>access decisions</code>.<ul><li>Furthermore, other monitoring systems, such as sensor data and telemetry data, will help fill in the environmental context and trigger alerts for response.</li><li>ZT enterprises will capture and inspect traffic, not just focusing on network telemetry but also <code>deeply analyzing the data packets themselves</code> to accurately discover traffic on the network and observe existing threats, adjusting defenses more intelligently.</li></ul></li><li><strong>Observation</strong>: The emphasis is on recording logs as part of abnormal behavior detection and dynamic changes in access decisions.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Automation and Orchestration ⭐️⭐️⭐️</summary><div class="toggle-content"><ul><li><strong>Description</strong>: Achieve fast and scalable operations within the enterprise through policy-based automated security processes. SOAR (Security Orchestration, Automation, and Response) and how it helps enterprises <code>respond more effectively to security incidents to reduce response time</code>.<ul><li>Security orchestration integrates security information and event management (SIEM) and other automation security tools to manage different security systems.</li><li>In ZT enterprises, <code>automated security responses require explicit processes</code> and <code>consistent security policy enforcement across all environments</code> to provide proactive command and control.</li></ul></li><li><strong>Observation</strong>: Emphasis on achieving automated security response, influencing policies to enable dynamic decisions.</li></ul></div></details><h2 id="Aggregate-Capabilities-and-Pillars">Aggregate Capabilities and Pillars</h2><div class="note warning flat"><p>Here, we will create a large table to organize and concretely understand how to achieve the goals of the Pillars. We will also highlight:</p><ul><li>Which ones are our main focus.</li><li>Which ones are not related to the application and data aspects. Do they need to be included? If so, how should they be adjusted?</li><li>Which parts are not covered, and which ones can be supplemented through literature.</li></ul></div><p>(Placeholder for an image)</p><p>The image above shows the abilities we should follow within the seven major pillars and how these abilities can be fulfilled through the Pillar. They can mainly be categorized as follows:</p><ul><li><strong>Aggregate</strong>:<ul><li>If in UML terms A points to B, it means that A owns B, but it’s a weak ownership. <code>A and B have their own lifecycles</code>.</li><li>Commonly used to describe that a class A owns instances of class B, and A and B cooperate but can exist independently.</li></ul></li><li><strong>Dependency</strong>:<ul><li>If in UML terms A points to B, A uses B, and changes in B might affect A.</li><li>Commonly used to describe that when A uses certain methods, it might pass <code>B as a parameter, but it doesn't hold B</code>.</li></ul></li></ul><details class="toggle" ><summary class="toggle-button" style="">Aggregate Capabilities 1: Zero Trust Authentication & Authorization</summary><div class="toggle-content"><p>These two mainly involve two Pillars’ “Conditional Authorization Capabilities”:</p><ul><li><code>User</code><ul><li>Focuses on entities considered as either human or non-human.</li><li>Authorization to systems and resources will be <code>not limited to standard roles but include attributes, state analysis of the entity, demands at specific times, and reasons for accessing resources and data</code>.</li></ul></li><li><code>Device</code><ul><li>“Conditional Authorization Capabilities” will revolve around enforcing systems and enforcing <code>device health</code> against acceptable baselines.</li><li>The system will continuously assess the current state of inventories and telemetry data. Further information will be obtained through <code>state scanning and log recording</code>.</li><li>The <code>system will be able to update in real-time</code>, or under requests for coordination or other corrective methods.</li><li>The level of scrutiny and requirements the system accessing data undergoes will relate to the <code>security level of the data being attempted to access</code>.</li></ul></li></ul></div></details><details class="toggle" style="border: 1px solid  Workload"><summary class="toggle-button" style="background-color:  Workload;color:  and Data Capability">Aggregate Capabilities 2: Zero Trust Infrastructure</summary><div class="toggle-content"><p>For <code>Infrastructure</code>, the aggregate capabilities primarily relate to the <code>Network and Environments Pillar</code>:</p><ul><li>Controls built upon this pillar and capabilities for any ZT-enabled infrastructure.</li><li>This includes not only on-premises infrastructure but also cloud resources.</li><li>Macro and micro-segmentation strategies can be designed, separating and isolating specific workloads as long as these workloads are rigorously defined and validated. This not only allows interconnections between required nodes but also meets the connectivity requirements of software-defined boundaries.</li></ul><p>For protecting <code>Application and Workload</code>, aggregate capabilities mainly relate to the <code>Workloads Pillar</code>:</p><ul><li>These aggregate capabilities encompass all capabilities around the Workload pillar.</li><li>These capabilities will protect <code>applications</code> and devices that provide data for end-users.</li><li>These capabilities are designed to prevent lateral movement, <code>validate good software practices</code>, and segment applications into discrete, highly secure zones.</li><li>The connectivity to this zone is subject to strict scrutiny and is <code>proxied between internal and external requests</code>. Standardization of application calls will aid in the proper implementation of policy changes and updates.</li></ul><p>For protecting <code>Data</code>, aggregate capabilities mainly relate to the <code>Data Pillar</code>:</p><ul><li>These aggregate capabilities encompass all capabilities around the Data pillar.</li><li>This capability mainly focuses on protecting data, including labeling data, identifying sensitive data, preventing leaks, or encrypting sensitive data.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Aggregate Capabilities 3: Analytics and Orchestration</summary><div class="toggle-content"><p>For <code>Analytics</code>, aggregate capabilities primarily relate to the <code>Visibility &amp; Analytics Pillar</code>:</p><ul><li>The capabilities under this pillar involve a combination of <code>continuous entity monitoring, sensors, log recording, and event-driven analysis tools, along with machine learning</code>.</li><li>ZT will use machine learning to establish benchmarks for environmental data and analysis.</li><li>Machine learning algorithms provide benchmark datasets, enabling the execution of ZT policies in ZT coordination with artificial intelligence.</li></ul><p>For <code>Orchestration</code>, aggregate capabilities primarily relate to the <code>Automation &amp; Orchestration Pillar</code>:</p><ul><li>Its focus will be on <code>providing automation</code> to deploy policy changes to ensure enterprises and control around sensitive data.</li><li>The automation and orchestration pillar can also consider the introduction of <code>artificial intelligence and robotic process automation capabilities</code> in the core capabilities as technology evolves.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Dependency Capabilities 4: Zero Trust Enabling</summary><div class="toggle-content"><p>Here are the key points for successfully applying Zero Trust security policies:<br><strong>Data Governance</strong>:</p><ul><li>Data governance is a crucial element for successfully applying Zero Trust security policies.</li><li><code>Data governance provides processes, tools, and frameworks for managing data from creation to processing</code>.</li></ul><p><strong>Zero Trust and Risk Management</strong>:</p><ul><li>Zero Trust provides new discovery content for use by the Risk Management Framework (RMF).</li><li>ZTA introduces processes within the Risk Management Framework (RMF) that provide new discovery content for Zero Trust while adapting to modern application development practices like DevSecOps.</li><li>The impact primarily focuses on the Prepare, Assess, and Monitor steps.</li><li>The Prepare phase requires significant discovery work, especially for logging data flows and defining segmentation policies.</li><li>As DevSecOps capabilities modify applications, the assessment phase will change.</li><li><code>Zero Trust requires extensive monitoring activities, improving feedback to the RMF process and event response</code>.</li></ul><p><strong>Software-Defined Enterprise (SDE)</strong>:</p><ul><li>The Software-Defined Enterprise is a key factor in achieving the breadth and depth of the Zero Trust architecture.</li><li><code>Virtualization and software-defined infrastructure allow the isolation of data and applications</code>.</li><li>Domain coordination and control provide enterprise control plans to drive configurations and policies consistent with Zero Trust controls.</li></ul></div></details><h2 id="Pillars-Resources-Capability-Mapping">Pillars, Resources &amp; Capability Mapping</h2><p><img src="https://i.imgur.com/4JdywWA.png" alt=""></p><p>The image above illustrates the concept of “Zero Trust Pillars, Resources &amp; Capability Mapping” and how security measures are implemented within the architecture.</p><ul><li><em>Separate tracking of NPE (non-person entity) identity and individual identity</em> allows the separation of verification confidence levels’ verification paths between execution points.</li><li>Authentication and authorization activities occur at multiple focal points within the enterprise, including users and endpoints, proxies, applications, and data.</li><li>At each execution point, logs are sent to SIEM for analysis to develop confidence levels.</li><li>Confidence levels for devices and users are independently developed and aggregated as needed for policy execution.</li><li>If the confidence score for non-human entities or individual entities exceeds a threshold, they are authorized to view the required data.</li><li>Data is protected during transit through Data Loss Prevention (DLP) while also feeding data into SIEM to ensure proper data usage.</li></ul><details class="toggle" ><summary class="toggle-button" style="">Enterprise Identity Service</summary><div class="toggle-content"><p>Enterprise Identity Service consists of three main components:</p><ul><li><em>Federated Enterprise Identity Service (FEIS)</em><ul><li>Aggregates identity credentials and authorizations and shares them among federated organizations to achieve <code>cross-domain access services</code>.</li></ul></li><li><em>Automation Account Provisioning (AAP)</em><ul><li>Provides identity governance services, <code>managing user permissions, executing business roles</code>, and account provisioning and deprovisioning for various applications.</li></ul></li><li><em>Multi-Domain Entity Manager (MDEM)</em><ul><li>Maintains and enforces cross-domain access policies to control data and service access.</li><li>It also acts as an enforcement point to oversee cross-domain user interactions and shares.</li><li>It provides <code>secure distribution of tokens and ensures token compliance across enterprise execution points</code>.</li></ul></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Key Considerations</summary><div class="toggle-content"><p>Key considerations for the Zero Trust Enterprise:</p><ul><li><strong>Cross-Domain Access Services</strong>:<ul><li><strong>Access Authorization</strong>:<ul><li>Authorization decisions are separated from application logic and are <code>driven by policies and central authorization services</code>. These authorization services encompass user, data, and service attributes to determine authorization decisions.</li><li>Access to data and services is managed centrally to ensure compliance with business rules and policies.</li><li><strong>Risk-Based Authorization</strong>:<ul><li>Authorization decisions are <code>influenced by risk analysis and user behaviors</code>. Suspicious activities are logged and can result in dynamic policy updates.</li></ul></li></ul></li><li><strong>User and Entity Behavior Analytics (UEBA)</strong>:<ul><li>UEBA tools are used to monitor user and entity behaviors and provide insights into potential security threats.</li><li>UEBA solutions leverage machine learning and statistical analysis to identify unusual behavior patterns and provide early warnings.</li></ul></li></ul></li><li><strong>Multi-Domain Entity Manager (MDEM)</strong>:<ul><li>MDEM is a key component responsible for managing and enforcing cross-domain access policies.</li><li>It ensures that access to data and services across domains is compliant with established policies and restrictions.</li><li>MDEM also facilitates secure token distribution and compliance verification.</li></ul></li><li><strong>Data Loss Prevention (DLP)</strong>:<ul><li>DLP solutions are employed to prevent the unauthorized transfer or exposure of sensitive data.</li><li>They use content inspection and contextual analysis to identify and protect sensitive data in transit.</li><li>DLP solutions are integrated into the data protection strategy to safeguard against data breaches.</li></ul></li></ul></div></details><h1 id="DOD-Learn-from-Use-Case">DOD - Learn from Use Case</h1><div class="note warning flat"><p>This section is primarily intended to address the following questions for recording and note-taking:</p><ol><li>How to ensure zero trust between AP and Database?</li><li>How to implement dynamic Policy-based Access Control?</li><li>How to achieve continuous authentication between AP and DB?</li></ol></div><hr><blockquote><p>Highlights: Describes what Data Centers should focus on</p></blockquote><p><img src="https://i.imgur.com/j8vFKlW.png" alt=""><br>Contemporary data security methodologies are built on outdated, isolated network-centric strategies and methods. In this network-centric security model, data is vulnerable because it is protected solely through basic security practices (such as usernames/passwords, user/device-based access, and static encryption) and standard role-based access control (RBAC) that is rarely updated or validated. Threat actors can evade these basic protective measures. Therefore, from the above, the article mentions the following capabilities that should be implemented for data centers:</p><ul><li>Encryption: Data within the data center, both at rest and in transit, must be encrypted.</li><li>Policy Enforcement with Data Labeling:<ul><li>Use Case 1: To provide Digital Rights Management (DRM) and Data Loss Prevention (DLP) solutions for data.</li><li>Use Case 2: Enabling additional dynamic policies using Attribute-Based Access Control (ABAC).</li></ul></li></ul><blockquote><p>Highlights: Describes when tagging and other access actions should occur (use “prohibit” to indicate who is responsible for “blocking” work)</p></blockquote><p><img src="https://i.imgur.com/cwTJoro.png" alt=""><br>From the above image, it can be seen that PEP primarily explains how to protect data stored in Data Store. It emphasizes Data Tagging as a crucial step, done at the time of document creation or import. This involves understanding what data an organization owns, its characteristics, and the privacy and security requirements necessary to meet appropriate data protection standards. Data can be classified and assigned various attributes, which can be used for data categorization, such as Personally Identifiable Information (PII) and sensitive data.</p><ul><li>Data Permission Management (DRM) + Data Loss Prevention (DLP) + Security Information and Event Management (SIEM) + Data Storage Collaboration:<ul><li>Timing: After Data Tagging.</li><li>Protective Measures: These four protective measures, combined with encryption and other cryptographic techniques mentioned earlier, provide robust data protection for a zero trust architecture.<ul><li>SIEM: Collects and analyzes access and change data for any accessed data.</li><li>DRM: Allows or denies access, editing, or copying of data.</li><li>DLP: Prevents access to and transmission of data.</li><li>DDM: If users/endpoints are deemed trustworthy and have been granted access to data, Dynamic Data Masking (DDM) masks and modifies data during access and transmission.</li></ul></li></ul></li></ul><div class="note info flat"><p>You might wonder, both DLP and DRM have blocking capabilities, what’s the difference between them?<br>DLP primarily focuses on requests from unknown sources, while DRM deals with requests from known sources.</p></div><blockquote><p>Highlights: Emphasizes the relationship between SIEM and SOAR and other monitoring mechanisms</p></blockquote><p><img src="https://i.imgur.com/m8gsuSe.png" alt=""></p><ul><li>PEP: After PEP authentication, it decrypts encrypted data and delivers it to the requesting user/device.</li><li>SIEM: All requests are logged by SIEM and analyzed. When suspicious activity is detected, an event notification is triggered, which is then handled by SOAR (Security Orchestration, Automation, and Response).</li><li>SOAR: Following the event response process, it can deploy mitigation strategies to terminate existing sessions, re-encrypt data, and update PEP policies to reject future requests.</li></ul><blockquote><p>Highlights: Mainly focuses on PDP and explains that PDP handles requests (labeling, DRM, DDM, DLP, encrypted connection-related), while PEP provides real-time data protection and receives (encryption, labeling, DRM-related) data.</p></blockquote><p><img src="https://i.imgur.com/KAmczyW.png" alt=""></p><ul><li>Architectural Advantages: Emphasizes protecting data itself rather than just data boundaries.</li><li>Data Request Routing: Done through Policy Decision Points (PDP), and requests that do not meet the policy cannot access data.</li><li>Policy Updates: PDP policies are updated in real-time through device health, privilege access management, and analysis.</li><li>Connection Management: When PDP policies change, PEP can terminate existing connections.</li><li>Data Protection: Multiple Policy Enforcement Points (PEPs) continuously protect data and employ measures such as encryption, labeling, masking (DDM), and loss prevention (DLP).</li><li>Policy Coordination: Policy coordination between ZT architecture components achieves deep defense, maintaining data integrity, availability, and confidentiality.</li></ul><blockquote><p>Highlights: Focuses on Analysis + AI/ML application to Policy.<br><img src="https://i.imgur.com/w48kovr.png" alt=""></p></blockquote><ul><li>In the ZT model, AI significantly enhances visibility, insight, and automation capabilities in the environment.</li><li>Comprehensive Data Collection and Analysis: Data is collected and analyzed comprehensively from various aspects of the environment.</li><li>Through SIEM analysis, threats are identified and processed by SOAR.</li><li>Future Analytics Use: This information is recorded and stored for future machine learning and artificial intelligence, including confidence scoring for users/non-privileged entities, advanced threat detection, creating and modifying baselines, and automation and orchestration with external threat intelligence feeds and other AI capabilities.</li></ul><h1 id="DOD-Zero-Trust-Architecture-Patterns">DOD - Zero Trust Architecture Patterns</h1><div class="note warning flat"><p>Based on sections 7.1 and 7.2, patterns for all architectures should be summarized, and the applicable patterns for research should be identified, along with explanations.</p></div><h2 id="Domain-Policy-Enforcement-for-Resource-Access">Domain Policy Enforcement for Resource Access</h2><p><img src="https://i.imgur.com/bPpmMu1.png" alt=""></p><ul><li><strong>Explanation</strong>: The main architecture is divided into three segments: Resource Domain – Secured User or Device / Secured Network / Secured Application and Data. Each segment has its domain orchestrator for policy configuration, and control is achieved through the Controller. Data is collected and transmitted to the Cybersecurity Domain Orchestrator for analysis of suspicious activities. Upon threat detection, automated policy adjustments are made to reduce threats.</li><li><strong>Advantages</strong>: Precise policy configuration is possible for different domains, with control through the Controller. This may align more with your research on control measures between AP and DB.</li><li><strong>Disadvantages</strong>: With separation into different Domain Policy Enforcement segments, there may be inconsistencies in authorization verification during data transmission.</li></ul><h2 id="Software-Defined-Perimeter">Software Defined Perimeter</h2><p><img src="https://i.imgur.com/Gip0hBe.png" alt=""></p><ul><li><strong>Explanation</strong>: It has two main features – a gateway for forwarding end-to-end messages and intercepting interruptions for zero trust authorization. It also requires agent installation on endpoints for identity authentication, health status checks, and playing a role similar to PEP. A Broker is used for endpoint registration and authorization, acting as a PDP. If authorization is successful, a Gateway establishes a Proxy to directly connect two endpoints.</li><li><strong>Advantages</strong>: Achieves uniformity in policy control and ensures all connected devices are managed because agent installation is required for connection.</li><li><strong>Disadvantages</strong>: Technical complexity may be higher, requiring a complete registration and connection process, with more considerations for connectivity.</li></ul><h2 id="ZT-Broker-Integration">ZT Broker Integration</h2><p><img src="https://i.imgur.com/WLnOzP0.png" alt=""></p><ul><li><strong>Explanation</strong>: Similar to Software Defined Perimeter, all applications are hidden from end-user networks, and all connections must pass through trusted agents. However, it might be confusing regarding the differences between them. The key differences include:<ul><li>The Broker acts as both PDP and PEP, with PEP and PDP pairs that can be distributed (multiple instances), implemented through a single virtual service, and load-balanced.</li><li>Brokers can be distributed at the edge, mid-tier, or data center.</li><li>Service Proxy is installed in the Broker, not in the Resource Application.</li><li>There is no emphasis on connecting through a Gateway (Proxy connection).</li></ul></li><li><strong>Advantages</strong>: PEP and PDP can be deployed in multiple locations, load-balanced, and access control points can be more widely distributed.</li><li><strong>Disadvantages</strong>: Having PEP and PDP in multiple locations simultaneously may result in inconsistent authorization verification, and Resource Applications without an agent installation cannot guarantee they are managed.</li></ul><h2 id="Micro-Macro-Segmentation">Micro / Macro Segmentation</h2><p>Micro / Macro Segmentation primarily achieves ZTA through a third-tier network architecture, which is somewhat different from the main topic of this article and will not be extensively explained or introduced.<br><img src="https://i.imgur.com/2f4DCSy.png" alt=""></p><ul><li><strong>Description</strong>: In this architecture, the primary role is played by the Next Generation Firewall (NGFW). In this setup, all traffic must pass through the NGFW before reaching its destination microsegment. In some contexts, microsegments can further break down into smaller components, defining process-to-process microsegments and evolving into API microsegments. When a user requests a three-tier web application, traffic passes through the PEP of the web service &gt; undergoes evaluation by the application PEP &gt; and is assessed once more between the request and return to the user. In total, there are three tiers, ensuring that traffic at each stage undergoes strict policy evaluation, thereby enhancing security. However, the issue is that there is no evaluation between the application and the database, making it seem like trusting the application.</li></ul><h1 id="DOD-Maturity-Model">DOD - Maturity Model</h1><div class="note warning flat"><p>Here, we mainly explain what needs to be done to meet the maturity model of ZTA.</p></div><h2 id="Prepare-for-ZTA">Prepare for ZTA</h2><div class="note info flat"><p>Keywords: Identify critical resource inventory, data flows, network traffic logs</p></div><p>There are two main parts to consider:</p><ul><li><code>Discovery</code><ul><li>Identify DAAS (Data, Applications, Assets, and Services)</li><li>Map data flows</li><li>Build user and device inventories</li><li>Identify privileged accounts</li><li>Log network traffic</li></ul></li><li><code>Assessment</code><ul><li>Use existing standards to determine compliance status</li><li>Ensure accounts have appropriate permissions</li><li>Verify network/environment security settings meet the principle of least privilege</li></ul></li></ul><h2 id="ZTA-Baseline">ZTA Baseline</h2><div class="note info flat"><p>Keywords: Network segmentation, Principle of Least Privilege, MFA, Data Classification Labels, Encryption</p></div><p>The main tasks include the following:</p><ul><li>Ensure access to DAAS is determined by Cybersecurity policies.</li><li>Implement network segmentation using a deny-all/allow-by-exception approach (whitelisting)</li><li>Enforce IT security policies for devices</li><li>Implement the principle of least privilege access</li><li>Use MFA</li><li>Perform data classification and label sensitive or critical data</li><li>Meet encryption requirements</li></ul><h2 id="ZTA-Intermediate">ZTA Intermediate</h2><div class="note info flat"><p>Keywords: Granularity, Micro-Segmentation, EFIS, PAM, DLP &amp; DRM, UEBA</p></div><p>The main tasks include the following:</p><ul><li>Strengthen cybersecurity policies with control based on granularity (user and device attributes)</li><li>Employ Micro-Segmentation for critical network segments</li><li>Authenticate users through the Enterprise Federated Identity Service (EFIS)</li><li>Enhance least privilege through Privileged Access Management (PAM)</li><li>Implement Data Loss Prevention (DLP) &amp; Digital Rights Management (DRM)</li><li>Automatically label and classify data through flow analysis</li><li>Establish baseline policies based on User and Entity Behavior Analytics (UEBA)</li></ul><h2 id="ZTA-Advanced">ZTA Advanced</h2><div class="note info flat"><p>Keywords: Dynamic Decisioning, Continuous Verification and Authorization, User + Device Meeting EFIS</p></div><p>The main tasks include the following:</p><ul><li>Achieve dynamic decisioning for access to DAAS, driven by powerful real-time analysis</li><li>Implement full micro-segmentation</li><li>Enforce continuous adaptive verification and authorization</li><li>Authenticate users and devices through the Enterprise Federated Identity Service (EFIS)</li><li>Implement Just-in-Time and Just-Enough access policies</li><li>Label and classify data through machine learning</li><li>Utilize advanced analytical techniques to automate threat detection and coordinate according to pre-designed strategies.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Research </category>
          
          <category> Thesis </category>
          
          <category> Zero Trust </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Master&#39;s Thesis </tag>
            
            <tag> Zero Trust </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NIST SP 800-209 Security Guidelines for Storage (2)</title>
      <link href="/en/posts/security-for-storage-infra-2/"/>
      <url>/en/posts/security-for-storage-infra-2/</url>
      
        <content type="html"><![CDATA[<h1 id="Introduction">Introduction</h1><p>Due to concerns about the length of the previous article <a href="/security-for-storage-infra">NIST SP 800-209 Security Guidelines for Storage (1) Threats and Risks</a>, a new post has been created to organize the content.</p><div class="note info flat"><p>The previous article primarily addressed threats, risks, and attack surfaces related to inventorying storage infrastructure. This article focuses on summarizing security recommendations for storage deployments. The contribution of this thesis lies in emphasizing measures that align with zero trust requirements and security standards such as SP800-209 related to data storage.</p></div><h1 id="4-Security-Guidelines-for-Storage-Deployments">4. Security Guidelines for Storage Deployments</h1><p>Sections 4.1 to 4.12 provide security recommendations and guidelines for storage infrastructure security. Each guideline is uniquely identified through a naming and numbering scheme, with the primary identifier taking the form of “<em>xx-SS-Ry</em>.”</p><p>However, because this thesis focuses on security measures related to connections between AP (clients) and storage devices and the security measures of the hosts themselves, this chapter will not list all security recommendations but will only highlight those related to AP (clients) and storage devices or the “storage infrastructure itself.”</p><div class="note info flat"><ol><li>“xx” represents two letter combinations related to the section title. For example, in section 4.1 “Physical Storage Security,” the primary identifier is marked as PS-SS-R1, PS-SS-R2, etc.</li><li>“SS” stands for “Storage Security.”</li><li>“y” is a consecutive numeric identifier, with further details denoted by “a,” “b,” such as ‘PS-SS-R1.a’ (following NIST SP 800-53, section 3.10), ‘PS-SS-R1.b’ (Supply Chain Protection), and so on.</li></ol></div><div class="note warning flat"><p>My insight: This chapter can be used to compile a checklist for inspecting security measures related to AP, AP Hosts themselves, storage device Hosts themselves, and the connection between them. This checklist can be used as part of the authorization and access control process to mitigate potential security threats.</p></div><h1 id="4-1-PS-Physical-Storage-Security">4.1 (PS) Physical Storage Security</h1><p>Physical security is a fundamental element of ensuring the security of any information technology infrastructure. Often, requirements for the “physical security of storage infrastructure” align with those of other infrastructure elements, such as computers and network devices, including facility security, monitoring, and transportation.</p><ul><li>Relevant standards for infrastructure elements include NIST SP 800-53, Rev5, and NIST SP 800-171.</li><li>Further discussions on media disposal and destruction can be found in ISO 27040 and NIST SP 800-88.</li></ul><div class="note info flat"><p>Therefore, this chapter mainly provides regulations for “physical security unique to storage infrastructure” or aspects less emphasized in other publications.</p></div><details class="toggle" ><summary class="toggle-button" style="">Requirement: PS-SS-R1 Ensure media security measures</summary><div class="toggle-content"><table><thead><tr><th><div style="width:100px"><code>PS-SS-R1</code></div></th><th>Ensure media security</th></tr></thead><tbody><tr><td><code>PS-SS-R1.a</code></td><td>Recommend following specific guidance from <em>NIST SP 800-53, Rev5</em>, including policy development, access restrictions, sensitive information labeling, secure storage, secure transmission, data clearing, and the use of encryption.</td></tr><tr><td><code>PS-SS-R1.b</code></td><td>Recommend purchasing media with <em>adequate supply chain protection</em>.</td></tr><tr><td><code>PS-SS-R1.c</code></td><td>For sensitive data, the distance between “backup physical” media storage and “primary data storage” locations should be sufficient.</td></tr><tr><td><code>PS-SS-R1.d</code></td><td>Maintain a list of sensitive data and record details, including sensitivity level, classification (related to which applications and services), encryption level, potential impact on the system in case of data compromise or loss, emergency measures and procedures, and data dependencies with other applications.</td></tr><tr><td><code>PS-SS-R1.e</code></td><td>Sensitive removable media should use advanced tracking control measures, such as RFID tags, GPS tracking devices, and tamper-evident protection.</td></tr><tr><td><code>PS-SS-R1.f</code></td><td>Consider using self-destruct mechanisms for extremely sensitive information, with careful consideration of how to protect these features from being targeted by attackers to trigger device destruction mechanisms.</td></tr></tbody></table></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: PS-SS-R2 Protect all sensitive administrative equipment</summary><div class="toggle-content"><p>Measures for “management workstations” that can access storage facilities should include:</p><ol><li><code>Organization-approved security controls</code>: Management access to storage infrastructure, including access, monitoring, and auditing, should be managed using organization-approved security controls.</li><li><code>Security at least as stringent as data protection</code>: Security measures for “management workstations” (including home-based workstation environments) accessing storage facilities should be at least as strict as those for “data protection” or “systems using data.”</li></ol></div></details><details class="toggle" style="border: 1px solid  including non-obvious storage components"><summary class="toggle-button" style="background-color:  including non-obvious storage components;">Requirement: PS-SS-R3 Data sanitization approach should cover storage infrastructure in detail</summary><div class="toggle-content"><ul><li>Data sanitization approaches should cover various components within the storage infrastructure, which may contain sensitive information. Ensure that components within the storage infrastructure are included in the organization’s data sanitization policy. These components include:<ul><li>Non-volatile memory</li><li>Cache objects (storage arrays, SAN switches, routers, etc.)</li><li>Firmware/BIOS settings and HBA-level configurations</li></ul></li></ul></div></details><h1 id="4-2-DP-Data-Protection">4.2 (DP) Data Protection</h1><p>This section primarily discusses various measures, perspectives, and levels of separation for data protection. Relevant requirements should consider the following aspects:</p><details class="toggle" ><summary class="toggle-button" style="">Different Aspects of Data Protection</summary><div class="toggle-content"><p>In this section, we mainly discuss the objectives and related activities of data protection, controlling them from various perspectives, including:</p><ol><li><em>Data Backup and Recovery</em>: This is a crucial control measure to ensure data recovery after unexpected failures or catastrophic events.</li><li><em>Archiving</em>: This is a control measure to retain data in long-term storage, typically used for preserving historical data or data required by regulations.</li><li><em>Replication Technologies</em>: This involves creating data copies between different locations or systems as a control measure to ensure availability in case of primary system failures.</li><li><em>Continuous Data Protection</em>: This is a control measure that involves continuous monitoring of data changes and real-time backups, allowing for rapid recovery to specific points in time.</li><li><em>Point-in-Time Copies and Snapshots</em>: This control measure involves copying data at specific points in time for restoration or querying when needed.</li></ol></div></details><details class="toggle" ><summary class="toggle-button" style="">Identification of Data Planes</summary><div class="toggle-content"><p>When discussing storage management and data protection, <em>distinguishing between different data planes</em> is crucial for a <em>better understanding and management of storage systems</em>. This is because data planes provide a way to organize and differentiate access methods, protocols, operations, and permissions related to data, ensuring that the system operates effectively on different levels. The main types of data planes include:</p><ol><li><em>Data Consumption Plane</em>: This plane involves access methods and protocols for performing I/O operations, as well as related network connections. It is the plane where users and applications read and write data.</li><li><em>Data Management Plane</em>: This plane involves the management of metadata and configuration information related to data, such as creating, configuring, and mapping devices. It focuses on managing data’s metadata and configuration information within storage systems.</li><li><em>Data Protection Plane</em>: This plane is concerned with data protection and backup operations, including copying, snapshots, backups, archiving, etc., to ensure data persistence and disaster recovery capabilities.</li></ol></div></details><details class="toggle" ><summary class="toggle-button" style="">Level of Separation for Data Planes</summary><div class="toggle-content"><p>In general, <em>increasing the granularity and separation of data planes can positively impact the security of data assets</em>, and the designs and implementations that can have a significant impact include:</p><ol><li><em>Two-layer separation at the network layer</em>: For example, using different VLANs to increase separation.</li><li><em>Logical network separation</em>: Using separate IP subnets to increase separation.</li><li><em>Filtering and Access Control Lists (ACLs)</em>: Adding ACLs to the data consumption plane to prevent management operations, increasing the separation between “consumption” and “management” planes.</li><li><em>Authorization Separation</em>: Restricting permissions for each role, using different roles for different planes.</li></ol></div></details><div class="note info flat"><p>In this section, rigorous recommendations for the implementation of each of the above control measures are also provided. Additionally, <em>other related requirements are included in sections 4.7 “Isolation” and 4.8 “Recovery Assurance,” as these requirements are closely related to data protection</em>.</p></div><h2 id="4-2-1-Data-Backup-Recovery-and-Archiving">4.2.1 Data Backup, Recovery, and Archiving</h2><details class="toggle" ><summary class="toggle-button" style="">Requirement: DP-SS-R1 Document Data Protection Plan or Policy</summary><div class="toggle-content"><p>This document aims to ensure that the organization has a comprehensive and secure data protection plan in place before deploying systems or data storage solutions to address potential data corruption, failures, or security issues. These measures will help to ensure data integrity and availability while ensuring compliance with relevant regulatory requirements.</p><table><thead><tr><th><code>DS-SS-R1</code></th><th>Document Data Protection Plan or Policy</th></tr></thead><tbody><tr><td><code>DP-SS-R1.a</code></td><td>Specifications for levels, frequencies, and backup quantities to meet the organization’s recovery objectives should be included. This should encompass:<br> - Frequencies and retention periods, e.g., snapshots every 48 hours, daily backups.<br> - Types, e.g., full backups, incremental backups, continuous backups (such as file version control, logs, or log shipping and archiving), replication, point-to-point backups, etc.</td></tr><tr><td><code>DP-SS-R1.b</code></td><td>Types of media to be used.</td></tr><tr><td><code>DP-SS-R1.c</code></td><td><em>Encryption requirements</em> applied to “backup data” should be at least as strong as the encryption level for “protected data.”</td></tr><tr><td><code>DP-SS-R1.d</code></td><td>Other protection requirements, such as digital signatures, archiving, location, facility security (including fire, explosion, and magnetic interference protection), immutability and locking, minimum number of backups per backup set, and geographic distribution of these backups.</td></tr><tr><td><code>DP-SS-R1.e</code></td><td>Reference applicable regulatory frameworks and associated controls.</td></tr><tr><td><code>DP-SS-R1.f</code></td><td><em>Comprehensive lifecycle management and disposal policies</em> for backup media should be included.</td></tr><tr><td><code>DP-SS-R1.g</code></td><td><em>Data recovery testing and verification</em> should be planned, including a minimum number of yearly recovery tests, which should include data recovery and system recovery.</td></tr><tr><td><code>DP-SS-R1.h</code></td><td>A reference to other security-related documents and policies.</td></tr></tbody></table></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: DP-SS-R2 Backups and Replication</summary><div class="toggle-content"><p>Backups and replication are fundamental components of data protection, ensuring data availability in the event of data loss or system failures. Organizations must establish comprehensive policies and procedures for backups and replication to meet their data recovery objectives.</p><table><thead><tr><th><code>DS-SS-R2</code></th><th>Backups and Replication</th></tr></thead><tbody><tr><td><code>DP-SS-R2.a</code></td><td><em>Regular and automated backups</em> of critical data should be performed according to the organization’s data protection plan. These backups must include all data necessary for the recovery of systems and data assets.</td></tr><tr><td><code>DP-SS-R2.b</code></td><td>Data backups should be securely stored and protected from unauthorized access or tampering. Off-site or remote backups should be considered to protect against physical disasters or site failures.</td></tr><tr><td><code>DP-SS-R2.c</code></td><td><em>Data replication</em> should be considered to ensure data availability and minimize downtime in the event of primary system failures.</td></tr><tr><td><code>DP-SS-R2.d</code></td><td>Backup and replication processes should be monitored and audited regularly to ensure their effectiveness and adherence to the organization’s data protection plan.</td></tr><tr><td><code>DP-SS-R2.e</code></td><td>Regularly test the restoration process for backups and validate the integrity of replicated data to ensure successful recovery in case of failures.</td></tr><tr><td><code>DP-SS-R2.f</code></td><td>Implement a process for <em>automated detection and alerting</em> of backup or replication failures.</td></tr></tbody></table></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: DP-SS-R3 Archiving of Data</summary><div class="toggle-content"><p>Archiving is essential for preserving historical data, complying with regulatory requirements, and ensuring data availability when needed. Organizations should have policies and procedures for data archiving.</p><table><thead><tr><th><code>DS-SS-R3</code></th><th>Archiving of Data</th></tr></thead><tbody><tr><td><code>DP-SS-R3.a</code></td><td><em>Establish archiving policies</em> that define the criteria for data to be archived, including data age, business value, and regulatory requirements.</td></tr><tr><td><code>DP-SS-R3.b</code></td><td>Archived data should be stored securely and protected against unauthorized access or tampering, similar to backup data.</td></tr><tr><td><code>DP-SS-R3.c</code></td><td>Implement mechanisms to efficiently retrieve and access archived data when needed, including indexing and search capabilities.</td></tr><tr><td><code>DP-SS-R3.d</code></td><td>Regularly review and update archiving policies to ensure they remain aligned with business needs and regulatory requirements.</td></tr><tr><td><code>DP-SS-R3.e</code></td><td>Archive data in a format that preserves its integrity and usability over time, taking into consideration long-term retention requirements.</td></tr></tbody></table></div></details><h2 id="4-2-2-Replication-and-Mirroring">4.2.2 Replication and Mirroring</h2><details class="toggle" ><summary class="toggle-button" style="">Requirement: DP-SS-R5 Consistency of Data Protection for Primary and Secondary Storage</summary><div class="toggle-content"><ul><li>Both synchronous and asynchronous “replication” require data protection at the same level as primary storage.</li><li>This includes encrypting data at rest and configuring access restrictions.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R6 Eliminating Unnecessary Replication Trust Between Storage Arrays</summary><div class="toggle-content"><ul><li>When there are no shared replicated volumes between arrays, the replication trust relationship between them should be <em>disabled</em>.</li><li>When there are shared replicated volumes between arrays, privileges for replication trust between them should be limited to the shared volumes only.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: DP-SS-R7 Data Protection During Transmission for Replication and Mirroring</summary><div class="toggle-content"><ul><li>During replication and mirroring, data confidentiality and integrity during “transmission” should be <em>protected using encryption</em>.</li><li>Encryption requirements can be relaxed when appropriate mitigation controls are in place, such as when mirroring occurs within the same cabinet or server room.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: DP-SS-R8 Automatic I/O Pause for Synchronous Replication</summary><div class="toggle-content"><ul><li>When the synchronous progress of secondary storage servers lags behind the updates on primary data, the <em>automatic I/O pause feature</em> should be enabled to prevent write operations on the primary storage device. Continuing to allow write operations on the primary storage device may result in<ul><li>Data inconsistency and data loss risks.</li></ul></li><li>However, please note that <em>enabling this feature increases the risk of attacks on the primary storage device</em>, as adversaries may attack the replication network path to trigger denial of service on the primary storage device.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: DP-SS-R9 Deleting Outdated Replicas to Reduce the Attack Surface</summary><div class="toggle-content"><ul><li>Regularly <em>delete outdated replicas</em> to reduce the attack surface.</li></ul></div></details><h2 id="4-2-3-Point-in-Time-Copies">4.2.3 Point-in-Time Copies</h2><details class="toggle" ><summary class="toggle-button" style="">Requirement: DP-SS-R10 Meeting Target Requirements for Point-to-Point Copies</summary><div class="toggle-content"><ul><li>Ensure that the configuration of point-to-point copies (e.g., snapshots) meets the <em>Recovery Point Objective (RPO)</em> requirements of the target dataset.</li><li>If business or compliance standards require that no more than <em>five minutes of committed data can be lost during recovery</em>, then the <em>snapshot interval should be five minutes or shorter</em>.<ul><li>Ensure the configuration includes a sufficient number of hourly snapshots to meet retention requirements.</li></ul></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: DP-SS-R11 Deleting Outdated Snapshots and Clones</summary><div class="toggle-content"><p>Regularly <em>delete outdated snapshots and clones</em> to reduce the attack surface.</p></div></details><h2 id="4-2-4-Continuous-Data-Protection">4.2.4 Continuous Data Protection</h2><details class="toggle" ><summary class="toggle-button" style="">Requirement: DP-SS-R12 Security Considerations for Continuous Data Protection</summary><div class="toggle-content"><ol><li>Functional Advantages: Improved <em>Recovery Point Objectives (RPO)</em>, more <em>granular retention policies</em>.</li><li>Technologies for Continuous Data Protection: Includes Continuous Data Protection (CDP), <em>version control</em> of “source data or copies” in cloud file and object storage, and “transaction log shipping.”</li><li>Assisting in <em>enhancing the forensics of sensitive data</em>: Backtracking to previous versions can help understand attack characteristics, timing, etc., but may be time-consuming.</li></ol></div></details><h1 id="4-3-AC-Authentication-and-Data-Access-Control">4.3 (AC) Authentication and Data Access Control</h1><p>Managing users and their managed hosts is an attack surface that attackers can exploit, and improper use of privileged users can lead to storage system failures or compromises. Implementing the “<em>least privilege model</em>” and utilizing specific roles for administration is crucial.</p><p>According to ISO/IEC 27040 standards, the following roles should be implemented and used in storage technologies: Security Administrator, Storage Administrator, and Security Auditor. These roles are designed to ensure the security of storage technology, restrict privileged access, and reduce the risk of attacks.</p><p>Below is a table summarizing the permissions and responsibilities of these roles:</p><details class="toggle" ><summary class="toggle-button" style="">Security Administrator</summary><div class="toggle-content"><table><thead><tr><th>Permissions Owned</th><th>Responsibilities</th><th>Not Allowed</th></tr></thead><tbody><tr><td>View and modify permissions</td><td>- Create and manage <code>accounts</code><br>- Set up and manage <code>roles and permissions</code> for users and administrative operations<br>- Formulate policies related to <code>validators, credentials, and keys</code><br>- Manage encryption and keys<br>- Manage <code>audit and logging</code></td><td>None</td></tr></tbody></table></div></details><details class="toggle" ><summary class="toggle-button" style="">Storage Administrator</summary><div class="toggle-content"><table><thead><tr><th>Permissions Owned</th><th>Responsibilities</th><th>Not Allowed</th></tr></thead><tbody><tr><td>Storage Administrator</td><td>View and modify permissions</td><td>- Access and manage all aspects of storage systems</td></tr></tbody></table></div></details><details class="toggle" ><summary class="toggle-button" style="">Security Auditor</summary><div class="toggle-content"><table><thead><tr><th>Permissions Owned</th><th>Responsibilities</th><th>Not Allowed</th></tr></thead><tbody><tr><td>Security Auditor</td><td>View permissions</td><td>- Conduct <code>authorization reviews</code><br>- <code>Validate security parameters</code> and configurations<br>- Check <code>audit logs</code></td></tr></tbody></table></div></details><details class="toggle" ><summary class="toggle-button" style="">Storage Auditor</summary><div class="toggle-content"><table><thead><tr><th>Permissions Owned</th><th>Responsibilities</th><th>Not Allowed</th></tr></thead><tbody><tr><td>Security Auditor</td><td>View permissions</td><td>- Conduct <code>authorization reviews</code><br>- <code>Validate security parameters</code> and configurations<br>- Check <code>audit logs</code></td></tr></tbody></table></div></details><h2 id="4-3-1-Authentication-Recommendations">4.3.1 Authentication Recommendations</h2><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R1 Unique Identifier for all users</summary><div class="toggle-content"><ol><li>All users, including administrators, should have a unique identifier for personal use only.</li><li>The identifiers assigned to administrators should meet at least Identity Assurance Level 3 (IAL 3) as specified in NIST document SP800-63A [35] sections 4.2 and 4.5.</li><li>The only exception is emergency use accounts, which are governed by AC-SS-R16.</li></ol></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R2 Centralized Authentication Solution</summary><div class="toggle-content"><ol><li>In large environments, a centralized authentication solution (e.g., Active Directory, Lightweight Directory Access Protocol [LDAP], Single Sign-On [SSO], organization-approved cloud authentication services) should be deployed to closely monitor and control user access to storage resources.</li><li>Ensure consistent enforcement of the organization’s authentication policies.</li><li>Avoid using built-in authentication and permission management functions and preferably disable them.</li></ol></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R3 Configuration of Authentication Servers</summary><div class="toggle-content"><table><thead><tr><th><code>DS-SS-R3</code></th><th>Requirement Details</th></tr></thead><tbody><tr><td><code>AC-SS-R3.a</code></td><td><em>Strictly control the assignment of servers performing authentication services</em>: Specify servers that perform authentication service to specific servers and ensure such assignments are rigorously managed and controlled.</td></tr><tr><td><code>AC-SS-R3.b</code></td><td><em>Multiple authentication servers should be in place</em>: To ensure availability and avoid a single point of failure.</td></tr></tbody></table></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R4 Secure Connection to Centralized Authentication Server</summary><div class="toggle-content"><ol><li>Communication between the centralized authentication server and authentication clients should use the latest security protocols, such as Transport Layer Security (TLS) 1.2 or higher.</li></ol></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R5 Use of Multi-Factor Authentication</summary><div class="toggle-content"><ol><li>Access configurations for infrastructure components storing critical data should employ at least two-factor authentication.</li><li>These authenticators should meet at least the requirements specified in NIST document SP800-63B [36] section 5.1.9. This requirement should be mandatory for users in the roles of Security Administrators and Storage Administrators.</li></ol></div></details><h2 id="4-3-2-Password-Recommendations">4.3.2 Password Recommendations</h2><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R6 Secure Password Policies Should Cover Service Accounts</summary><div class="toggle-content"><ol><li>Secure password policies should apply not only to personal accounts but also to service accounts (e.g., Simple Network Management Protocol (SNMP), Network Data Management Protocol (NDMP), and accounts used by automation tools).</li><li>These passwords should at least meet the requirements for memorized secrets as described in NIST document SP800-63B [36] section 5.1.1.</li></ol></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R7 Password Length</summary><div class="toggle-content"><ul><li>A strong password should have a minimum of 15 characters, preferably 20 characters.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R8 Password Complexity</summary><div class="toggle-content"><ul><li>A strong password should include a combination of uppercase and lowercase letters, numbers, and special characters. It should not resemble the username and should not contain repeated character sequences.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R9 Password Expiration</summary><div class="toggle-content"><ul><li>All passwords should have expiration times set. The expiration time for administrator accounts should be shorter than for regular user accounts.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R10 Password Reuse</summary><div class="toggle-content"><ul><li>Users should not reuse the most recent four (or more) passwords, depending on organizational risk factors.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R11 Password Caching</summary><div class="toggle-content"><table><thead><tr><th>Standard</th><th>Requirement Details</th></tr></thead><tbody><tr><td><code>AC-SS-R11.a</code></td><td>Passwords should not be cached on servers, desktops, or any other systems.</td></tr><tr><td><code>AC-SS-R11.b</code></td><td>Sufficiently short Time to Live (TTL) or equivalent control mechanisms should be used.</td></tr></tbody></table></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R12 Saving Passwords</summary><div class="toggle-content"><ul><li>Passwords should not be saved in plaintext anywhere (e.g., documents or scripts).</li><li>Even if passwords are stored in encrypted form, enabling storage management applications to locally remember usernames and passwords for automatic login should be strictly prohibited unless managed through authorized central authentication services (such as LDAP SSO).</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R13 Eliminate or Change Default Passwords</summary><div class="toggle-content"><ul><li>Default passwords that come with system installations or deployments should be changed immediately.</li></ul></div></details><h2 id="4-3-3-Account-Management-Recommendations">4.3.3 Account Management Recommendations</h2><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R14 Use of accounts not associated with system users</summary><div class="toggle-content"><ul><li><em>Disable accounts not associated with any users</em>, such as those not present in Active Directory, like “guest,” “anonymous,” “nobody.”</li><li>Their default configurations, such as passwords and permissions, should be changed per the organization’s policy scope.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R15 Account lockout</summary><div class="toggle-content"><ul><li>After a <em>certain number of failed login attempts</em>, the user should be <em>locked out</em>.</li><li>Some implementations of account lockout include <em>automatic resets (account unlocking) after a certain time or power cycle</em>.</li><li>Automatic reset should not be allowed on sensitive storage systems.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R16 A local user account for emergency purposes</summary><div class="toggle-content"><ul><li>A separate local user account should be reserved for providing <em>emergency-only access to storage resources</em> in case the “central authentication system” is unavailable.</li><li>This account should comply with:<ul><li>All organizational policies (e.g., password length).</li><li>Its usage should be restricted to specific, secure locations.</li><li>Follow well-documented procedures, including <em>appropriate approvals and notifications to relevant stakeholders</em>.</li></ul></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R17 Eliminate or disable default user accounts</summary><div class="toggle-content"><ul><li>Default user accounts that come with system installations should be <em>eliminated or disabled</em> if associated functionalities exist.</li><li>If the elimination or deactivation of default user accounts’ functionality is not possible or there is a legitimate reason to retain any account, <em>AC-SS-R18 requirements should be met</em>.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R18 Limit local and default user accounts</summary><div class="toggle-content"><table><thead><tr><th>Requirement</th><th>Requirement Details</th></tr></thead><tbody><tr><td><code>AC-SS-R18.a</code></td><td><em>Limit</em> the use of such accounts and their <em>assigned privileges</em>.</td></tr><tr><td><code>AC-SS-R18.b</code></td><td><em>Password policies</em> should apply to all users, local and default accounts, including accounts with administrative privileges.</td></tr></tbody></table></div></details><h2 id="4-3-4-Privilege-and-Session-Management-Recommendations">4.3.4 Privilege and Session Management Recommendations</h2><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R19 Role and Responsibility Configuration</summary><div class="toggle-content"><ol><li>At least <em>four roles</em> specified in the ISO standard ISO/IEC 27040 [10] (i.e., <em>Security Administrator, Storage Administrator, Security Auditor, and Storage Auditor</em>) should be implemented for access to all storage resources.</li><li>Ensure that storage products have sufficiently granular role control mechanisms for handling sensitive information, and if the storage product does not have such functionality, it can achieve similar effects through compensatory controls.</li></ol></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R20 Follow the Principle of Least Privilege</summary><div class="toggle-content"><p>Follow the “Principle of Least Privilege” to assign privileges to roles and assign roles to users. It should include at least the following:</p><table><thead><tr><th>Standard</th><th>Requirement Details</th></tr></thead><tbody><tr><td><code>AC-SS-R20.a</code></td><td>Assign privileges for “Data Management” and privileges for “Data Protection” to different roles, and these two roles should not be assigned to the same user.</td></tr><tr><td><code>AC-SS-R20.b</code></td><td>Assign privileges for “Data Management” and privileges for “Host Management” to different roles, and these two roles should not be assigned to the same user.</td></tr></tbody></table><p>Additionally:</p><ul><li>Data Management: Permissions related to tasks such as creating new storage volumes or sharing resources for the normal operation of storage resources.</li><li>Data Protection: Permissions related to configuring, stopping, or deleting backups, ensuring the security of stored data, and preventing data loss.</li><li>Host Management: Tasks such as creating/deleting objects in storage controllers, permissions related to managing the hardware and infrastructure of storage systems.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R21 Principle of Least Privilege</summary><div class="toggle-content"><ul><li>Any privileges assigned to roles should follow the “Principle of Least Privilege.”</li><li>The permissions allocated to roles should not exceed what is required for the functions they perform, such as accessing specific storage resources like block devices, files, objects, etc.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R22 Secure Session Management</summary><div class="toggle-content"><ul><li>All sessions between clients and storage infrastructure systems should be managed according to the required levels of authentication assurance, as per the requirements of [63B] Section 7, including termination and automatic logout.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AC-SS-R23 Implement Daily Message and Login Banner Notifications</summary><div class="toggle-content"><ul><li>“Daily Message” or “Login Banner” notifications should be displayed before logging into any storage infrastructure component or system through the user interface (UI), command-line interface (CLI), or application programming interface (API), if applicable. The message should include legal statements:<ul><li>“Warning users are accessing restricted systems with sensitive data.”</li><li>And provide any other warnings and meaningful messages per the organization’s security and privacy policies.</li></ul></li></ul></div></details><h2 id="4-3-5-SAN-Specific-Recommendations">4.3.5 SAN-Specific Recommendations</h2><div class="note info flat"><ul><li>SAN stands for Storage Area Network, which is used for data transmission between storage devices and servers.</li><li>It typically consists of specialized hardware and software and uses high-speed connectivity technologies such as Fibre Channel or Ethernet for efficient, low-latency data transfer.</li><li>SAN’s storage resources are seen as local disks on servers, allowing servers to access and manage these storage devices through SAN.</li></ul></div><p>Access control topics related to SAN involve multiple aspects. Some aspects overlap with <em>network configuration and access management</em>, which have already been covered in other sections. To gain a comprehensive understanding of all aspects of access control, please refer to the content in these three sections:</p><ul><li>Access control recommendations related to “Network Infrastructure” (e.g., switches, ports, host bus adapters, and network interface cards) and “Protocols” can be found in Section 4.6 with detailed discussions.</li><li>Encryption of data during <em>transmission</em> (one of the mechanisms of access control) is discussed in detail in Section 4.9.</li><li><em>Access management</em> is discussed in detail in Section 4.10.</li></ul><p>This section primarily discusses “data-related” access control in SAN, covering access control for block devices, implementing zoning, and access control specifications for Fibre Channel.</p><details class="toggle" style="border: 1px solid  SSD"><summary class="toggle-button" style="background-color:  SSD;color:  etc.)">Note: AC-SS-R24 - Access Control for Block Devices (HDD</summary><div class="toggle-content"><p>Access to a set of Storage Area Network (SAN) devices by a set of hosts should be restricted through zoning (software or hardware) and masking to achieve the minimum required access permissions.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Note: AC-SS-R25 - Access Control for Block Device Copies and Replicas</summary><div class="toggle-content"><ul><li>Access to a set of SAN-copied block devices, snapshots, and other types of point-in-time replicas by a set of hosts should be restricted through partition zoning and masking to achieve the minimum required access permissions.</li><li>In many cases, hosts granted access should not be allowed to access replicas.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Note: AC-SS-R26 - Permissions for Default Zones</summary><div class="toggle-content"><ul><li>The permissions for default zoning (possibly product-specific) should always be configured as “deny all.”</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Note: AC-SS-R27 - Implementation of Zoning</summary><div class="toggle-content"><p>Zoning should be implemented based on reasonable logic in a switched SAN architecture, especially with relevance to “environments” and “traffic” types, which should be separated as much as possible:</p><table><thead><tr><th>Requirement</th><th>Requirement Details</th></tr></thead><tbody><tr><td><code>AC-SS-R27.a</code></td><td>Environments: Development, testing, production, etc.</td></tr><tr><td><code>AC-SS-R27.b</code></td><td>Traffic Types: Data access, management, copying, backup, etc.</td></tr><tr><td><code>AC-SS-R27.c</code></td><td>Host Types: Virtualized, physical hosts.</td></tr><tr><td><code>AC-SS-R27.d</code></td><td>Storage Device Types: Tape, disk.</td></tr></tbody></table></div></details><details class="toggle" ><summary class="toggle-button" style="">Note: AC-SS-R28 - Implementation of Software Zoning</summary><div class="toggle-content"><p>When implementing software zoning, only allow hosts to connect to storage devices through Simple Name Servers (SNS) by consulting the software zoning table rather than directly using device discovery.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Note: AC-SS-R29 - Control Over Devices That Can Join the SAN</summary><div class="toggle-content"><ul><li>In SAN, there is a policy-defined feature that can “create a whitelist” listing the switches, data storage devices, and hosts that can join the storage area network. It is recommended to fully utilize this feature where applicable.</li></ul></div></details><h2 id="4-3-6-File-and-Object-Access-Recommendations">4.3.6 File and Object Access Recommendations</h2><details class="toggle" ><summary class="toggle-button" style="">Note: AC-SS-R30 - Limit Access to All Types of Object Storage Data to a Minimum</summary><div class="toggle-content"><p>Limit access to all types of object storage data (e.g., files, objects) following the “Principle of Least Privilege,” including:</p><table><thead><tr><th>Requirement</th><th>Requirement Details</th></tr></thead><tbody><tr><td><code>AC-SS-R30.a</code></td><td>Restrict access to object storage data via any protocol based on client IP and/or relevant subnets while requiring specified ports/protocols.</td></tr><tr><td><code>AC-SS-R30.b</code></td><td>Use more granular access control mechanisms (e.g., by roles, IDs, tags, accounts, Virtual Private Clouds (VPCs), VPC endpoints, etc.).</td></tr><tr><td><code>AC-SS-R30.c</code></td><td>Access permissions should be granted only to centrally managed users and roles, such as users in the <em>enterprise directory</em> or <em>approved business services</em>, and not to specific system-local users.</td></tr><tr><td><code>AC-SS-R30.d</code></td><td>For any shares, set default access permissions to “deny all” or equivalent settings.</td></tr><tr><td><code>AC-SS-R30.e</code></td><td>Default shares should be disabled or deleted. If they are needed for specific purposes, access permissions should be restricted to the minimum required.</td></tr><tr><td><code>AC-SS-R30.f</code></td><td>Access permissions (e.g., read, write, execute, modify, delete, view ACLs, change ACLs) should be individually assigned based on the “Need to Know” principle.</td></tr><tr><td><code>AC-SS-R30.g</code></td><td>If available, use features that define object storage ACLs and use the user, group, or administrator permission model of the local operating system.</td></tr><tr><td><code>AC-SS-R30.h</code></td><td>If policy definition features for file-level access patterns are available, utilize them and implement the ability to detect policy violations and send notifications.</td></tr></tbody></table><div class="note warning flat"><p>Note: “Need to know” is an information security principle that emphasizes that individuals should only have access to sensitive information or resources if they have a legitimate requirement to know or are authorized to perform specific tasks. This principle applies to various situations, including data access permissions, network access permissions, access to confidential documents, and more.</p></div></div></details><details class="toggle" ><summary class="toggle-button" style="">Note: AC-SS-R31 - Disable Unauthenticated Users</summary><div class="toggle-content"><ul><li><em>Unauthenticated users should be disabled (e.g., anonymous, empty, guest, or “public access” users)</em>.</li><li>Exceptions may be provided to allow critical organizational functions, such as network discovery, but in such cases, these users should be mapped to the “nobody” user group rather than “ID 0.”</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Note: AC-SS-R32 - Regularly Review Security Settings</summary><div class="toggle-content"><ul><li>Regularly <em>review the security settings of all stored data</em> mentioned above, including various types of data (e.g., files, objects), to ensure no deviations.</li><li>Record the results of the reviews.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Note: AC-SS-R33 - Use Anti-Malware Scanning Tools</summary><div class="toggle-content"><ul><li>Use anti-malware tools to scan sensitive information files.</li><li>Whenever “access” involves “sensitive information” in “files,” <em>first scan with organization-approved anti-malware tools</em> to ensure the files are not compromised.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Note: AC-SS-R34 - Implement Fine-Grained Permission Assignments</summary><div class="toggle-content"><ul><li>Implement fine-grained permission assignments:<ul><li>For file and object sharing systems (e.g., NFS, CIFS, cloud object storage), use <em>more granular permission granting</em>.</li><li>Do not use coarser-grained methods (e.g., <em>controlling files or objects instead of controlling entire folders</em>, or controlling shares or storage buckets).</li></ul></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Note: AC-SS-R35 - Restrict Root Access to Protect NFS</summary><div class="toggle-content"><ul><li>Restrict root access to protect NFS, including using the “nosuid” option.</li><li>Avoid using “no_root_squash” to <em>prevent programs on clients from running as the root user</em>.</li><li>And <em>avoid remote root users from modifying shared files</em>. In general, NFS clients should not be allowed to <em>run “suid” and “sgid” programs</em> on exported file systems.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Note: AC-SS-R36 - Set noexec Option to Prevent Execution of Executable Files</summary><div class="toggle-content"><ul><li>Require that NFS shares that are <em>set to “read only” mode</em> have the “noexec” option added to their mount configurations to <em>prevent the execution of executable files</em> on the share.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Note: AC-SS-R37 - Do Not Export Administrative File Systems</summary><div class="toggle-content"><ul><li><em>Do not export administrative file systems</em>, including the ‘/’ file system and restricted operating system or storage array system folders.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Note: AC-SS-R38 - Do Not Grant Full Control Permissions to Any Users</summary><div class="toggle-content"><ul><li>When using CIFS, do not grant “full control” permissions to any users, as recipients may use this permission to modify permissions, leading to privilege leakage.</li></ul><div class="note info flat"><p>CIFS stands for Common Internet File System. It is a protocol used for sharing files and resources over computer networks. CIFS was originally developed by Microsoft for file sharing in Windows operating systems.</p><p>The CIFS protocol allows different computers to share files over a network, enabling users to access and manipulate files on other computers over the network, similar to accessing local files. This facilitates resource sharing among users, including documents, images, audio, video, and more.</p></div></div></details><details class="toggle" ><summary class="toggle-button" style="">Note: AC-SS-R39 - Use Object Locking to Prevent Unauthorized Deletion</summary><div class="toggle-content"><ul><li>For <em>sensitive information</em>, if supported, <em>use advanced controls</em> to prevent <em>unauthorized object deletion</em>.</li><li>(For example, requiring <em>multi-factor authentication when deleting objects</em> or locking objects to prevent deletion).</li></ul></div></details><h1 id="4-4-AL-Audit-Log">4.4 (AL) Audit Log</h1><p>Storage infrastructure components generate event log records for a large number of transactions or events. These event log records must be logged in some way for auditing purposes.</p><ul><li>From a <code>security</code> or <code>compliance</code> perspective, it is important to capture those necessary event log records to provide evidence of operations.</li><li>It enforces accountability and traceability, meets evidence requirements, and provides adequate monitoring of the system.</li></ul><p>The following are security-related audit log events:</p><ol><li><code>Administrative Events</code> - Related to the administration of system permissions.<ul><li>For example, resetting user passwords, account creation/deletion, permission modifications, role changes, group membership changes, privilege operations, and configuration creation/changes.</li></ul></li><li><code>Security-Related Events</code> - Events that can result in security incidents, such as changes to system security configurations and authorization error messages.<ul><li>For example, changes to user configurations and security configurations, failed/block attempts to access storage, and blocked login attempts. These events are often of interest, although some may overlap with administrative events.</li></ul></li><li><code>Data Access Events</code> - Events related to data access, and monitoring access to sensitive information (e.g., determining what an adversary may have accessed) is helpful.</li></ol><p>The following are consequences of not properly documenting audit logs:</p><ul><li>Insufficient security logs and analysis allow attackers to hide their location, malware, and activities on victim machines.</li><li>Lack of reliable audit logs means that attacks can go undetected for an extended period, and the actual damage caused may be irreversible.</li><li>Due to poor or nonexistent log analysis processes, attackers can sometimes control victims’ machines within the target organization for months or years without anyone in the target organization knowing, even though evidence of the attack could be in unreviewed log files.</li></ul><p>Given the criticality of event log data for attack detection and forensic investigations, here are security recommendations for implementing audit log functionality:</p><details class="toggle" ><summary class="toggle-button" style="">Requirement: AL-SS-R1 - Enable Audit Logging for Storage Infrastructure Components</summary><div class="toggle-content"><ul><li>This is an information security requirement that states that <code>all storage infrastructure components should enable audit logging</code> and use reliable transmission methods and secure communication protocols.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AL-SS-R2 - Requirement for Reliable External Time Synchronization</summary><div class="toggle-content"><ul><li>Network Time Protocol (NTP) service is crucial for time synchronization.</li><li>If NTP service is disabled:<ul><li>Dependent systems may receive inaccurate timestamps for messages, events, and alerts.</li><li>Time inconsistencies among different devices, making it impossible for log analysis, correlation analysis, anomaly detection, or forensics.</li></ul></li><li>Establish and <code>use a common and accurate time source</code> throughout the environment to ensure that event records from different sources can be correlated.</li><li>The following are recommendations for deploying and integrating NTP with storage-related devices:<br>| <div style="width:130px">Requirement</div> |  Requirement Content |<br>|---------|----------|<br>| <code>AL-SS-R2.a</code> | All devices (including log servers and storage infrastructure) should <em>enable the NTP service</em>. |<br>| <code>AL-SS-R2.b</code> | <em>Have devices</em> configured to synchronize time with <em>time source servers</em> (e.g., NTP servers). |<br>| <code>AL-SS-R2.c</code> | Access should only be granted to centrally managed users and roles, such as users in the enterprise <em>directory</em> or <em>approved business services</em>, and <code>not to specific system local users</code>. |<br>| <code>AL-SS-R2.d</code> | Establish <em>at least three independently located time servers</em> to ensure that even if one server fails or becomes unavailable, the other servers can still provide accurate time information. |<br>| <code>AL-SS-R2.e</code> | <em>Use certificates</em> to verify the identity of time source servers to ensure the security of the time synchronization service. |<br>| <code>AL-SS-R2.f</code> | - Access restrictions options like “ntpd” access restrictions can be utilized to limit access to time source servers. <br> - You can configure an access control list listing devices allowed or denied access to the time server. (e.g., configure <code>restrict 192.168.2.10</code> to allow only this IP to access). |</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AL-SS-R3 - Centralized Logging and Ensuring Reliability</summary><div class="toggle-content"><ul><li>By writing logs to a <em>central log server</em> (e.g., syslog server, cloud log service), the risk of log loss or tampering is reduced because they are more secure within the <em>internal network</em>. Here are recommendations for deploying and integrating centralized log logging with storage-related devices:<br>| <div style="width:130px">Requirement</div> |  Requirement Content |<br>|---------|----------|<br>| <code>AL-SS-R3.a</code> | The organization should “define” the organizational log record “standard” for storage devices and specify the required log record levels. (For more specific recommendations, see AL-SS-R4). |<br>| <code>AL-SS-R3.b</code> | “All devices” should be configured to transmit log event data to the organization’s approved “central log server” based on the applicable “organizational log record standard.” |<br>| <code>AL-SS-R3.c</code> | The effectiveness of the central log configuration should be monitored on all devices (e.g., log service stays active, log record levels are configured per organizational standard, each device is configured with an approved log server), and anomalies detected should be given high priority for resolution. |<br>| <code>AL-SS-R3.d</code> | Multiple syslog servers should be deployed to achieve continuous logging and prevent a single point of failure. |<br>| <code>AL-SS-R3.e</code> | At least one offline copy of each log should be retained. |<br>| <code>AL-SS-R3.f</code> | To prevent the loss of entries before stopping and restarting all log entries, log records should be configured to write to disk in real-time, without using buffering, and using reliable protocols. |</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AL-SS-R4 - Log Record Levels</summary><div class="toggle-content"><p>Storage audit logs should include (but are not limited to) the following events related to the protection of all storage-related objects, sites, and accounts:</p><table><thead><tr><th><div style="width:130px">Requirement</div></th><th>Requirement Content</th></tr></thead><tbody><tr><td><code>AL-SS-R4.a</code></td><td>In sensitive environments, Read-only API Calls.</td></tr><tr><td><code>AL-SS-R4.b</code></td><td>All “denied access attempts” to services, ports, files, objects, or devices should be logged.</td></tr><tr><td><code>AL-SS-R4.c</code></td><td>Log “encryption key management operations” covering the entire “key lifecycle operation” (especially encryption keys), such as key generation, key deletion, certificate management, etc., especially events related to key destruction should be recorded.</td></tr></tbody></table></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AL-SS-R5 - Audit Log Retention and Protection</summary><div class="toggle-content"><p>The following measures should be taken for audit log retention and protection:</p><table><thead><tr><th><div style="width:130px">Requirement</div></th><th>Requirement Content</th></tr></thead><tbody><tr><td><code>AL-SS-R5.a</code></td><td>There should be a “sufficiently long log data retention” period because it often takes time to detect ongoing or already occurred intrusion events.</td></tr><tr><td><code>AL-SS-R5.b</code></td><td>“Adequate storage space” should be allocated, and remaining space and abnormal growth rate of log data should be actively monitored to “prevent log destinations from filling up.” (Known attack patterns include “filling logs to hinder evidence collection,” and proper monitoring helps identify such attacks in real-time.)</td></tr><tr><td><code>AL-SS-R5.c</code></td><td>Archived log data should be “protected against tampering” (e.g., using WORM or immutable storage, object locking, multi-factor authentication (MFA) for deletion approval). If supported, central log servers should also use these storage options.</td></tr><tr><td><code>AL-SS-R5.d</code></td><td>Limit access to log data and servers by “specifying roles and accounts.”</td></tr><tr><td><code>AL-SS-R5.e</code></td><td>“Enable encryption” because access to log data may provide valuable insights to attackers about assets and potential attack vectors.</td></tr></tbody></table></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AL-SS-R6 - SIEM Integration</summary><div class="toggle-content"><ul><li>If supported, “integrate storage infrastructure logs” with Security Information and Event Management (SIEM) for potential threat detection.</li></ul></div></details><h1 id="4-5-IR-Preparation-for-Data-Incident-Response-and-Cyber-Recovery">4.5 (IR) Preparation for Data Incident Response and Cyber Recovery</h1><p>For information on incident response roles and establishment, you can refer to the NIST framework for improving the security of critical infrastructure [40]. Events related to storage should be handled as part of the organization’s incident response process, which includes isolation, root cause analysis, definition and management of response plans, testing, and regular process review and updates. The following recommendations cover specific aspects to consider regarding storage infrastructure and data assets.</p><div class="note info flat"><p>[40] National Institute of Standards and Technology (2018) Framework for Improving Critical Infrastructure Cybersecurity, Version 1.1. (National Institute of Standards and Technology, Gaithersburg, MD). <a href="https://doi.org/10.6028/NIST.CSWP.04162018">https://doi.org/10.6028/NIST.CSWP.04162018</a></p></div><details class="toggle" ><summary class="toggle-button" style="">Requirement: IR-SS-R1 – Develop Response Plans for Intrusions into Storage Components</summary><div class="toggle-content"><p>The following elements should be considered in the organization’s risk analysis, isolation, remediation, recovery, and testing procedures:</p><table><thead><tr><th><div style="width:130px">Requirement</div></th><th>Requirement Content</th></tr></thead><tbody><tr><td><code>IR-SS-R1.a</code></td><td>Intrusion response plans for the entire storage array or entire cloud-based storage assets (e.g., SAN, NAS, object storage, elastic file systems).</td></tr><tr><td><code>IR-SS-R1.b</code></td><td>Intrusion response plans for backup systems.</td></tr><tr><td><code>IR-SS-R1.c</code></td><td>Intrusion response plans for individual storage elements (e.g., shares, block devices).</td></tr><tr><td><code>IR-SS-R1.d</code></td><td>Intrusions into FC SAN networks (including individual switches and SAN services).</td></tr></tbody></table></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: IR-SS-R2 – Ensure the Immutability of Recovered Assets During Incident Management</summary><div class="toggle-content"><ul><li>Combine the recommendations provided in section 4.7 regarding the <em>protection of network recovery copies</em> to ensure they remain isolated during <em>incident management</em>.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: IR-SS-R3 – Verify the Health of Recovered Compute Components During Recovery</summary><div class="toggle-content"><ul><li>Ensure that recovered executable files, applications, containers, and operating system images are <em>free from infection before deploying them into the production environment</em>.</li></ul></div></details><h1 id="4-6-NC-Guidelines-for-Network-Configuration">4.6 (NC) Guidelines for Network Configuration</h1><p>Network topics related to storage involve multiple aspects, some of which overlap with data access control, access management, and encryption, which are covered in other sections. To get a comprehensive understanding of all network configuration aspects, please refer to the content of all sections:</p><ol><li>In section 4.3, there are certain network recommendations closely related to <em>data access control</em>.</li><li>In section 4.9, there are <em>encryption recommendations</em> related to <em>networks and protocols</em>.</li><li>In section 4.10, there are certain network recommendations closely related to <em>access management</em>.</li></ol><div class="note info flat"><p>This section primarily covers <em>network infrastructure (e.g., switch, port, HBA, and NIC configurations, partitioning guidelines, etc.) and protocols</em>.</p></div><h2 id="4-6-1-FC-SAN-and-NVMEoF">4.6.1 FC SAN and NVMEoF</h2><div class="note info flat"><ul><li>FC SAN: FC SAN is a storage area network technology that uses <em>Fibre Channel protocol</em> to connect <em>hosts and storage devices</em>. It is a high-performance, reliable, and scalable solution typically used to connect enterprise-grade storage systems and hosts.</li><li>NVMEoF (NVME over Fabric): NVMEoF aims to use the NVMe protocol to access remote storage devices over a network without the need for a direct local connection.<ul><li>NVMe (Non-Volatile Memory Express) is an efficient storage access protocol designed specifically for <em>non-volatile storage devices such as SSDs</em>.</li><li>NVMeoF extends the NVMe protocol to <em>Fabrics</em> (such as Ethernet or InfiniBand) in existing network architectures.</li><li>This technology allows hosts to <em>access remote storage devices over the network using the NVMe protocol</em> without a direct local connection.</li><li>This approach enables efficient, low-latency storage access in data centers and cloud environments while providing better scalability and flexibility.</li></ul></li></ul></div><details class="toggle" ><summary class="toggle-button" style="">Note: NC-SS-R1 - Host and Switch Authentication</summary><div class="toggle-content"><ul><li>Each <code>host</code> and <code>storage switch</code> should have unique identities and should undergo authentication before joining the network (e.g., FC-SP-2 AUTH-A).</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Note: NC-SS-R2 - Use Approved PKI Mechanisms</summary><div class="toggle-content"><ul><li>Use organization-approved and certified <em>centralized PKI systems to manage switch certificates</em> (e.g., Fibre-Channel Certificate Authentication Protocol or FCAP) instead of using self-signed certificates from devices.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Note: NC-SS-R3 - Use a Hybrid Approach for Zoning</summary><div class="toggle-content"><p>Implement an approach that combines different types of zoning mechanisms rather than using a single type of zoning (i.e., host, switch, and storage device):</p><table><thead><tr><th><div style="width:130px">Requirement</div></th><th>Requirement Content</th></tr></thead><tbody><tr><td><code>NC-SS-R3.a</code></td><td>Zoning based on the <code>host</code>, where applications on the host can access and see which accessible devices or storage resources are available.</td></tr><tr><td><code>NC-SS-R3.b</code></td><td>Zoning based on the <code>switch</code>, which involves using the switch to <em>control communication between devices</em>, allowing only specific devices to interact with other specific devices.</td></tr><tr><td><code>NC-SS-R3.c</code></td><td>Zoning based on the <code>storage device</code>, where in the storage system, the <em>storage array determines which hosts (or more specifically, which host’s HBA ports)</em> can access which block devices, while <em>other hosts not listed are denied access</em>.</td></tr><tr><td><code>NC-SS-R3.d</code></td><td>Zoning based on <code>functionality</code>, where zoning creates several dedicated zones within the storage network, each with a specific purpose, improving the management and control of storage resource access.</td></tr></tbody></table></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R4 - Considerations for Zoning</summary><div class="toggle-content"><ul><li>Zoning refers to making block devices <em>visible or invisible to hosts</em>.</li><li>It is preferred to place the <em>zoning as close to the data as possible</em>, as far away from data users or clients as possible (e.g., prioritize array zoning over switch zoning, core switches over edge switches, and switches over HBAs).</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R5 - Backup Switch Configuration Data</summary><div class="toggle-content"><ul><li>Create a backup of <em>switch configuration data</em>, including zone configuration profiles.</li><li>This backup should be kept outside of SAN switches to enable <em>redeployment in case of errors, malicious damage, or deletion</em>.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R6 - Restrict Switch Management Functions to the Minimum Necessary</summary><div class="toggle-content"><table><thead><tr><th><div style="width:130px">Requirement</div></th><th>Requirement Content</th></tr></thead><tbody><tr><td><code>NC-SS-R6.a</code></td><td>When implementing a Storage Area Network (SAN) structure, <em>establish clear policies</em> specifying and <em>minimizing authorized switches</em> for distributing configuration data (while providing acceptable redundancy).</td></tr><tr><td><code>NC-SS-R6.b</code></td><td><em>Do not enable unnecessary configuration management permissions</em> and services, such as password distribution processes that send passwords to the respective users or devices.</td></tr></tbody></table></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R7 - Considerations for Soft and Hard Zoning</summary><div class="toggle-content"><ul><li>Soft Zoning relies on host identity to restrict access to storage areas, is relatively less secure but may be more suitable for scenarios involving cross-facility and physical security risks.</li><li>Hard Zoning, on the other hand, uses physical port numbers and does not depend on host identity, is more secure, and is especially suitable for situations where physical access is strictly controlled.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R8 - Restrict Specific Fibre Channel Ports for Performing Management Tasks</summary><div class="toggle-content"><ul><li><em>Restrict</em> which Fibre Channel <em>physical and logical ports</em> of Storage Area Networks (SANs) can be used for management.</li><li>Only <em>specific Fibre Channel ports</em> should be able to <em>perform management tasks</em>, such as setting up, configuring, or monitoring SANs. Other Fibre Channel ports should be disabled or have their functions restricted to ensure they cannot be used for management tasks.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R9 - Limit Communication Between Switches</summary><div class="toggle-content"><ul><li>Limit communication between <em>switches</em>.</li><li>Ensure that only <em>necessary switches can communicate with each other</em>, reducing the risk of unauthorized devices entering the Storage Area Network.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R10 - Disable Unused Storage Area Network (SAN) Ports</summary><div class="toggle-content"><ul><li><em>Disable unused Storage Area Network</em> (SAN) ports to prevent accidental or intentional connections by unauthorized devices.</li></ul></div></details><h2 id="4-6-2-IP-Storage-Networking">4.6.2 IP Storage Networking</h2><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R11 – IP Storage Network Segmentation</summary><div class="toggle-content"><p>This section primarily discusses the principles of segmentation in IP storage networks aimed at securing storage-related communication over IP networks. Here’s a summary of the key points in this paragraph:</p><ol><li>In storage-related communication, <em>segmentation of environments and traffic should occur at the Network Layer Layers 2 and 3</em> based on different types of traffic to ensure security.</li><li>For sensitive environments, maximum segmentation should be implemented, and the basis for segmentation includes:<br>| <div style="width:130px">Requirement</div> |  Requirement Content |<br>|---------|----------|<br>| <code>NC-SS-R11.a</code> | Types of traffic: Data access protocols, management, replication, backup, host, and application networks, etc. |<br>| <code>NC-SS-R11.b</code> | Further differentiate management traffic for different solutions, vendors, and technologies. If two or more storage solutions are in use (e.g., different array technologies, server-based SAN products, switch technologies, storage virtualization, etc.), management traffic for each environment should be segmented from others. |<br>| <code>NC-SS-R11.b</code> | Data access protocols (e.g., iSCSI, NFS, proprietary vendor protocols, etc.). |<br>| <code>NC-SS-R11.b</code> | Types of servers or hosts accessing data: Virtualized hosts vs. physical hosts. |</li></ol><p>These segmentation principles aim to ensure the security of IP storage networks, allowing different types of traffic and sensitive information to be appropriately isolated in the network, reducing potential security risks.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R12 - Subnet Segmentation</summary><div class="toggle-content"><ul><li>IP or Ethernet management ports on SAN switches should be placed in separate subnets, including data access subnets between hosts and storage, and separate subnets for inter-host communication.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R13 - Enable Device IP Access Control</summary><div class="toggle-content"><p>Device IP access control should be enabled, and relevant security features, such as built-in firewall rules, IP filtering, and access control lists, should be configured on storage devices to achieve:</p><table><thead><tr><th><div style="width:130px">Requirement</div></th><th>Requirement Content</th></tr></thead><tbody><tr><td><code>NC-SS-R13.a</code></td><td>Control and limit access only to the required hosts or applications for their associated storage objects.</td></tr><tr><td><code>NC-SS-R13.b</code></td><td>Independently control IP traffic between management hosts and management interfaces related to storage.</td></tr></tbody></table></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R14 - Apply IP Access Control at the Network Level</summary><div class="toggle-content"><p>Use routing, firewalls, access control lists, Virtual Private Cloud (VPC) security groups, and similar mechanisms to restrict all traffic types (data access and management traffic) between servers or applications and their associated storage objects to allowed IP addresses and TCP/UDP ports and protocols:</p><table><thead><tr><th><div style="width:130px">Requirement</div></th><th>Requirement Content</th></tr></thead><tbody><tr><td><code>NC-SS-R14.a</code></td><td>Between hosts or applications and their used storage objects.</td></tr><tr><td><code>NC-SS-R14.b</code></td><td>Between management hosts and applications and the storage management interfaces associated with them.</td></tr></tbody></table></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R15 - Block Internet or Public Network Access</summary><div class="toggle-content"><p>Access to non-public storage objects from the internet or other public networks should be blocked.</p></div></details><details class="toggle" style="border: 1px solid  Implement Adequate Controls"><summary class="toggle-button" style="background-color:  Implement Adequate Controls;">Requirement: NC-SS-R16 - For Storage Objects Requiring Public Access</summary><div class="toggle-content"><p>(a) Minimize access.<br>(b) Use physically and logically separated storage subnets, preferably with different storage devices and pools for non-public storage objects.<br>© Consider protection against denial of service attacks.<br>(d) Cache copies (e.g., using Content Delivery Networks (CDNs), copies, and proxies) while maintaining at least the same security characteristics as the source data.<br>(e) Consider regulatory requirements (e.g., confidentiality, storage location restrictions).<br>(f) Any other applicable security controls (e.g., encryption, authentication).</p></div></details><details class="toggle" style="border: 1px solid  Direct All Traffic to Valid Internal Organization IP Addresses as Destinations"><summary class="toggle-button" style="background-color:  Direct All Traffic to Valid Internal Organization IP Addresses as Destinations;">Requirement: NC-SS-R17 - When Configuring SNMP</summary><div class="toggle-content"><p>When configuring SNMP, all traffic should be directed to valid internal organization IP addresses as destinations, and the effectiveness of the configured settings should be periodically reviewed.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R17 - Consider Using Isolated Non-Routable VLANs</summary><div class="toggle-content"><p>For server-based SAN deployments, consider using isolated non-routable VLANs to protect data storage environments and mitigate security concerns.</p></div></details><h2 id="4-6-3-Protocols">4.6.3 Protocols</h2><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R19 - Disable Insecure File Access Protocol Versions</summary><div class="toggle-content"><ul><li>Deprecated, unsupported, or insecure protocol versions such as SMB v1, NFS 1 and 2 should be blocked.</li><li>It is recommended to disable these protocols on both clients and servers for increased security.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R20 - SNMP Security Configuration</summary><div class="toggle-content"><p>(a) If SNMP is not in use, it should be disabled.<br>(b) Modify the default known community strings, even if SNMP is not enabled. The configured strings should comply with the organization’s password policy.<br>© Use different community strings for devices with different sensitivities.<br>(d) Use at least SNMP version 3.<br>(e) Enforce SNMP authentication and encryption features.<br>(f) If not absolutely necessary, do not configure SNMP with read-write access. If required, limit and control the use of read-write SNMP.<br>(g) Use access control lists to control access to devices via SNMP.<br>(h) Regularly verify that SNMP traps are sent to authorized managers.<br>(i) Refer to the U.S. Department of Homeland Security (CISA) TA17-156A guidelines for additional guidance.</p></div></details><details class="toggle" style="border: 1px solid  Domains"><summary class="toggle-button" style="background-color:  Domains;color:  and Similar Services">Requirement: NC-SS-R21 - Integrity of Directories</summary><div class="toggle-content"><p>Regularly review the configurations of all storage elements (such as devices, switches, management workstations, management software) that provide services to ensure only approved configurations are in use and remediate any inconsistencies.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R22 - Consider the Use of Standard and Non-Standard TCP/IP or UDP Ports</summary><div class="toggle-content"><p>Consider using non-standard ports to obscure applications or services, making it harder for hackers to identify the correct port number.<br>The disadvantage of using non-standard ports is that security scanning tools may not recognize suspicious activity on non-standard ports, as these tools expect specific behavior on standard ports.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R23 - Enable FCoE Initialization Protocol (FIP) Listening Filters</summary><div class="toggle-content"><p>FIP listening is a security mechanism to prevent unauthorized access and data transmission to the FC network.<br>FCoE adapters connect FC initiators (servers) to FCoE forwarders (FCFs) to enable FIP snooping on the relevant VLANs.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R24 - Restrict iSCSI Ports</summary><div class="toggle-content"><p>Prevent hosts on the iSCSI network from accessing any TCP ports other than those specified for iSCSI on that network.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R25 - Use iSCSI Authentication</summary><div class="toggle-content"><p>Authenticate iSCSI initiators (e.g., CHAP, SRP, Kerberos, SPKM1/2) when establishing sessions. Use bidirectional authentication instead of unidirectional CHAP. Note that authentication does not provide channel encryption or integrity protection.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R26 - Use NDMP Security Features</summary><div class="toggle-content"><p>When using NDMP, the following security features should be configured:<br>(a) Control which hosts can initiate NDMP sessions.<br>(b) Use challenge-response authentication (do not use plaintext authentication options).<br>© Log NDMP connection attempts.<br>(d) NDMP passwords should adhere to the organization’s password policy (e.g., length, complexity).<br>(e) Assign only the necessary NDMP-related permissions to users.<br>(f) Encrypt NDMP control connections.<br>(g) Rate-limit NDMP sessions or server.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R27 - Use TLS in LDAP</summary><div class="toggle-content"><p>When configuring Active Directory options for storage systems, use TLS to secure LDAP connections.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: NC-SS-R28 - Considerations for Other Protocols</summary><div class="toggle-content"><p>When using other protocols (such as SymAPI, SMI-S, GNS, etc.), consider adopting the recommendations in sections 4.6.2 and 4.6.3.<br>Specifically:<br>(a) Segment traffic for data access and management from other environments.<br>(b) Limit TCP and UDP ports.<br>© Enable encryption as appropriate.</p></div></details><h1 id="4-7-IS-Isolation">4.7 (IS) Isolation</h1><p>When production data is damaged or lost, organizations should be able to recover the data through copies or backup data copies. If the damage results from malicious attacks, and the attacker can also destroy backup data copies, an attack on the production environment will have catastrophic consequences because the organization won’t be able to recover. To enhance the resilience of backup copies, <em>it should ensure sufficient isolation between data assets and their recovery copies</em>. In this context, organizations should differentiate at least two data protection scenarios:</p><ol><li><em>Non-malicious Recovery</em> - Requires data copies to address scenarios like <code>natural disasters, hardware failures, human errors</code>, etc. These may include local copies (e.g., snapshots taken before maintenance), disaster recovery copies (DR copies), backups, and long-term archives. The closer these copies are to the production environment, the more likely they are mapped to compute systems for testing and disaster recovery.</li><li><em>Recovery from Network Attacks</em> - Requires <code>hardened, locked down, and isolated data copies</code>. Design should strive to achieve a state where these copies remain unaffected, even if associated production data volumes or other types of copies have been compromised.</li></ol><details class="toggle" ><summary class="toggle-button" style="">Requirement: IS-SS-R1 – Separation of Storage Systems</summary><div class="toggle-content"><p>(a) In <em>private clouds</em>, backup copies designed to guard against network attacks should be established within specified <em>dedicated storage environments</em>. In <em>public clouds</em>, these backup copies should be created using <em>separate accounts (or equivalent accounts)</em>.<br>(b) Long-term backups and storage systems should be physically separated from the production data storage systems.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: IS-SS-R2 – Separation of Management Systems</summary><div class="toggle-content"><ul><li>The management of storage systems storing network attack recovery copies should come from a <em>designated management system</em> that is <em>separated</em> from the production environment and other systems connected to production (including data protection mechanisms).</li><li>Production and regular backup systems should not have access to these management systems. The system should be hosted in a dedicated environment only connected to the isolated network.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: IS-SS-R3 – Access Restriction to Network Attack Recovery Systems and Long-term Backups</summary><div class="toggle-content"><p>(a) For sensitive information, network attack <em>recovery copies</em> and their systems should not be visible to regular IT personnel. They should only be accessible by a single individual (e.g., CISO) or a very limited group of senior executives or security managers using special credentials. This ensures that if IT administrator credentials are compromised, attackers cannot use them to access network attack recovery copies. This restricted team can access network attack recovery copies, but administrative privileges will be granted to a smaller subset for granting permissions to other users.<br>(b) Permissions to access long-term backups should be separate from permissions used for other storage management tasks (e.g., SAN management, storage allocation) and should involve different user IDs, accounts, and credentials.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: IS-SS-R4 – Offline Storage</summary><div class="toggle-content"><ul><li>Network attack recovery backups should be <em>stored offline</em>, not in the same location as production data. This ensures that even if attackers physically enter the production site or successfully infiltrate the physical location, they cannot access or compromise network attack recovery backups.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: IS-SS-R5 – Independent Full Backups</summary><div class="toggle-content"><ul><li>Backup systems typically use incremental backups, capturing changes to data relative to a baseline backup. These incremental backups must be used together with the baseline backup for recovery. For some backup schemes (e.g., snapshots), only incremental backups are used (i.e., the baseline backup is the production data itself).</li><li>To handle recovery scenarios correctly, <em>dependencies between backups should be considered and sufficient isolation between different types of backups should be maintained</em>. Specifically:<ul><li>(a) Replicated disaster recovery backups should not depend on production baseline data.</li><li>(b) Network attack recovery backups should not depend on production baseline data. Dependency on disaster recovery baseline data is only allowed if these backups are sufficiently isolated from production baseline data and comply with IS-SS-R1, IS-SS-R2, and IS-SS-R3 recommendations.</li><li>© <em>Archived data for long-term storage should not depend on production and disaster recovery baseline data</em>.</li></ul></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: IS-SS-R6 – Disable All Unnecessary Services and Protocols</summary><div class="toggle-content"><p>All unnecessary services and protocols should be disabled on the network attack recovery storage system. In environments where management is done solely through application programming interfaces (APIs) or command-line interfaces (CLIs), it’s also recommended to disable any interactive web interfaces.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: IS-SS-R7 - Isolate Data from Applications During Restoration</summary><div class="toggle-content"><p>(a) During data restoration, data copies should not be mounted, exported, or mapped to hosts or applications. Instead, they should be restored to an isolated temporary environment (e.g., offline environment) rather than directly restoring to the target host or application. Alternatively, a less secure approach may allow the target host or application limited read-only access during the restoration process (e.g., mapping or mounting), but such access should be removed immediately after restoration.<br>(b) Data copies for long-term backups should not be directly mounted, exported, or mapped to hosts or applications.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: IS-SS-R8 - Consider Implementing an Air Gap</summary><div class="toggle-content"><ul><li>Organizations should consider establishing an <em>air gap around sensitive data</em> for data recovery copies.</li><li>Strict air gaps should provide complete <em>physical and network-level separation</em>.</li><li>Some storage technologies introduce less strict isolation techniques also referred to as “air gaps” that can be turned off for limited periods when synchronizing with production systems. The effectiveness of each technology should be evaluated based on data value and adversary capabilities. When choosing to implement strict air gaps, precautions should be taken to bypass known air gap system vulnerabilities, including:<ul><li>(a) Preventing visual, auditory, and thermal signal transmission between air gap systems and other devices (e.g., maintaining sufficient distance or using vibration damping and/or adequate physical separation).</li><li>(b) Preventing any potential wireless transmission functions in air gap devices.</li><li>© Disabling exposed data ports (e.g., USB, network).</li><li>(d) Using power regulation or isolated circuits.</li></ul></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: IS-SS-R9 - Perform Regular Isolation Audits</summary><div class="toggle-content"><p><em>Regularly review the isolation recommendations mentioned above at least once a year</em> as part of routine audits to ensure that there are no configuration gaps or deviations that could compromise the isolation of recovery copies. For sensitive and high-value storage systems, audits may need to be conducted at least quarterly and after major changes, depending on which occurs first. Audit results should be documented.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: IS-SS-R10 - Consider the Use of Immutable Storage Technologies</summary><div class="toggle-content"><p>Consider the use of immutable storage technologies, which can further isolate and protect recovery data (e.g., retention locks, vault locks, immutability policies).</p></div></details><h1 id="4-8-RA-Restoration-Assurance">4.8 (RA) Restoration Assurance</h1><ul><li>This section focuses on “restoration assurance,” ensuring successful recovery in the event of business disruptions, disaster recovery incidents, or cyberattacks.</li><li>Having restoration processes alone is insufficient; organizations also need to ensure that these processes are effective. The effectiveness of restoration can be challenged due to various reasons, including but not limited to system complexity, missing documentation, outdated procedures, human error, inadequate testing, or incorrect configurations.</li></ul><details class="toggle" ><summary class="toggle-button" style="">Requirement: RA-PR-R1 - Verify Restoration Procedures</summary><div class="toggle-content"><p>(a) <em>Restoration procedures should be documented, maintained, and periodically reviewed</em>. They should clearly describe how to restore data from different types of recovery copies.<br>(b) Organizations should <em>periodically test restoration procedures</em>, with a focus on validating that data can be successfully restored and that the restored data is usable and accurate.<br>© For recovery from network attacks, organizations should validate that the <em>network attack recovery copies can be restored successfully in an isolated environment</em>, and the restoration process itself should not introduce vulnerabilities.<br>(d) Restoration procedures should specify how to validate the integrity and authenticity of restored data.<br>(e) Organizations should maintain a record of restoration tests and outcomes, addressing any issues discovered during testing.<br>(f) In situations where immutable storage technologies are employed (as mentioned in IS-SS-R10), ensure that restoration procedures include how to verify the immutability of the data and its suitability for restoration.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: RA-PR-R2 - Assess Restoration Timeframes</summary><div class="toggle-content"><p>(a) Organizations should <em>assess the timeframes required for restoration</em> based on different scenarios, including recovery from network attacks. These assessments should consider the volume of data, complexity of the restoration process, and the specific characteristics of the organization’s environment.<br>(b) Based on the assessments, organizations should set <em>restoration time objectives (RTOs)</em> for different data types and scenarios. RTOs should be realistic and achievable.<br>© Periodically review and update RTOs as the organization’s data environment evolves.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: RA-SS-R3 - Availability of All Relevant Software and Hardware Components</summary><div class="toggle-content"><p>All relevant software and hardware components used to operate the system (e.g., drivers, firmware) should be backed up, protected, and available for recovery operations.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: RA-SS-R4 - Selection of Backup and Data Replication Technologies Should Align with Organizational RTO Requirements</summary><div class="toggle-content"><ul><li>RTO stands for “Recovery Time Objective” and is used to measure the desired recovery speed.</li><li>The ability to meet the RTO comprehensively should consider all relevant components (such as data recovery, configuration files, encryption keys).</li><li>Balancing the actual speed required for recovery and adjusting all relevant components to achieve the desired recovery speed should also consider the associated costs.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: RA-SS-R5 - Conduct Regular Recovery Testing to Ensure Meeting RTOs</summary><div class="toggle-content"><p>Regularly perform recovery testing operations to ensure successful completion and compliance with the required timeframes.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: RA-SS-R6 - Set Recovery Point Objectives (RPOs)</summary><div class="toggle-content"><ul><li>Set a “Recovery Point Objective” for each data asset, which measures the amount of data loss that can be tolerated in terms of time after a failure occurs.</li><li>The design and implementation of backup and data replication technologies should support data recovery under this objective.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: RA-SS-R7 - Meet Data Retention and Replication Frequency Requirements for Organizational Data Assets</summary><div class="toggle-content"><p>Determine the “data retention and replication frequency requirements for each data asset” (see DP-SS-R1 for more details). The design and implementation of backup and data replication technologies should support these requirements.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: RA-SS-R8 - Ensure the Health of Remote Copy Backups and Data Replication</summary><div class="toggle-content"><ul><li>“Periodically verify the status of backup copies.”</li><li>This includes checking for relevant error logs and ensuring that backup and data replication media are in good condition.</li><li>The verification frequency should align with the sensitivity and value of the protected data but should not be less than once a year.</li><li>Maintaining a sample rate within one to one and a half orders of magnitude lower than the backup frequency, such as verifying daily backups weekly or monthly, can serve as a reliable benchmark.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: RA-SS-R9 - Separate Data from Applications during Restoration</summary><div class="toggle-content"><p>To avoid restoring infected code or software when restoring data, “data should be separated from applications” during restoration.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: RA-SS-R10 - Document Disaster Recovery Plan</summary><div class="toggle-content"><p>A “disaster recovery plan for storage infrastructure” must be written, including all resources, mappings to the formal production environment, processes, and testing procedures. Backup of these documents should also be maintained.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: RA-SS-R11 - Network Security Measures for Data Copies</summary><div class="toggle-content"><ul><li>For mission-critical information, disaster recovery copies should be “scanned using various anti-malware scanning tools” to detect known vulnerabilities and anomalies.</li><li>Ideally, “all copies should be scanned.” If not possible, “at least a subset of copies should be scanned,” and these scanned and secure copies should be documented. Network security tools include antivirus software, anti-malware, vulnerability scanning, and security analysis tools.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: RA-SS-R12 - Conduct Periodic Audits</summary><div class="toggle-content"><ul><li>“The recommendations should be reviewed as part of periodic audits” to check the integrity of copies, reassess dependencies, software and hardware requirements, the technical suitability to support recovery speed, Recovery Point Objectives (RPOs), retention periods, health checks, disaster recovery plans, and network security measures.</li><li>Identify and track issues and perform remediation.</li><li>Audit frequency should align with the sensitivity and value of the protected data but should not be less than once a year.</li><li>For sensitive and high-value storage systems, audits may need to be conducted quarterly and after major changes, depending on which occurs first.</li><li>Audit results should be documented.</li></ul></div></details><h1 id="4-9-Encryption-EN">4.9 Encryption (EN)</h1><div class="note info flat"><p>Encryption is the process of transforming data from a readable form (plaintext) into an unreadable form that is not easily understood by unauthorized individuals (ciphertext). This ensures that sensitive information remains inaccessible or comprehensible to unauthorized parties.</p></div><p>In storage systems, encryption should be implemented “end-to-end,” including:</p><ol><li>Data at Rest: Data stored in relevant facilities, whether physical or logical (e.g., tapes, disks, optical media), should be encrypted. This includes not only the data itself but also metadata, such as access permissions, labels, paths, and log information.</li><li>Data in Transit: Data transferred between storage elements, whether it’s data read/written by clients, replication between storage devices or pools, or data transmitted over a network, should be encrypted unless the entire communication medium is within a protected environment (e.g., a data center).</li><li>Administrative Access: Connections that allow “configuration or control” of storage elements, storage networks, and data through standard and proprietary protocols and APIs.</li></ol><details class="toggle" style="border: 1px solid  Hashing"><summary class="toggle-button" style="background-color:  Hashing;color:  and Encryption">Requirement: EN-SS-R1 - TLS</summary><div class="toggle-content"><ul><li>To support encrypted communication between storage clients and servers, the “Transport Layer Security (TLS) protocol” should be used.</li><li>The selection and configuration of the TLS protocol implementation should follow relevant guidelines, including the choice of TLS versions and cryptographic algorithms.<ul><li>Guidelines sources include “NIST SP800-52 Rev2” and “SNIA TLS Specification for Storage Systems Version 1.1.”</li></ul></li></ul></div></details><details class="toggle" style="border: 1px solid  Telnet"><summary class="toggle-button" style="background-color:  Telnet;color:  FTP">Requirement: EN-SS-R2 - Avoid Plain Text Protocols such as HTTP</summary><div class="toggle-content"><ul><li>Plain text protocols are susceptible to eavesdropping, interception, and other attacks because they do not encrypt traffic or login details.</li><li>In sensitive storage environments, “using HTTP for redirection to HTTPS should not be allowed” unless it’s only used for handling URLs related to error inputs.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: EN-SS-R3 - Encryption of Storage Management API Sessions</summary><div class="toggle-content"><ul><li>Encryption should be applied to all API and CLI client sessions and can be achieved using specific configuration options within “management software” or “API/CLI software components.”</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: EN-SS-R4 - Encryption of Administrative Access Sessions</summary><div class="toggle-content"><ul><li>Administrative sessions using HTTP should be encrypted using “TLS (HTTPS).”</li><li>Command Line Interface (CLI) access should use “SSH for encryption” instead of Telnet.</li><li>Authentication during API access should not use plaintext, and the session itself should be encrypted.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: EN-SS-R5 - Enable FIPS Mode in FIPS Environments</summary><div class="toggle-content"><ul><li>FIPS 140-3 requires that cryptographic modules should be a combination of hardware, software, firmware, or any combination thereof, used to implement cryptographic functions or processes, including cryptographic algorithms, and optionally key generation, within a defined cryptographic boundary.</li><li>FIPS specifies certain cryptographic algorithms as secure and dictates which algorithms should be used when a cryptographic module is called FIPS-compliant.</li><li>Organizations that comply with FIPS standards should ensure that FIPS mode is enabled in their FIPS-compliant storage infrastructure components.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: EN-SS-R6 - Static Encryption of Sensitive Data</summary><div class="toggle-content"><p>Static encryption protects data from various data-related risks, including unauthorized access, media loss, or theft. Static encryption should be enabled for sensitive data, considering the following:</p><ol><li>Use Infrastructure Encryption: Utilize built-in encryption features provided by disks, storage arrays, or cloud storage, whether using keys provided by vendors or keys provided by the organization, to protect against threats like device loss, misplacement, or theft. However, this may not protect against:<ol><li>Insider Attacks - When an attacker infiltrates a host already associated with storage (or when storage can be mapped to an unauthorized host through legitimate means).</li><li>Privilege Escalation Attacks - Where administrators or attackers with high privileges may turn off encryption or decrypt data.</li></ol></li><li>Use End-to-End Encryption: Data is encrypted at its source (e.g., applications, databases, volumes), and only ciphertext is presented to storage infrastructure and administrators. This significantly enhances security but may come with considerable costs:<ol><li>Data Reduction Mechanisms Are Affected - For instance, compression and deduplication may become inefficient.</li><li>Management Becomes More Complex.</li></ol></li><li>Use Dual Independent-Layer Encryption Where Possible: Consider using dual independent-layer encryption for stored sensitive data. This configuration enhances resilience if keys are compromised, especially when different encryption services are used.</li><li>Consider Data Retention Requirements: If “encrypted data is backed up or archived,” related keys should be protected, and the protection duration should match that of the data. Alternatively, backup data should regenerate new keys. In either case, “data and encryption keys should not be kept together.”</li></ol></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: EN-SS-R7 - Data Encryption in Transit</summary><div class="toggle-content"><ul><li>(a) Block Transfers on Fibre-Channel: While Fibre-Channel link encryption is defined in ANSI/INCITS 545-2019 standards, most Host Bus Adapters (HBAs) and storage vendors do not currently support it. For sensitive information, “end-to-end encryption (host to storage)” should be used.</li><li>(b) Block Transfers on IP: IP storage traffic faces the same security risks as regular IP networks. By default, IP block transfer protocols do not provide data confidentiality, integrity, or authentication for each data packet. Similar to link encryption, although there are technical specifications for encrypting IP storage traffic, current technologies do not natively support it. When using IP block transfer protocols (e.g., iSCSI, FCIP, proprietary protocols), consider using “IPsec tunnels to protect segments exposed on the network.” Additionally, for sensitive information, “end-to-end encryption (host to storage)” should be used.</li><li>© File and Object Storage Access: Data encryption should be enabled for data transfer during backups and remote replication, where supported. For file access, mechanisms like SMB encryption should be used to encrypt sensitive data, or options for NFS encryption provided by cloud service providers, or NFS over TLS using channel encryption (e.g., ‘stunnel’). Ensure that object access is done via HTTPS with TLS.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: EN-SS-R8 - Communication Between Storage System Components Should Be Encrypted</summary><div class="toggle-content"><ul><li>“Interactions between storage system components” should be reviewed, and available encryption options should be used.</li><li>Encryption should be used to protect communication between “storage nodes and managers,” active storage nodes and witness devices, and with policy servers and antivirus servers.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: EN-SS-R9 - Encryption Key Management Requirements</summary><div class="toggle-content"><ul><li>Follow general recommendations for key management outlined in “NIST SP 800-57” parts 1-3, especially focusing on:<ul><li>Key Lifetimes.</li><li>Maximum Data That Keys Can Protect.</li><li>Key Management Infrastructure.</li><li>Key Regeneration.</li><li>Auditing.</li><li>Key Backup and Recovery.</li></ul></li></ul></div></details><h1 id="4-10-AA-Administrative-Access">4.10 (AA) Administrative Access</h1><ul><li>This section focuses on <code>administrative access</code> to storage elements, including <em>arrays, networks and architectures, management tools, backups, replication, and cloud storage</em>, among others.</li><li>Administrative access can be achieved either by <code>directly connecting to storage components</code> or through <code>management software</code>. Both of these connection methods can use different interfaces, including graphical user interfaces (UIs), command-line interfaces (CLIs), and application programming interfaces (APIs).</li></ul><p>Some of the recommendations in this chapter overlap with aspects related to administrative access. To avoid duplication, additional relevant recommendations can be found in the following two sections:</p><ul><li>In the previous section 4.9 Encryption, there are recommendations related to encryption.</li><li>In the previous section 4.3 Authentication and Data Access Control, there are recommendations related to data access control, some of which may also apply to administrative access.</li></ul><p>This section provides security guidelines for configuring administrative access, and the key points are summarized below:</p><details class="toggle" ><summary class="toggle-button" style="">Requirement: AA-SS-R1 - Limit Network Access to SAN Switch Management Ports</summary><div class="toggle-content"><ul><li>Limit <em>network access</em> to <code>SAN switch management ports</code> to <em>specifically assigned devices and administrators</em> using mechanisms like access control lists (ACLs).</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AA-SS-R2 - Control and Minimize Components with Administrative Privileges</summary><div class="toggle-content"><p>This includes CLI servers, management consoles, API gateways, witness hosts, and storage devices with control privileges. Specifically:<br>(a) Actively identify components with storage management privileges and ensure that only authorized components have these privileges. If unnecessary components are identified, they should be immediately removed and reported.<br>(b) Remove unnecessary permissions and capabilities from authorized devices.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AA-SS-R3 - Implement the Principle of Least Privilege</summary><div class="toggle-content"><ul><li>Restrict the <em>privileges of users with administrative access</em> to the <em>minimum necessary</em>.</li><li>This includes limiting the minimum actions users can perform and restricting the scope of these privileges to cover only relevant systems or areas.</li><li>Full administrative privileges should only be granted to users who require them.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AA-SS-R4 - Restrict Access for Service Accounts</summary><div class="toggle-content"><ul><li>Service accounts (e.g., accounts used by monitoring tools) should be restricted to <em>read-only</em> and <em>metadata-only access</em>.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AA-SS-R5 - Authenticate and Authorize All CLI/API Access</summary><div class="toggle-content"><ul><li>Authentication and authorization should be applied to <em>CLI/API</em> usage.</li><li>If authentication and authorization are not possible, additional security measures should be in place to protect unauthorized access, such as using privilege management tools to limit control to the minimum necessary commands and objects.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AA-SS-R6 – Prefer API Access Control Over CLI/Shell Access</summary><div class="toggle-content"><ul><li><em>API access control should be prioritized</em>, as CLI/shell access has the capability to access the operating system and file system, including configuration files.</li><li>If CLI/shell access is the only option, it should be used over secure protocols like SSH.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AA-SS-R7 – Restrict Operating System Privileges for Management Consoles</summary><div class="toggle-content"><ul><li>Access to management consoles should only be provided through specified storage accounts and <em>not use operating system management accounts</em> (see also AC-SS-R20).</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AA-SS-R8 – Secure Web-Based User Interfaces for Management Console Access</summary><div class="toggle-content"><ul><li>Web services providing access to the management console should be hardened to meet or exceed the minimum standards of other web application servers within the organization.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AA-SS-R9 – Limit Host Storage Control Privileges</summary><div class="toggle-content"><ul><li>In certain shared data compute cluster configurations (e.g., clusters, geoclusters, scale sets, or storage virtualization infrastructure), hosts are granted management privileges over storage to control the allocation and behavior of shared cluster data resources.</li><li>When this management access is required, the scope and privileges granted to hosts should be limited to specific elements (e.g., LUNs, shares, files, objects) that the hosts need to control and specific operations they need to perform.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AA-SS-R10 – Command Device or Gateway Configuration</summary><div class="toggle-content"><p>Some storage arrays allow hosts to have control over special block devices (referred to as “command devices” and “gateways”) that provide access to specific block devices. When used, the following security guidelines are recommended:<br>(a) <em>Limit the use of control devices</em>: If feasible, eliminate the use of these devices entirely (e.g., switch to API access). If elimination is not possible, ensure that they are mapped only to necessary hosts (e.g., management hosts).<br>(b) <em>Scan control devices</em>: Conduct network scans to discover control devices and ensure they are only mapped to necessary and authorized hosts.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AA-SS-R11 – Disable or Restrict Call Home or Remote Access</summary><div class="toggle-content"><p>Call home or remote access is typically used for collecting telemetry and diagnostic data for manufacturer analysis and resolution of technical issues, as well as for automatic software updates. However, these features can also become targets for hacking, so they should be <code>disabled if not needed</code> and <code>restricted and controlled if required</code>.<br>(a) <em>Modify default credentials</em>: Change the default credentials for remote connections.<br>(b) <em>Limit privileges</em>: Grant only the minimum necessary privileges.<br>© <em>Enforce encryption</em>: Use secure protocols like TLS/SSH/IPsec and FIPS-approved encryption algorithms.<br>(d) <em>Use an allow list to restrict access</em>: Use an allow list to restrict access to specific IPs and users.<br>(e) <em>Maintain complete logs of remote access</em>: For audit purposes, all remote access should be fully logged.<br>(f) <em>Enable built-in data obfuscation features</em>: For storage devices that allow obfuscation of sensitive data (such as IP addresses, WWNs, device names, and usernames), this feature should be enabled.<br>(g) <em>Limit the scope of data sent</em>: Limit the scope of data sent to the minimum required.<br>(h) <em>Regularly review and approve</em>: Regularly review data sent to vendors either periodically or automatically, ensuring that it does not contain sensitive information like IP addresses, usernames, or actual storage device content. Also, review to ensure that connections go to valid vendor IP addresses.<br>(i) <em>Authorize each connection</em>: If possible, implement a mechanism that requests permission before allowing each connection.<br>(j) <em>Limit access to gateway systems</em>: Special attention should be paid to protecting and restricting access to gateway systems when vendors access them remotely through devices, servers, or appliances.<br>(k) <em>Disable software updates over vendor remote access links</em>: In sensitive environments, software components and updates should not be allowed to be downloaded and deployed over vendor remote access links (either manually or automatically).</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AA-SS-R12 - Limit Network Access for Management</summary><div class="toggle-content"><ol><li>It is recommended to <em>separate management networks from other traffic</em> (see sections 4.6 and 4.7).</li><li>Further <em>enhance access control for management networks</em>, which can be achieved through the following mechanisms:<br>(a) Virtual Private Networks (VPNs), IPsec, or one or more “jump servers”: Use VPNs, IPsec, or one or more “jump servers” or “login proxy servers,” which are dedicated servers located in the management network and can only be accessed from outside the network. These servers can be used for connecting to other servers only after proper authentication and authorization.<br>(b) Enhance logging and tracking capabilities, such as session logging.</li></ol></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AA-SS-R13 - Securely Protect Core Storage Management Files and Executables</summary><div class="toggle-content"><ol><li>Storage management software typically includes <code>configuration files</code> used to control the operation of storage systems, including undocumented options.</li><li>These sensitive directories and files should have appropriate <code>access restrictions</code> and <code>correct owners and group memberships</code>.</li><li>This includes the following:<ul><li><code>Configuration files</code>: Record users and roles, network settings, consistency groups, device groups, and other storage options. Configuration files defining consistency and device groups are typically automatically propagated from central management hosts to other hosts connected to managed storage systems. Therefore, if compromised, it could affect multiple systems.</li><li><code>Scripts</code>: Used to control the startup, monitoring, and stopping of storage management services and daemons, as well as their own executables. These scripts and other critical management-related files should be securely protected.</li></ul></li><li>Controls for configuration files, scripts, and other critical management-related files should include:<br>(a) <code>Restrictions on access and permissions</code>, and control of ownership of key directories and files.<br>(b) For sensitive environments, consider <code>monitoring changes to the contents of these files</code> to prevent unauthorized alterations.</li></ol></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: AA-SS-R14 - Use Approved PKI Mechanisms for Administrative Access</summary><div class="toggle-content"><ul><li>For storage device management and storage management consoles, it is recommended to use <code>organization-approved and certified centralized PKI systems</code> rather than self-signed certificates from devices or software.</li></ul></div></details><h1 id="4-11-CM-Configuration-Management">4.11 (CM) Configuration Management</h1><p>The purpose of configuration management is to provide visibility and control over the configuration, behavior, and physical and logical attributes of the entire storage device throughout its <em>lifecycle</em>. In the context of storage security, this includes the following:</p><ul><li>Maintaining a comprehensive and real-time <em>inventory</em>, managing changes, and ensuring that configurations <em>continuously adhere to the organization’s security baseline and current industry best practices</em>, while also ensuring they are not vulnerable to known risks.</li></ul><p>To achieve this goal, appropriate controls, policies, processes, and tools are required. A comprehensive guide to IT configuration management can be referenced in <code>NIST Special Publication (SP) 800-53</code> [28]. The following paragraphs contain recommendations applicable to storage infrastructure.</p><details class="toggle" style="border: 1px solid  Including Identifying the Names"><summary class="toggle-button" style="background-color:  Including Identifying the Names;color:  Addresses">Requirement: CM-SS-R1 - Establish a Comprehensive Inventory of Storage Devices</summary><div class="toggle-content"><ol><li>Arrays</li><li>Storage virtualization systems</li><li>Management consoles</li><li>Hosts monitoring storage remote network connectivity status (e.g., Witness hosts)</li><li>Hosts with storage management software or plugins installed</li><li>Data protection appliances</li><li>Backup clients and servers</li><li>Storage network switches</li><li>Storage adapters or Host Bus Adapters (HBAs)</li><li>I/O multipathing software</li><li>Pairing of primary storage systems and (replica) target storage systems</li><li>Designated host backup servers or off-site backup situations</li><li>Tape libraries and tape drives</li><li>Disk drives and removable media</li></ol></div></details><details class="toggle" style="border: 1px solid  Including Data Components and Data Access Configurations Identified Through Logical Data Asset Identifications"><summary class="toggle-button" style="background-color:  Including Data Components and Data Access Configurations Identified Through Logical Data Asset Identifications;">Requirement: CM-SS-R2 - Establish a Comprehensive Inventory of Data and Configuration Assets</summary><div class="toggle-content"><ol><li>Storage pools, LUNs, masking, and partitions</li><li>Initiators and initiator groups</li><li>File shares and Access Control Lists (ACLs)</li><li>Object storage pools, buckets, etc.</li><li>Backup replicas and snapshots</li><li>Backup catalogs and access permissions</li><li>Backup sets (local, archive, cloud virtualization, tape, archival devices, etc.)</li><li>Users, groups, roles, and permissions</li><li>Host access configurations to storage assets (e.g., LUNs, file shares, global file systems, object storage)</li><li>Images of storage software, virtual devices, etc.</li></ol></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: CM-SS-R3 - Create a Comprehensive Storage Security Policy</summary><div class="toggle-content"><ul><li>A storage security policy can be a standalone policy or part of the organization’s security policy.</li><li>The policy should be based on the following sources:<ul><li>Recommendations from this publication and cited sources.</li><li>Internal organization-specific storage-related security standards.</li><li>Best security practices from relevant vendors.</li></ul></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: CM-SS-R4 - Maintain Updates to the Storage Security Policy</summary><div class="toggle-content"><ul><li>The storage security policy should be <em>reviewed and updated regularly</em> (at least annually).</li><li>Security baselines should be <em>updated based on the latest vendor and industry recommendations for available storage systems and/or specific storage devices</em> (preferably quarterly and at least annually).</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: CM-SS-R5 - Regularly Assess the Configuration Compliance of the Storage Security Policy</summary><div class="toggle-content"><ul><li>(a) Ensure that the actual configuration <em>complies with the storage security baseline</em> and identify gaps.</li><li>(b) Timely address and remediate identified gaps.</li><li>© Consider defining key performance indicators (KPIs) for storage security baseline compliance based on data types, organizational functions, and sensitivity.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: CM-SS-R6 - Create a Storage Change Management Process</summary><div class="toggle-content"><ul><li>This can be a dedicated process or part of the organization’s general change management process.</li><li>Covers:<ul><li>(a) Planning, reviewing, and approving storage configuration changes.</li><li>(b) Updating environmental documentation and inventory (e.g., infrastructure, data, configurations).</li><li>© Evaluating compliance after any changes to sensitive storage environments.</li></ul></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: CM-SS-R7 - Detect Unauthorized Storage Security Changes</summary><div class="toggle-content"><ul><li>Establish a process to <em>detect unauthorized changes to storage configurations</em>, which can be done using log records, comparing configuration storage assets with past states, or comparing with organization-approved baselines.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: CM-SS-R8 - Software Updates and Patches</summary><div class="toggle-content"><p>(a) <em>Ensure updates to storage software versions</em>: Establish a process for regularly updating storage software to the latest stable and secure versions. This includes managing software, API and CLI suites, array and HBA firmware versions, and operating system driver software.<br>(b) <em>Install critical security updates and patches</em>: Establish a proactive and frequent process for installing important and emergency storage security patches.<br>© <em>Mitigation plans for unobtainable patches</em> - If certain storage components have critical vulnerabilities, and updates or patches are not provided by the vendor, suspend the use of these components unless an appropriate mitigation plan can be defined.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: CM-SS-R9 - Network Topology Documentation</summary><div class="toggle-content"><p>Keep storage-related network documentation up to date, including drawings of both Fibre Channel (FC) and IP.</p></div></details><details class="toggle" ><summary class="toggle-button" style="">Requirement: CM-SS-R10 - Review FC SAN Security Configurations</summary><div class="toggle-content"><p>Over time, certain security changes may not reliably propagate throughout the entire Fibre Channel (FC) fabric.</p><ul><li><em>Regularly review FC SAN</em> (similar to IP and Ethernet networks) to assess its security, identify and prioritize vulnerabilities, and define improvement plans.</li><li>Security audits should be conducted at least annually and, in sensitive environments, at least quarterly or after any major changes - whichever comes first.</li><li>Audit results should be documented.</li></ul></div></details><h1 id="4-12-ST-Storage-Security-Training">4.12 (ST) Storage Security Training</h1><details class="toggle" ><summary class="toggle-button" style="">Requirement: ST-SS-R1 - Storage Security Training Plan</summary><div class="toggle-content"><p>A storage security training plan should be developed and <em>incorporated into existing organizational training activities and schedules</em> to meet the following target audiences:</p><ol><li><em>Information security professionals</em>: Provide them with fundamental knowledge of storage security.</li><li><em>Storage administrators</em>: Familiarize them with storage security principles, as well as the organization’s policies and security baselines.</li><li><em>Managers</em>: Understand the fundamental principles of data protection.</li></ol></div></details>]]></content>
      
      
      <categories>
          
          <category> Research </category>
          
          <category> Database </category>
          
          <category> Security </category>
          
          <category> Master&#39;s Thesis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database </tag>
            
            <tag> Master&#39;s Thesis </tag>
            
            <tag> Cloud Storage </tag>
            
            <tag> Security </tag>
            
            <tag> NIST SP 800-209 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NIST SP 800-209 Security Guidelines for Storage (1) Threats and Risks</title>
      <link href="/en/posts/security-for-storage-infra/"/>
      <url>/en/posts/security-for-storage-infra/</url>
      
        <content type="html"><![CDATA[<h1 id="References">References</h1><ul><li><a href="https://csrc.nist.gov/publications/detail/sp/800-209/final">NIST SP800-209 Security Guidelines for Storage Infrastructure</a></li><li><a href="https://owasp.org/API-Security/editions/2023/en/0x11-t10/">OWASP API Top 10, 2023</a></li><li><a href="https://owasp.org/Top10/">OWASP Top 10, 2021</a></li><li><a href="https://ithelp.ithome.com.tw/m/articles/10294214">OWASP Top 10, 2021</a>: Summary by others with concise content.</li><li><a href="https://s.itho.me/ccms_slides/2022/9/29/6f51c8e9-67ba-4267-913d-d4461bba3894.pdf">OWASP Top 10, 2021</a>: Presentation with clearer details on specific measures and threats.</li></ul><h1 id="Introduction">Introduction</h1><p>Based on the previous content and research topics, it is essential to first understand that the main purpose of this article is to organize:</p><ul><li>[x] <code>What are the relevant threats and risks of data storage?</code></li><li>[ ] How to prevent these threats and risks with a zero-trust approach?</li></ul><hr><p>To be able to organize the relevant threats and risks of storage security, I have compiled the relevant security standards for Cloud Storage published by NIST, NIST SP 800-209. This document outlines:</p><ul><li><em>The evolution of storage technology landscape, current security threats, and the resulting risks</em>.</li><li>It primarily provides <em>a comprehensive set of security recommendations</em> to address threats, covering…<ul><li>Common security management areas of Information Technology (IT) infrastructure: such as physical security, identity authentication and authorization, change management, configuration control, and incident response and recovery.</li><li>Security management areas specific to storage infrastructure: such as storage infrastructure, data protection, isolation, recovery assurance, and encryption.</li></ul></li></ul><div class="note warning flat"><p>I will only organize data that I find useful or available, and I will include some personal observations or statements. Therefore, this article is for reference only, and the <em>correct content should be primarily referenced from NIST SP800-209</em>.</p></div><h1 id="Key-Summary">Key Summary</h1><p>Below is my key summary for this chapter, if you want to quickly understand, you can read this section.</p><blockquote><p>Mapping Threats and Risks - Summary of Chapter 3</p></blockquote><table><thead><tr><th><div style="width:130px">Threat</div></th><th>Possible Risks</th><th>Threat Level</th></tr></thead><tbody><tr><td>Backdoors and Unpatched Vulnerabilities</td><td>- Different risks depending on the type of <em>vulnerability</em>.<br> - Risks apply depending on whether <em>credentials are stolen or leaked</em>.</td><td>High</td></tr><tr><td>Privilege Escalation</td><td>- Risks depend on whether <em>administrator</em> or <em>user credentials are stolen or leaked</em>.</td><td>High</td></tr><tr><td>Human Error and Intentional Configuration Mistakes</td><td>- Different risks based on the <em>type</em> and <em>scope</em> of human or configuration errors.<br> - If it is a misconfiguration, <em>all risks in section 3.2</em> may occur.</td><td>High</td></tr><tr><td>Physical Theft of Media</td><td>- Different risks depending on the <em>scope</em> of theft.<br> - Risks include <em>data disclosure and exposure</em>, <em>data destruction</em>, <em>backup compromise</em>, and <em>data unavailability and service disruption</em> due to theft.</td><td>Medium</td></tr><tr><td>Insecure Images, Software, and Firmware</td><td>- Different risks based on the <em>type</em> and <em>scope</em> of impacts.<br> - If it is an insecure configuration, <em>all risks in section 3.2</em> may occur.</td><td>High</td></tr><tr><td>Malware and Ransomware Infection</td><td>- Malware can lead to <em>privilege elevation</em>, <em>credentials being stolen or leaked</em>, and other threats.<br> - Depending on where malware <em>appears</em>, such as in application systems or management systems, it can affect the occurrence of <em>all risks in section 3.2</em>.</td><td>High</td></tr><tr><td>Cryptographic Compromise</td><td>- May lead to <em>data disclosure and exposure</em> in (a) static data, (b) data in transit, and © data in user/administrator sessions.</td><td>Medium</td></tr><tr><td>Credentials Stolen or Leaked</td><td>1. <em>Application System</em>: Risks may include <em>data disclosure and exposure</em>, <em>unauthorized data changes and additions</em>, <em>data destruction</em>, etc.<br> 2. <em>Administrative System</em>: Risks include <em>backup compromise</em>, <em>ransomware attack</em>, <em>data unavailability and service disruption</em>, <em>tampering with storage-related logs and audit data</em>, and insecure storage configuration parameters.</td><td>High</td></tr></tbody></table><h1 id="2-11-Storage-and-Data-Management">2.11 Storage and Data Management</h1><p>As mentioned earlier, the following content primarily focuses on other aspects of storage and data management, rather than directly addressing “information security” control measures. Therefore, we will only provide a brief overview of the content briefly mentioned in NIST SP 800-209.</p><div class="note info flat"><p>My thoughts: What is significant in the above is “data protection.” The three aspects mentioned can be explored in the context of information assurance/security. Consider the integration of “data classification” and “data protection.” For example, using data classification for access control in data protection.</p></div><details class="toggle" ><summary class="toggle-button" style="">Storage Resource Configuration and Resource Management</summary><div class="toggle-content"><ul><li>Content: This section mainly explains key points to consider in the lifecycle of storage resource configuration or management. It covers areas such as managing and controlling “physical devices,” coordinating changes across multiple “assets,” performance management and optimization, asset management, and event management.</li><li>Thoughts: Not the main focus of the paper.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Data Classification or Categorization</summary><div class="toggle-content"><ul><li>It mentions referencing data regulations like PII, PCI-DSS, HIPAA, etc., to classify data more granularly and apply different protections to different types of data.</li><li>It can be categorized into several main types:<ul><li>Sensitivity (e.g., sensitive vs. non-sensitive).</li><li>Frequency (e.g., frequently accessed vs. infrequently accessed).</li><li>Environment (e.g., production environment vs. development environment vs. test environment vs. demo environment).</li></ul></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Data Sanitization</summary><div class="toggle-content"><ul><li>It explains the need to use appropriate data sanitization methods based on the type and specifics of the data.</li><li>It mentions that data sanitization can primarily be divided into the following categories:<ul><li>Clean: For example, overwriting existing data.</li><li>Purge: For example, using strong magnetic fields for demagnetization in magnetic media or using cryptographic erasure for encrypted data.</li><li>Destruct: For example, physically destroying media, such as burning or shredding.</li></ul></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Data Retention</summary><div class="toggle-content"><ul><li>It explains that in certain situations, specific data may need to be retained for a short-term, medium-term (i.e., less than 10 years), or long-term duration.</li><li>Data retention is typically achieved by backing up data copies to some medium. This might be done to fulfill operational, legal, regulatory, or statutory requirements.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Data Protection</summary><div class="toggle-content"><ul><li>It is a comprehensive term referring to all activities that ensure data is accessible, available, undamaged, and usable for all authorized purposes and meets acceptable performance levels.</li><li>These activities must comply with regulatory requirements, including privacy protection, and involve all physical, managerial, and technical means to ensure data is not accidentally or unauthorizedly disclosed, modified, or destroyed.</li><li>Data protection involves various lifecycle stages, including:<ul><li>(Storage) Static data on endpoints - data stored on servers or client devices.</li><li>(In transit) Data in transit - data transferred between storage devices, client to server, or server to server.</li><li>(In use) Data in use - data being viewed, modified, or synchronized between devices.</li><li>(Out of secure boundaries) Data outside secure boundaries - data during downloads, physical media transport, etc.</li></ul></li><li>Data protection can be divided into three aspects:<ol><li>Storage: Mainly discussing protection related to “storage” itself, such as backup, recovery, replication, immutability, continuous data protection, snapshots, etc.</li><li>Privacy: Mainly discussing the “privacy of data” itself, but this varies by region, and it’s not discussed here.</li><li>Information assurance/security: Mainly technical control measures, each of which requires a dedicated section to discuss its details, so it’s not discussed here.</li></ol></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Data Reduction</summary><div class="toggle-content"><ul><li>There are two common methods of data reduction, and these methods can be used in combination.<ul><li>Data Deduplication: Data deduplication attempts to replace multiple data copies with references pointing to a shared copy. It’s like having the same file, so you don’t need to copy multiple identical data.</li><li>Data Compression: Data is encoded using known algorithms to generate a data representation that takes up less storage space than the unencoded representation.</li></ul></li></ul></div></details><h1 id="3-Threats-Risks-and-Attack-Surfaces-Related-to-Storage-Infrastructure">3. Threats, Risks, and Attack Surfaces Related to Storage Infrastructure</h1><div class="note info flat"><p>Threat - The cause of potential unwanted events that may harm systems or organizations.</p></div><p>Chapter three primarily provides background information about “security threats,” “risks,” and “attack surfaces” (methods that may be used) related to storage system infrastructure.</p><h2 id="3-1-Threats">3.1 Threats</h2><p>Nine threats that Storage Infrastructure may encounter are primarily discussed:</p><details class="toggle" ><summary class="toggle-button" style="">3.3.1 Credential Theft or Compromise</summary><div class="toggle-content"><ul><li>The most common and <em>easily exploited is the theft of login credentials</em>.</li><li>The text mentions that effective credential theft involves “<em>directly obtaining the user’s password, rather than guessing</em>,” so relying solely on password length and complexity is often insufficient to protect the system from attacks. For example, the following scenarios do not depend on password complexity:<ul><li>Modern ransomware often collects passwords from the data it captures.</li><li>Keylogging is also a form of credential theft unaffected by password complexity, where malicious software can virtually monitor user-entered passwords[23].</li></ul></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">3.3.2 Cracking Encryption</summary><div class="toggle-content"><ul><li>Encryption key generation uses “randomness” to create keys. However, various vulnerabilities exist, from “weak encryption algorithms” and “weak key generators” to “server-side vulnerabilities,” key leakage, fundamental design flaws or vulnerabilities, and backdoors, etc. [24].</li><li>In simple terms, it’s essential to use strong encryption methods and protect encryption keys properly. Actively changing encryption keys can be a strategy to prevent key cracking or insufficient strength. In key generation, key strength, quality, and entropy play vital roles, and keys should not be reused.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">3.3.3 Infection of Malware and Ransomware</summary><div class="toggle-content"><ul><li>The text mentions that attacks on “storage management systems” are often easier than attacks on the “storage devices” themselves.</li><li>Therefore, <em>malware may cause harm when installed on storage management hosts</em>, such as stealing credentials, privilege escalation, data corruption, loss or alteration, and compromising future backups, among others.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">3.3.4 Backdoors and Unpatched Vulnerabilities</summary><div class="toggle-content"><ul><li>Backdoors are typically software mechanisms or features intentionally created by suppliers, individual contributors (in rare cases, possibly state or malicious actors), often considered reasonable by the authors (e.g., for support, debugging, national security, etc.).</li><li>Since backdoors have the potential for harm, they are not documented in official documents, and only a limited set of people are aware of their existence. However, over time, the existence of backdoors may be deliberately or inadvertently disclosed or discovered by the public.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">3.3.5 Privilege Escalation</summary><div class="toggle-content"><ul><li>Privilege escalation exploits software vulnerabilities, design or deployment flaws, or configuration errors to gain access rights to protected resources in applications or user contexts.</li><li>Privilege escalation is highly associated with backdoor vulnerabilities. Privilege escalation comes in two forms:<ol><li>Vertical privilege escalation (privilege elevation): Low-privilege users or applications accessing the functionality or content of high-privilege users or applications.</li><li>Horizontal privilege escalation: Ordinary users accessing functionality or content reserved for other ordinary users.</li></ol></li><li>Impact on databases:<ul><li>In storage systems, this threat may lead to various risks, including data corruption, data alteration, data loss, etc.</li><li>For example, an attacker may use escalated privileges to enter the storage system, delete volumes, and modify access configurations.</li><li>This type of attack may also jeopardize data backup copies (e.g., synchronous/asynchronous replicas, snapshots) or the generation of future backups.</li><li>Privilege escalation can occur at various levels, such as storage components (e.g., storage arrays, hosts, or clients), network devices, or management systems.</li></ul></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">3.3.6 Human Error and Deliberate Misconfiguration</summary><div class="toggle-content"><ul><li>Even with security controls in place, users may make technically supported storage configuration changes that still pose unacceptable risks.</li><li>Possible human errors include:<ul><li>Typographical errors.</li><li>Lack of understanding or familiarity with internal security standards and vendor best practices.</li><li>Communication errors between individuals or teams.</li><li>Errors related to storage infrastructure guidance or automation:<ul><li>Direct errors, such as defects in scripts and configuration files.</li><li>Indirect errors, such as unnoticed software dependencies.</li></ul></li><li>Mapping restricted object storage pools to public networks, stopping replication or backup for maintenance but failing to re-enable them afterward.</li></ul></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">3.3.7 Physical Theft of Storage Media</summary><div class="toggle-content"><ul><li>All data is ultimately stored on one or more physical media, making them vulnerable to theft.</li><li>These media, whether online or offline, may be removed from their designated (fixed) locations or stolen during physical transportation processes, such as archiving media used for backups during transport, or during storage device shipment as part of a data center migration project.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">3.3.8 Network Eavesdropping</summary><div class="toggle-content"><ul><li>Data may be intercepted when transmitted.</li><li>Transmission can involve many components: network cards (wired or wireless), transmission cables (power or optical), relays, switches, routers, etc. Any of these components may be compromised, and many forms of compromise are difficult or impossible to detect using state-of-the-art tools and methods.</li><li>Possible actions related to data include:<ul><li>Some transmission compromises may involve data interception (also known as passive eavesdropping).</li><li>It may also involve the insertion, deletion, or modification of data, metadata, or control traffic during transmission.</li></ul></li></ul></div></details><details class="toggle" style="border: 1px solid  Software"><summary class="toggle-button" style="background-color:  Software;color:  and Firmware">3.3.9 Insecure Images</summary><div class="toggle-content"><ul><li>Adversaries may attempt to interfere with the software distribution, updates, or installation processes of storage devices to introduce incorrect, outdated, or maliciously modified code (e.g., binary files, images, firmware, drivers, etc.).</li><li>The software update process may rely on complex delivery chains: each link in the chain may become a target for introducing tampered software.<ul><li><em>Publishers (e.g., vendors, third parties, open-source communities)</em>: Publishers may be penetrated to infect source code repositories, gain access to registered software or device access, and release modified, signed binary files on download sites or update servers.</li><li><em>Delivery methods (e.g., transmission or download, transportation of installation media, file copying by vendor staff)</em>.</li><li><em>Locally retained copies of organizations (e.g., proxy servers, internal file servers)</em>, etc.</li></ul></li><li>Affected storage components include: disk drives, tape drives and libraries, network cards and controllers (e.g., HBA, network interface cards or NIC, FCoE adapters, etc.), switches and other network devices, storage enclosures and arrays, storage operating systems, storage components of client operating systems, and more.</li></ul></div></details><h2 id="3-2-Risk">3.2 Risk</h2><p>This chapter describes the definition of security risks. The difference compared to 3.1 Threat can be summarized as follows:</p><div class="note warning flat"><p>Threat: It represents the potential locations for attacks or possible causes of Risk that have not yet resulted in harm to users or the organization (Risk).</p><p>Risk: It is the degree of threat to an entity (which could be an organization, system, or information). These risks mainly encompass the aspects of confidentiality, integrity, and availability that they might affect. This can impact an organization’s mission, reputation, assets, and other related interests.</p><p>For example, Threats include factors like “weak passwords” and “human configuration errors” (Threat) that can result in “data leakage” (Risk).</p></div><div class="note info flat"><p>Security risk is defined as the degree of threat to an entity (which could be an organization, system, or information) from potential situations or events (impact x probability). These risks mainly cover the aspects of confidentiality, integrity, and availability that they might affect. This can impact an organization’s mission, reputation, assets, and other related interests.</p></div><p>Some relevant security risks are as follows:</p><details class="toggle" ><summary class="toggle-button" style="">Data Breach and Data Exposure</summary><div class="toggle-content"><ul><li>Data Breach refers to incidents involving <em>sensitive and protected information being copied, transmitted, accessed, intentionally exposed to the public, or used by unauthorized individuals or entities</em>. The impact of data breaches can range from inconvenience to users to exposing sensitive or confidential data, resulting in irreversible damage to an organization’s reputation and operational health.</li><li>Data breaches can be caused by two main sources:<ul><li><em>External sources</em>, such as hackers or cybercriminals.</li><li><em>Internal personnel</em>, such as malicious insiders or disgruntled employees.</li></ul></li><li>Possible root causes include some of the Threats mentioned earlier:<ul><li>Weak encryption (or no encryption) during storage or transmission.</li><li>Software vulnerabilities.</li><li>Loss of removable media.</li><li>Theft of media.</li><li>Incorrect or overly permissive access controls.</li><li>Incorrect or incomplete data sanitization practices (including object deletion, retirement, or media reuse).</li><li>Sending information to the wrong recipients.</li><li>Uploading data in an incorrect manner (e.g., uploading protected data to public data repositories).</li></ul></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Unauthorized Data Alteration and Addition</summary><div class="toggle-content"><ul><li><em>Attackers gain access to data storage infrastructure</em> in a way that allows them to <em>modify data</em> in a manner that affects future application transactions or other uses of the data.</li><li>Unauthorized data alteration and addition can come from external or internal sources and may be done in a covert or easily detectable manner.</li><li>This risk can be achieved using a “salami attack” method, where attackers steal small amounts of data or funds from a large number of transactions over an extended period.</li><li>The impact of data alteration and addition can range from financial losses to permanent damage to reputation and trust.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Data Corruption</summary><div class="toggle-content"><ul><li>Data Corruption refers to data that is damaged or altered unexpectedly during writing, reading, storage, transmission, or processing. It results in unexpected outcomes (exceptions) when objects containing the corrupted data are accessed in the system or related applications.</li><li>Typically, when Data Corruption occurs, it leads to unexpected outcomes when objects containing the data are accessed in the system or related applications. These outcomes can range from minor data loss to system crashes.</li><li>Specific scenarios include:<ul><li>If a file is corrupted, users may not be able to open it, or it may open with some or all of its data rendered unreadable.</li><li>Some types of malicious software may intentionally corrupt or destroy files by overwriting their contents with invalid or garbage code or by securely erasing their content in a security-conscious way.</li></ul></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Compromising Backups</summary><div class="toggle-content"><ul><li>Data backups are essential, including <em>retaining copies of data, snapshots, etc</em>. Backups allow us to recover these assets in case of data corruption or loss.</li><li>There are several considerations for backups:<ul><li><em>Data Consistency</em>: Backups must be “correctly generated” and have appropriate “retention frequencies” and “update frequencies.”</li><li><em>Backup Security</em>: The storage of backups must also be secure to prevent unauthorized access.</li></ul></li><li>Failure modes for backups include:<ul><li>Lack of consideration for consistency or integrity of write order during backups, which can lead to incorrect configurations.</li><li>Insufficient retention periods or infrequent backup updates, which may result in the inability to recover certain old or new data.</li></ul></li><li>Attack strategies:<ul><li><em>Disruption of the Backup Process</em>: When existing backups cannot be compromised, another viable attack strategy is to <em>disrupt the backup process itself, gradually “poisoning” future backups</em>. By the time the only available backups are too outdated, it becomes impossible to fully recover data.</li><li><em>Targeting Backup Copies of Specific Systems or Applications</em>: For example, operating system images, software packages, firmware, source code repositories, etc. This way, when attempting to respond to an infection by rebuilding individual components or entire environments, at least some malicious code is reintroduced into the environment, allowing the attacker to quickly regain control of the system or cause more damage.</li></ul></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Malicious Data Obfuscation and Encryption</summary><div class="toggle-content"><ul><li><em>Reversible data obfuscation and/or encryption makes data “unavailable” to users or organizations unless restored using keys held exclusively by attackers</em>.</li><li>This type of risk is commonly used in ransomware attacks, where victims’ data is encrypted, and a ransom is demanded to regain access to the data.</li><li>Recent developments have expanded from targeting data or files on user devices or enterprise servers to other storage components such as NAS and backup devices.</li><li>Impact: These attacks are typically designed to be identified, and they often come with threats and ransom demands. The impact of data obfuscation and encryption can range from financial losses to permanent damage to reputation and trust.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Data Unavailability and Denial of Service</summary><div class="toggle-content"><ul><li><em>Data customers are unable to access some or all of their data</em>. While such damage may be reversible (e.g., by restoring altered or deleted configurations), it can result in prolonged downtime and service interruptions.</li><li>Risks of data unavailability interruptions may be caused by:<ul><li>Damage to “communication paths” or “access configurations,” intentionally or unintentionally.</li><li>Physical damage, such as interruptions in communication paths.</li><li>Logical damage:<ul><li>Endpoint configuration errors of network components.</li><li>Modification or deletion of access control (SAN) settings by attackers.</li><li>Suspension of exports in NFS (Network File System) preventing clients from accessing their data.</li></ul></li></ul></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Tampering of Storage-Related Log and Audit Data</summary><div class="toggle-content"><ul><li>It refers to attackers deleting or modifying log data (e.g., timestamps) to <em>prevent effective audit trails, cover up attacks (real-time or post-event), or provide false information to investigators</em>.</li><li>Attack behaviors:<ul><li><em>Disabling Logging Systems</em>: Attackers may attempt to temporarily or permanently disable the logging function of the target system, making their activities untraceable and their attacks less likely to be discovered and traced.</li><li><em>Filling All Available Space with Bogus Information</em>: Attackers may write a large amount of false log information to fill the available log space, making it difficult to correctly record and store real log data, confusing investigators and tracking.</li><li><em>Redirecting Log Data to Rogue Log Servers</em>: Attackers may use social engineering or deceptive means against clients or users to have them send valuable log data to rogue or fake log servers controlled by the attackers, making it easier for the attackers to gain control of sensitive information.</li></ul></li><li>Impact: The goal of these actions is to disrupt, confuse, and conceal attack activities to protect the attacker’s identity and hinder security personnel from tracking and investigating the attack event.</li></ul></div></details><details class="toggle" style="border: 1px solid  Firmware and Images"><summary class="toggle-button" style="background-color:  Firmware and Images;">Compromising Storage OS or Binaries</summary><div class="toggle-content"><ul><li>Attacks on storage software, including the operating system, firmware, images of storage devices, etc., resulting in adverse consequences that provide attackers with means for remote access, reading, copying, altering, or destroying data and its copies, changing security settings, exposing data, altering storage infrastructure behavior, etc.</li><li>Possible outcomes:<ul><li>Changes in storage behavior can be used to introduce various potential and difficult-to-detect attacks.</li><li>Presentation of incorrect data to storage clients (even if stored data is intact).</li><li>Provision of incorrect statuses to storage clients, such as false reporting of the presence or state of snapshots and security settings.</li></ul></li></ul></div></details><h2 id="3-3-Attack-Surface">3.3 Attack Surface</h2><div class="note info flat"><p>The attack surface is defined as “the sum of the different points (the ‘attack vectors’) where an unauthorized user (the ‘attacker’) can try to enter data into or extract data from an environment” [31].</p></div><p>This section will list common digital and physical attack surfaces related to storage infrastructure.</p><details class="toggle" ><summary class="toggle-button" style="">Physical Access</summary><div class="toggle-content"><ul><li><em>Physical access protection is the last line of defense</em>. Once an intruder gains access to the storage infrastructure, they may ultimately attempt data theft, copying, or corruption, or even modify access configurations for remote access.</li><li><em>Targets include infiltrating physical devices</em>: intrusion into data centers, peripheral areas, communication infrastructure (cabling), transportation of physical objects (hosts, disks, etc.).</li><li>There are two methods for physical access:<ol><li>“Explicit access”: Attackers pretend to be legitimate personnel to enter protected physical devices.</li><li>“Tailgating”: Attackers pose as legitimate visitors and follow them to gain physical access to protected devices.</li></ol></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Access to Storage Operating System</summary><div class="toggle-content"><ul><li>The primary <em>objective of this attack is to infiltrate storage devices through the operating system</em>.</li><li>Possible threats:<ul><li>Operating systems all have <em>security vulnerabilities</em>, so regular updates with security patches are essential.</li><li>Operating systems may be affected by <em>improper configurations</em>, allowing attackers various methods of access, including local login processes (SSH, rshell, telnet), remote login via TCP/IP, and exploiting system vulnerabilities.</li></ul></li><li>In the case of “Hyper-Converged Infrastructure (HCI),” the attack surface may be larger as it involves multiple host operating systems.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Access to Management Hosts</summary><div class="toggle-content"><ul><li>Most storage components are primarily managed or configured through “commercial operating system hosts.”</li><li>Attackers may infiltrate management hosts in the following ways:<ol><li><em>Through malicious software</em>: Infiltrating management hosts.</li><li><em>Exploiting vulnerabilities in the operating system</em>: Carrying out attacks.</li></ol></li><li>Possible attack behaviors include compromising executables, reading cached data, installing eavesdropping devices to read memory data, installing malicious software, and obtaining configuration information.</li><li>Risks associated with infiltrating management hosts can lead to data corruption, data loss, tampering with backups, altering logs, and audits, making the damage potentially limitless.</li></ul></div></details><details class="toggle" style="border: 1px solid  Management Software"><summary class="toggle-button" style="background-color:  Management Software;color:  and In-Band Management">Management APIs</summary><div class="toggle-content"><ul><li>Storage infrastructure components typically expose “management interfaces” such as “user interfaces (UIs),” “APIs,” or related management protocols to manage the associated devices.</li><li>For example, management interfaces may include access protocols (SOAP), REST APIs, etc., interacting with external network services for key management, authentication, and authorization.</li><li>These management interfaces can introduce various attack surfaces, including:<ol><li><em>Accessing storage devices through management interfaces (APIs) without infiltrating management software</em>.</li><li>Performing <em>in-band access</em> through data links (e.g., fiber channels), impersonating clients to send management commands.</li></ol></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Storage Clients</summary><div class="toggle-content"><ul><li>Storage clients are typically “computing components” or “applications installed on computing components” that use storage protocols to “read” resources.</li><li>Attackers may employ various attack methods by infiltrating clients, including:<ol><li>Sending management commands to storage devices through clients.</li><li>Compromising clients used for creating backups, potentially harming future backups.</li></ol></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Storage Network</summary><div class="toggle-content"><ul><li>Attackers primarily gain access through <em>infiltrating network components</em> (including host adapters, switches, cables, extenders) and attacks on data transmission paths, leading to possible attack behaviors:<ol><li><em>Data</em>: Copying, viewing, redirecting, or stealing.</li><li><em>Configuration data</em>: Reading user credentials, encryption keys, etc.</li><li><em>Network components</em>: Disrupting network components, modifying valid payloads, damaging or altering and adding data.</li><li><em>Performing Man-in-the-Middle attacks (MITM)</em>: Sniffing data, bypassing encryption and authentication mechanisms.</li></ol></li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Compute Environment of Key Individuals</summary><div class="toggle-content"><ul><li>Some “key users” have “management rights” over the “storage infrastructure,” such as remote connections to storage management hosts.</li><li>The “computing environment of key users” (e.g., laptops, desktops, home networks) may be exploited as a foothold to gain access to the storage infrastructure, causing damage.</li><li>For example, installing malicious software on a key user’s device, which then installs keyloggers to intercept login credentials.</li></ul></div></details><details class="toggle" ><summary class="toggle-button" style="">Electrical Network and other Utilities</summary><div class="toggle-content"><ul><li>The “storage infrastructure” is connected to the electrical network, making it a potential attack surface. Possible attacks include:<ul><li>Sudden power surges, lightning: Causing damage, including erasing data on electromagnetic disks.</li><li>Through malicious software (e.g., PowerHammer): Exfiltrating data by modulating the power consumption (CPU workload) of infected machines or altering current flow to steal sensitive information like passwords and encryption keys.</li><li>Line-level attacks: Intercepting data by eavesdropping on the power cables of infected computers.</li><li>Non-Intrusive data theft: Collecting information by measuring signals emitted on power cables and decoding them into binary form.</li></ul></li><li><em>Other utilities, security, and environmental control systems</em> may introduce risks such as system risks (e.g., overheating, floods, explosions), data leakage risks (e.g., stealing video surveillance to intercept password input or capturing content from screens, panels, indicator lights), and attempts to hijack the internal communication capabilities of environmental systems (e.g., WiFi, Bluetooth) to evade air gap isolation and network controls.</li></ul></div></details><h1 id="Consolidation-01-Organizing-Threats-and-Physical-Attacks-Reference-OWASP">Consolidation 01: Organizing Threats and Physical Attacks (Reference OWASP)</h1><p>Before creating a threat model, we need to organize the attack techniques used in threats more clearly to facilitate the creation of the threat model.</p><p>There is a close relationship between API security and databases. The <code>OWASP Top 10</code> is a list of the most common web application security risks published by the Open Web Application Security Project (OWASP), and in the 2023 version, the top ten API security risks have been included, reflecting the importance of API security in modern applications.</p><p>In addition, <code>NIST SP 800-209</code> provides guidelines on database security, especially in <em>Section 4.6</em>, which mentions <code>access control recommendations</code> related to <em>network infrastructure and protocols</em>. This is because databases involve the storage, management, and access of data, while network infrastructure and protocols are essential components that support data transmission and access. Therefore, here we will refer to <code>OWASP Top 10 2021</code>, <code>OWASP Top 10 2023</code> for reference and then map the threats that databases may pose to what is mentioned in NIST SP800-209 Section 3.2.</p><h2 id="1-Credential-Theft-or-Compromise">1. Credential Theft or Compromise</h2><p>Primary Defense Measures:</p><ul><li>Use secure encryption protocols such as TLS 1.2, TLS 1.3</li><li>Use iterated hashing algorithms like Argon2, scrypt, bcrypt, or PBKDF2 with salt to store passwords securely</li><li>Implement corresponding control measures based on processing, storage, and transmission behavior</li><li>Disable caching for responses containing sensitive data</li></ul><table><thead><tr><th>Reference Source</th><th>Related Threats</th><th>Description</th><th><div style="width:130px">NIST SP 800-209 Security Recommendations</div></th></tr></thead><tbody><tr><td>NIST SP 800-209</td><td>3.3.1 Credential Theft or Compromise</td><td>NIST SP 800-209 indicates that effective credential theft is mostly “direct acquisition of the user’s password, rather than guessing,” so relying solely on password length and complexity is usually insufficient to protect the system from attacks.</td><td>- Chapter 4.9 Encryption <br> - Chapter 4.3 Authentication and Data Access Control</td></tr><tr><td>OWASP 2023</td><td>API2:2023 Broken Authentication</td><td>Improper implementation of authentication mechanisms can allow attackers to compromise or abuse authentication tokens, temporarily or permanently impersonating other users. Compromising user/client identification capabilities can harm the overall security of the API.</td><td>- Chapter 4.9 Encryption <br> - Chapter 4.3 Authentication and Data Access Control</td></tr></tbody></table><h2 id="2-Cracking-Encryption">2. Cracking Encryption</h2><p>Primary Defense Measures:</p><ul><li>Using strong encryption methods is essential</li><li>Safeguard encryption keys properly</li><li>Regularly change encryption keys as a strategy to prevent them from being cracked or weak</li><li>Key strength, quality, and entropy play important roles in key generation, and keys should not be reused</li></ul><table><thead><tr><th>Reference Source</th><th>Related Threats</th><th>Description</th><th><div style="width:130px">NIST SP 800-209 Security Recommendations</div></th></tr></thead><tbody><tr><td>NIST SP 800-209</td><td>3.3.2 Cracking Encryption</td><td>Vulnerabilities such as weak encryption algorithms, weak key generators, or server-side vulnerabilities can lead to cracking encryption.</td><td>- Chapter 4.9 Encryption <br> - Requirement: EN-SS-R9 - Encryption Key Management Requirements <br> - Requirement: EN-SS-R6 - Static Encryption of Sensitive Data</td></tr><tr><td>OWASP 2021</td><td>A02:2021 Cryptographic Failures</td><td>This category typically results from the use of weaker encryption algorithms or weak key generators in cryptographic algorithms, leading to the exposure of sensitive data or compromise of systems.</td><td>- Chapter 4.9 Encryption <br> - Requirement: EN-SS-R9 - Encryption Key Management Requirements <br> - Requirement: EN-SS-R6 - Static Encryption of Sensitive Data</td></tr></tbody></table><h2 id="3-Infection-of-Malware-and-Ransomware">3. Infection of Malware and Ransomware</h2><p>Primary Defense Measures:</p><ul><li>Disaster recovery copies of critical data should be scanned with various anti-malware scanning tools to detect known vulnerabilities and anomalies.</li><li>For sensitive data, regular use of antivirus tools to scan at least one subset of past copies to identify infected copies.</li></ul><table><thead><tr><th>Reference Source</th><th>Related Threats</th><th>Description</th><th><div style="width:130px">NIST SP 800-209 Security Recommendations</div></th></tr></thead><tbody><tr><td>NIST SP 800-209</td><td>3.3.3 Infection of Malware and Ransomware</td><td>Attacks often target “storage management systems” rather than the “storage devices” themselves. Therefore, malware may cause harm by being installed on the storage management host, such as stealing credentials, elevating privileges, data corruption, loss, or alteration, and disrupting future backups.</td><td>- Requirement AC-SS-R33 - Use of Anti-Malware Scanning Tools <br> - Requirement RA-SS-R11 - Network Security Measures for Data Copies <br> - Requirement: DP-SS-R3.c Requirements for Backup-Related Standard Operating Procedures</td></tr></tbody></table><h2 id="4-Backdoors-and-Unpatched-Vulnerabilities">4. Backdoors and Unpatched Vulnerabilities</h2><p>Primary Defense Measures:</p><ul><li>Features like call home or remote access are often used to collect telemetry and diagnostic data for manufacturer analysis and technical issue resolution, as well as for automatic software updates. However, these features can also be targeted by hackers, so they should be disabled if not needed, or limited and controlled if necessary.</li><li>Ensure the storage software versions are up to date</li><li>Install critical security updates and patches</li><li>Develop mitigation plans for cases where patches cannot be obtained</li></ul><table><thead><tr><th>Reference Source</th><th>Related Threats</th><th>Description</th><th><div style="width:130px">NIST SP 800-209 Security Recommendations</div></th></tr></thead><tbody><tr><td>NIST SP 800-209</td><td>3.3.4 Backdoors and Unpatched Vulnerabilities</td><td>Backdoors are usually software mechanisms or features intentionally created by suppliers, individual contributors (in rare cases, it may be state or malicious actors), and are not documented in official documentation due to the potential harm they pose. However, over time, the existence of backdoors may be intentionally or unintentionally disclosed or discovered by the public.</td><td>- Requirement: NC-SS-R10 Disable Unused Storage Area Network (SAN) Ports <br> - Chapter 4.6 Network Configuration Guidelines <br> - Requirement: AA-SS-R11 Disable or Limit Call Home or Remote Access <br> - Requirement: CM-SS-R8 Software Updates and Patches</td></tr></tbody></table><h2 id="5-Privilege-Escalation">5. Privilege Escalation</h2><p>Primary Defense Measures:</p><ul><li>Except for public resources, <code>default to deny access</code></li><li>Establish <code>access control mechanisms</code> and apply them consistently</li><li>Log access control failures and set alerts (e.g., repeated login failures)</li><li>Implement traffic limits for API access to reduce damage from automated attacks</li><li>Invalidate identity-based cookies upon logout or timeout</li><li>Use the shortest access time for JWTs; if JWTs are used for extended periods, it is recommended to follow OAuth standards to invalidate them</li></ul><table><thead><tr><th>Reference Source</th><th>Related Threats</th><th>Description</th><th><div style="width:130px">NIST SP 800-209 Security Recommendations</div></th></tr></thead><tbody><tr><td>NIST SP 800-209</td><td>3.3.5 Privilege Escalation</td><td>Exploiting software vulnerabilities, design or deployment flaws, or configuration errors to gain unauthorized access to protected resources of applications or users.</td><td>- Chapter 4.3 Identity and Data Access Control <br> - Requirement: AC-SS-R26 Default Partition Permissions</td></tr><tr><td>OWASP 2023</td><td>API3:2023 - Broken Object Property Level Authorization</td><td>Missing or improper authorization validation at the object property level leading to information leakage or unauthorized tampering.</td><td>Same as above</td></tr><tr><td>OWASP 2023</td><td>API5:2023 - Broken Function Level Authorization</td><td>Complex access control policies involving different levels, configurations, and roles without clear separation between management and regular functions, allowing attackers to send API requests to endpoints they should not access, leading to authorization vulnerabilities.</td><td>Same as above</td></tr><tr><td>OWASP 2021</td><td>A01:2021 Broken Access Control</td><td>Control measures failing resulting in unauthorized information disclosure, modification, corruption, or execution of business functions beyond the original permissions.</td><td>Same as above</td></tr><tr><td>OWASP 2021</td><td>A07:2021 Identification and Authentication Failures</td><td>Previously known as Broken Authentication, common flaws in account login/logout design mechanisms, with standardized frameworks helping to reduce the likelihood of such risks.</td><td>Same as above</td></tr></tbody></table><h2 id="6-Human-Error-and-Deliberate-Misconfiguration">6. Human Error and Deliberate Misconfiguration</h2><p>Main Defensive Measures:</p><ul><li>Automated processes for deploying and verifying various security settings in the environment.</li><li>Consistent configurations across development and operational environments with different credentials.</li><li>Minimization and localization of server functionality.</li><li>Conduct security reviews and changes based on relevant updates (Refer to A06:2021 Dangerous or Outdated Components).</li><li>Use security headers.</li><li>Organizations should be able to recover data when production data is damaged or lost by replicating or backing up data copies, ensuring sufficient isolation between data assets and their recovery copies.</li><li>Ensure successful recovery in case of business disruptions, disaster recovery events, or security breaches.</li><li>Maintain a comprehensive and real-time configuration management list, manage changes, and ensure configurations consistently align with the organization’s security baselines and current industry best practices, while safeguarding against known risks.</li></ul><table><thead><tr><th>Reference Source</th><th>Related Threats</th><th>Description</th><th><div style="width:130px">NIST SP 800-209 Security Recommendations</div></th></tr></thead><tbody><tr><td>NIST SP 800-209</td><td>3.3.6 Human Error and Deliberate Misconfiguration</td><td>Unacceptable risks caused by technical support users making storage configuration changes.</td><td>- Chapter 4.7 Isolation <br> - Chapter 4.8 Recovery Assurance <br> - Chapter 4.11 Configuration Management</td></tr><tr><td>OWASP 2023</td><td>API4:2023 - Unrestricted Resource Consumption</td><td>APIs are often designed to return data for queries, requiring resources such as network bandwidth, CPU, memory, and storage. Other resources like email/SMS/phone or biometric authentication are integrated through APIs provided by service providers and billed on a per-request basis. Successful attackers may exploit this risk, leading to denial of service or increased operational costs.</td><td>Same as above</td></tr><tr><td>OWASP 2023</td><td>API8:2023 - Security Misconfiguration</td><td>APIs and supporting systems often involve complex configurations, designed to make APIs more flexible and customizable. Software and DevOps engineers may overlook these configurations or not follow security best practices in configuration, opening doors to attacks.</td><td>Same as above</td></tr><tr><td>OWASP 2021</td><td>A05:2021 Security Misconfiguration</td><td>Unnecessary features, services, ports, or security risks opened in a production environment, including XML External Entity (XXE) attacks.</td><td>Same as above</td></tr><tr><td>OWASP 2021</td><td>A08:2021 Software and Data Integrity Failures</td><td>Insecure Continuous Integration/Continuous Deployment (CI/CD) processes, using automatic updates lacking sufficient integrity verification.</td><td>Same as above</td></tr></tbody></table><h2 id="7-Physical-Theft-of-Storage-Media">7. Physical Theft of Storage Media</h2><p>Main Defensive Measures:</p><ul><li>Backup of network-attacked recovery should be stored offline, separate from production data.</li><li>This ensures that even if attackers gain physical access to production locations or successfully infiltrate physical locations, they cannot access or damage network-attacked recovery backups.</li><li>Physical security is a fundamental element of ensuring the security of any information technology infrastructure. Often, “physical security of storage infrastructure” requirements should be the same as “other infrastructure elements” (such as facility security, monitoring, transportation, etc.).<ul><li>Relevant standards for infrastructure elements include NIST SP 800-53, Rev5, NIST SP 800-171.</li><li>For media disposal and destruction, you can refer to ISO 27040, NIST SP 800-88 for further discussion.</li></ul></li></ul><table><thead><tr><th>Reference Source</th><th>Related Threats</th><th>Description</th><th><div style="width:130px">NIST SP 800-209 Security Recommendations</div></th></tr></thead><tbody><tr><td>NIST SP 800-209</td><td>3.3.7 Physical Theft of Storage Media</td><td>All data ultimately resides on one or more physical media that are susceptible to theft. Whether online or offline, they may be removed from their designated (fixed) locations or stolen during physical transport, such as archiving media used for backups or transporting storage devices as part of a data center migration project.</td><td>Chapter 4.1 Physical Storage Security</td></tr></tbody></table><h2 id="8-Network-Eavesdropping">8. Network Eavesdropping</h2><p>Main Defensive Measures:</p><ul><li>You can refer to NIST SP 800-209 Chapter 4.6 Network Configuration Guidance, which mainly covers network infrastructure (such as switches, ports, HBA and NIC configurations, zoning guidelines, etc.) and protocols.</li></ul><table><thead><tr><th>Reference Source</th><th>Related Threats</th><th>Description</th><th><div style="width:130px">NIST SP 800-209 Security Recommendations</div></th></tr></thead><tbody><tr><td>NIST SP 800-209</td><td>3.3.8 Network Eavesdropping</td><td>Data may be intercepted during transmission. Transmission can cover many components: network cards (wired or wireless), transmission cables (carrying power or light), relays, switches, routers, etc. Any of these components may be compromised, involving the insertion, deletion, or modification of data during transmission, metadata, or control flow.</td><td>Chapter 4.6 Network Configuration Guidance</td></tr></tbody></table><h2 id="9-Insecure-Images-Software-and-Firmware">9. Insecure Images, Software and Firmware</h2><p>While NIST SP 800-209 provides fewer specific security recommendations for applications, data leaks often occur due to insecure applications. However, it discusses less about securing the interaction between applications (AP) and data.</p><p>Security recommendations related to applications in the standard mainly include:</p><ul><li>Requirement 4.2.1 Data Backup, Recovery, and Storage<ul><li>Emphasizes data integrity at the application and business process levels in terms of data backup, recovery, and storage.</li><li>Strictly requires application availability during restoration.</li></ul></li><li>Requirement NC-SS-R3 - Use a mixed method for zoning<ul><li>Involves host-based partitioning mechanisms to control what resources or storage data an application on the host can access and view.</li></ul></li><li>Requirement RA-SS-R9 - Separation of data and application recovery<ul><li>Advocates isolating data from applications during data recovery to avoid restoring compromised code or software.</li></ul></li><li>Chapter 4.3 Identity and Data Access Control<ul><li>Recommends limiting privileged access for applications to reduce the risk of attacks on storage systems.</li></ul></li></ul><p>In the context of insecure images, software, and firmware, the following recommendations apply:</p><ul><li>Requirement AC-SS-R33 - Use anti-malware scanning tools</li><li>Requirement RA-SS-R11 - Network security measures for data copies</li><li>Requirement DP-SS-R3.c includes requirements for backup-related standard operating procedures</li></ul><table><thead><tr><th>Threat Source</th><th>Related Threats</th><th>Description</th><th><div style="width:130px">NIST SP 800-209 Security Recommendations</div></th></tr></thead><tbody><tr><td>Applications (Client-side)</td><td>API1:2023 - Broken Object Level Authorization</td><td>APIs often handle object identification publicly, creating a broad attack surface related to object access control. OWASP suggests designing object authorization in every feature to prevent unauthorized information disclosure, data tampering, or destruction.</td><td>- Requirement 4.2.1 Data Backup, Recovery, and Storage <br> - Requirement NC-SS-R3 - Use a mixed method for zoning  <br> - Requirement RA-SS-R9 - Separation of data and application recovery <br> - Chapter 4.3 Identity and Data Access Control</td></tr><tr><td>Applications (Client-side)</td><td>API6:2023 - Unrestricted Access to Sensitive Business Flows</td><td>Threats due to application flow issues may affect APIs because of excessive automation.</td><td>Same as above</td></tr><tr><td>Applications (Client-side)</td><td>API7:2023 - Server Side Request Forgery</td><td>When APIs fetch remote resources without verifying the URI provided by unauthenticated users, server-side request forgery (SSRF) flaws can occur. This allows attackers to send crafted requests to unexpected destinations, even behind firewalls or VPNs.</td><td>Same as above</td></tr><tr><td>Applications (Client-side)</td><td>API9:2023 - Improper Inventory Management</td><td>APIs often expose more endpoints than traditional web applications, making accurate and up-to-date documentation critical. Proper management of hosts and API versions is also essential to reduce maintenance issues such as deprecated API versions and exposed testing endpoints.</td><td>Same as above</td></tr><tr><td>Applications (Client-side)</td><td>A03:2021 Injection</td><td>Includes XSS attacks, SQL injection, and command injection.</td><td>Same as above</td></tr><tr><td>Applications (Client-side)</td><td>A04:2021 Insecure Design</td><td>Security issues resulting from incomplete system and feature design.</td><td>Same as above</td></tr><tr><td>Applications (Client-side)</td><td>A10:2021 SSRF</td><td>When web servers fetch remote resources without verifying the URL provided by users, SSRF attacks can occur, even with firewall, VPN, or other network ACL protections in place. The severity of SSRF attacks increases with cloud services and their complex structures.</td><td>Same as above</td></tr><tr><td>Images, Software, and Firmware</td><td>3.3.9 Insecure Images, Software and Firmware</td><td>Refers to attempts to disrupt the software distribution, updates, or installation process of storage devices to introduce incorrect, outdated, or maliciously modified code. Every aspect of the software update process may be a target for introducing tampered software, including publishers (e.g., vendors, third parties, open-source communities), delivery methods (e.g., transmission or download, transportation of installation media, file copying by vendor employees), and individual organization-maintained local copies (e.g., proxy servers, internal file servers).</td><td>- Requirement AC-SS-R33 - Use anti-malware scanning tools <br> - Requirement RA-SS-R11 - Network security measures for data copies <br> - Requirement DP-SS-R3.c includes requirements for backup-related standard operating procedures</td></tr><tr><td>Third-party Packages</td><td>API10:2023 Unsafe Consumption of APIs</td><td>Developers often trust data from third-party APIs more, leading to weaker security standards for third-party APIs. Attackers tend to prioritize attacking third-party services rather than directly attempting to compromise the target API.</td><td>Same as above</td></tr><tr><td>Third-party Packages</td><td>A06:2021 Vulnerable and Outdated Components</td><td>Using components (operating systems, software, packages, libraries, frameworks) with known vulnerabilities in system development.</td><td>Same as above</td></tr><tr><td>Third-party Packages</td><td>A08:2021 Software and Data Integrity Failures</td><td>Focuses on deserialization attacks and trust issues with third-party packages, libraries, modules, etc., including failure to protect software and data integrity, insecure deserialization, and the use of untrusted sources for packages, libraries, modules, etc.</td><td>Same as above</td></tr></tbody></table><h2 id="10-Security-Logging-and-Monitoring-Failures">10. Security Logging and Monitoring Failures</h2><p>While NIST SP 800-209 does not list specific threats related to security logging, OWASP Top 10 2021 (A09) mentions threats related to security logging and monitoring failures. Chapter 4.4 (AL) of NIST SP 800-209 also emphasizes the importance of security logging and monitoring and provides related recommendations. Therefore, this section adds a threat aspect for security logging and monitoring.</p><table><thead><tr><th>Related Threats</th><th>Description</th><th>Defensive Measures</th></tr></thead><tbody><tr><td>AA09:2021 Security Logging and Monitoring Failures</td><td>Such failures can directly impact visibility, event alerts, and forensics.</td><td>Chapter 4.4 (AL) Audit Logs</td></tr></tbody></table><h1 id="Consolidated-Threat-Model-02-Design-Threat-Model">Consolidated Threat Model 02: Design Threat Model</h1><p>The following threat model is a compilation of common threats referencing NIST SP 800-209 and OWASP Top 10. The environment briefly describes threats that the data infrastructure may face, including system boundaries, data transmission, backup monitoring, and more. Based on these threats, refer to the relevant threat descriptions and security recommendations in Consolidated Threat Model 01.</p><p><img src="https://i.imgur.com/HOvKOAN.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> Research </category>
          
          <category> Database </category>
          
          <category> Security </category>
          
          <category> Graduation Thesis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database </tag>
            
            <tag> Master&#39;s Thesis </tag>
            
            <tag> Cloud Storage </tag>
            
            <tag> Security </tag>
            
            <tag> NIST SP 800-209 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>How to Intervene in Connection Pool?</title>
      <link href="/en/posts/interupt-connection-pool/"/>
      <url>/en/posts/interupt-connection-pool/</url>
      
        <content type="html"><![CDATA[<h1 id="Reference-Links">Reference Links</h1><ul><li><a href="https://wearecommunity.io/communities/india-java-user-group/articles/2344">Hikari Connection Pooling with Spring Boot</a></li><li><a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-proxy.html">AWS RDS Proxy</a></li><li><a href="https://github.com/brettwooldridge/HikariCP">Hikrai-Source Code</a></li><li><a href="https://www.ithome.com.tw/news/138554">AWS Launches Proxy Service to Boost Scalability of Relational Database Applications</a></li><li><a href="https://blog.csdn.net/fly_duck/article/details/109755842?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-109755842-blog-124268396.235%5Ev38%5Epc_relevant_sort&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-109755842-blog-124268396.235%5Ev38%5Epc_relevant_sort&amp;utm_relevant_index=2">Hikari Configuration Settings</a></li><li><a href="https://blog.csdn.net/wangmx1993328/article/details/81865153?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=SpringBoot%20Hikari%20%E8%87%AA%E5%AE%9A%E7%BE%A9datasourc&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-3-81865153.nonecase&amp;spm=1018.2226.3001.4187">Inject Druid DataSource for Monitoring</a></li><li><a href="https://blog.51cto.com/boytnt/5794967">How to Specify Your Own DataSource Extending Hirkari</a></li><li><a href="https://www.modb.pro/db/59110">How to Build a Practical RDS Proxy? (Part 1)</a>: Briefly mentions implementing an RDS Proxy using Golang</li><li><a href="https://github.com/ShannonHung/kingshard">kingshard</a>: An open-source MySQL Proxy written in Go, no longer actively maintained</li><li><a href="https://dev.mysql.com/doc/internals/en/connection-phase.html">MySQL Official Connection Phase Description</a>: Official connection protocol documentation</li><li><a href="https://www.jianshu.com/p/af1c5406c737">Capturing MySQL Handshake Protocol</a>: Provides a general overview of capturing MySQL protocol packets</li><li><a href="https://ithelp.ithome.com.tw/articles/10226783">Database Layer Expansion from 30 to 25 - Read/Write Separation Architecture</a>: Explains database read/write separation</li></ul><h1 id="Introduction">Introduction</h1><p>You can refer to my research direction, which is about meeting zero-trust requirements in a database. <strong>The core of zero-trust mechanisms is essentially access control mechanisms</strong>. When it comes to Authentication (verifying who a person is), you gather all relevant context, including risks, and after careful consideration, you perform Authorization (granting access). Since our goal is to meet zero-trust requirements in a database…</p><blockquote><p>We need to explore where the place for verification and authorization in the database is. It undoubtedly leads us to the Connection.<br>But what are the ways to intervene in the Connection?</p></blockquote><ol><li><p><strong>Intervening in Connection Pool via a Third Party</strong></p><ul><li>When discussing authentication and authorization, we often think about providing driver, username, password, and URL to establish a connection. The most common thing mentioned when establishing a connection is Connection Pool. <strong>In simple terms, it is an intermediate layer between the application and the data source when establishing a connection</strong>. This intermediate layer can perform many tasks, such as connection pooling, read/write separation, caching query results, and more. We want to perform authentication and authorization in this intermediate layer.</li><li>A simple way to intervene in Connection Pool is to modify some third-party packages used by applications, such as HikariDataSource used by Spring Boot.</li></ul></li><li><p><strong>Using Database Proxy</strong></p><ul><li>I first encountered this term when looking at the source code of Hikari and found proxy connection settings. Later, I searched online, and AWS RDS Proxy immediately stood out. AWS RDS Proxy stands for Relational Database Service Proxy.</li><li>Database Proxy can also perform authentication and authorization. In essence, it acts as an intermediate layer between multiple applications and the database.</li><li>Similar to Connection Pool, it serves as an intermediate layer in the application, but its scope is broader because it is not limited to a single application but serves as the entry point for all applications’ database connections.</li></ul></li></ol><h1 id="Using-Database-Proxy">Using Database Proxy</h1><h2 id="AWS-RDS-Proxy">AWS RDS Proxy</h2><p><img src="https://i.imgur.com/N44uCbX.png" alt=""></p><p>AWS RDS Proxy is an intermediate layer service that makes connections between applications and databases more stable. It also provides features such as connection pooling, read/write separation, caching query results, and more. AWS has many applications like AWS Lambda, Fargate, Amazon ECS, or EKS, where there is a significant and rapid need to open or close connections to the database server. Such operations can easily deplete the database’s memory and computational resources.</p><blockquote><p>Connection Pooling: Reduces the impact on database memory and computational resources when establishing new connections.</p></blockquote><p>This is where RDS Proxy comes into play. Amazon RDS Proxy instances maintain connection pools established between RDS database instances, reducing the impact on database memory and computational resources when establishing new connections. It allows applications to share these connections, improving the efficiency of the database and the scalability of applications.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyHikariDataSource</span> <span class="keyword">extends</span> <span class="title class_">HikariDataSource</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Connection <span class="title function_">getConnection</span><span class="params">()</span> <span class="keyword">throws</span> SQLException &#123;</span><br><span class="line">        <span class="comment">// You can do some settings here</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>.getConnection();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>Point to your own class in config file</p></blockquote><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">spring.datasource.type=com.test.dao.MyHikariDataSource</span>    <span class="comment"># point to your own class</span></span><br><span class="line"><span class="string">spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver</span></span><br><span class="line"><span class="string">spring.datasource.url=jdbc:mysql://127.0.0.1:3306/db</span></span><br><span class="line"><span class="string">spring.datasource.username=USERNAME</span></span><br><span class="line"><span class="string">spring.datasource.password=PASSWORD</span>    </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Research </category>
          
          <category> Database </category>
          
          <category> Thesis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database </tag>
            
            <tag> Connection Pool </tag>
            
            <tag> Master&#39;s Thesis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JDBC Basics and Connection Pooling Explained</title>
      <link href="/en/posts/about-jdbc-connection-pool/"/>
      <url>/en/posts/about-jdbc-connection-pool/</url>
      
        <content type="html"><![CDATA[<h1 id="References">References</h1><ul><li><a href="https://www.1ju.org/jdbc/jdbc-introduction">What Is JDBC?</a></li><li><a href="https://medium.com/learning-from-jhipster/14-%E6%B7%B1%E5%85%A5-jdbc-connection-pool-%E4%B8%A6%E5%B0%8E%E5%85%A5-h2-db-939adee9c50">(14) Dive into JDBC, Connection Pool, and Introduce H2 DB</a></li><li><a href="https://medium.com/@sawomirkowalski/design-patterns-object-pool-e8269fd45e10">Design Pattern - Object Pool</a></li><li><a href="https://iter01.com/16624.html">Understanding the Implementation and Principles of Database Connection Pool</a></li><li><a href="https://www.linqz.io/2019/03/why-to-use-hikari-connection-pool.html">Why Is Hikari So Fast</a></li><li><a href="https://blog.csdn.net/assember/article/details/121976290">Difference Between spring-boot-starter-jdbc and spring-boot-starter-data-jdbc</a></li><li><a href="https://docs.spring.io/spring-boot/docs/current/reference/html/appendix-application-properties.html#data-properties">Spring Boot - Data Properties</a></li></ul><h1 id="Introduction">Introduction</h1><p>JDBC, short for Java Database Connectivity, is primarily an API standard used for <strong>connecting Java programming language to databases</strong>. You can also think of it as a library. But what exactly does this API standard encompass?</p><ol><li>Connecting to a database.</li><li>Creating and executing SQL statements.</li></ol><h1 id="JDBC-Architecture">JDBC Architecture</h1><p><img src="https://i.imgur.com/D1mM5vk.png" alt=""><br>The JDBC API provides the following interfaces and classes:</p><ul><li><code>Driver Manager</code>: Manages a list of database drivers. It matches connection requests from Java applications with the appropriate database driver to <strong>establish a database connection</strong>.</li><li><code>Driver</code>: <strong>Handles communication with the database</strong>. It is rarely communicated with directly, and instead, interactions are managed through the Driver Manager.</li><li><code>Connection</code>: Provides <strong>methods for connecting to the database</strong>.</li><li><code>Statement</code>: Used for <strong>executing SQL statements</strong> and returning results.</li><li><code>ResultSet</code>: Used for <strong>holding the results obtained from a database query</strong>.</li><li><code>SQLException</code>: This class handles <strong>any errors that occur in the database application</strong>.</li></ul><blockquote><p>You can understand the purposes of JDBC API interfaces through the following example:</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Reference: https://medium.com/learning-from-jhipster/14-%E6%B7%B1%E5%85%A5-jdbc-connection-pool-%E4%B8%A6%E5%B0%8E%E5%85%A5-h2-db-939adee9c50</span></span><br><span class="line"><span class="keyword">import</span> java.sql.Connection;</span><br><span class="line"><span class="keyword">import</span> java.sql.DriverManager;</span><br><span class="line"><span class="keyword">import</span> java.sql.ResultSet;</span><br><span class="line"><span class="keyword">import</span> java.sql.SQLException;</span><br><span class="line"><span class="keyword">import</span> java.sql.Statement;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SQLDatabaseConnection</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Connect to your database.</span></span><br><span class="line">  <span class="comment">// Replace server name, username, and password with your credentials</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">    <span class="comment">// 1. Load the JDBC Driver for SQL Server</span></span><br><span class="line">    Class.forName(<span class="string">&quot;com.microsoft.sqlserver.jdbc.SQLServerDriver&quot;</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 2. Edit the connection URL</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">connectionUrl</span> <span class="operator">=</span></span><br><span class="line">        <span class="string">&quot;jdbc:sqlserver://yourserver.database.windows.net:1433;&quot;</span></span><br><span class="line">        + <span class="string">&quot;database=AdventureWorks;&quot;</span></span><br><span class="line">        + <span class="string">&quot;user=yourusername@yourserver;&quot;</span></span><br><span class="line">        + <span class="string">&quot;password=yourpassword;&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Used to hold the result set</span></span><br><span class="line">    <span class="type">ResultSet</span> <span class="variable">resultSet</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// https://docs.oracle.com/javase/tutorial/essential/exceptions/tryResourceClose.html</span></span><br><span class="line">    <span class="keyword">try</span> (</span><br><span class="line">      <span class="comment">// 3. Establish a connection</span></span><br><span class="line">      <span class="type">Connection</span> <span class="variable">connection</span> <span class="operator">=</span> DriverManager.getConnection(connectionUrl);</span><br><span class="line">      <span class="comment">// 4. Create a Statement object for executing SQL commands</span></span><br><span class="line">      <span class="type">Statement</span> <span class="variable">statement</span> <span class="operator">=</span> connection.createStatement();</span><br><span class="line">    ) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Create and execute a SELECT SQL statement.</span></span><br><span class="line">      <span class="type">String</span> <span class="variable">selectSql</span> <span class="operator">=</span> <span class="string">&quot;SELECT TOP 10 Title, FirstName, LastName from SalesLT.Customer&quot;</span>;</span><br><span class="line">      <span class="comment">// 5. Execute the SQL command and retrieve the result</span></span><br><span class="line">      resultSet = statement.executeQuery(selectSql);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Print results from the select statement</span></span><br><span class="line">      <span class="keyword">while</span> (resultSet.next()) &#123;</span><br><span class="line">        System.out.println(resultSet.getString(<span class="number">2</span>) + <span class="string">&quot; &quot;</span> + resultSet.getString(<span class="number">3</span>));</span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// Cleanup</span></span><br><span class="line">      <span class="comment">// 6. Release resources, close the Connection, and Statement</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line">      e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="JDBC-Connection">JDBC Connection</h1><p>Usually, to establish a database connection, the following steps are required:</p><ol><li><strong>Set up the Driver</strong>: Load the JDBC Driver for SQL Server.</li><li><strong>Create a Connection</strong>: (Using <code>DriverManager.getConnection()</code>) to establish a TCP socket connection.</li><li><strong>Submit SQL</strong>: Create a <code>Statement</code> and execute SQL commands.</li><li><strong>Close the Connection</strong>: Close the TCP socket.</li></ol><p>However, every time we need to communicate with the database, performing these steps repeatedly can create unnecessary overhead for the system.</p><div class="note info flat"><p>If we can extract those repetitive actions every time we connect, we can reduce the system’s burden and improve program execution performance. <strong>This is what we are going to discuss next - Connection Pooling</strong>.</p></div><h2 id="Connection-Pool">Connection Pool</h2><p>Connection Pooling is implemented using the “Object Pool Pattern.” Let’s start with a brief explanation from Wikipedia:</p><blockquote><p>The object pool pattern is a creational design pattern. <strong>An object pool contains a set of initialized and ready-to-use objects</strong> that can be created and destroyed as needed. Clients can request objects from the pool, use them for processing, and return them to the pool instead of creating and destroying them directly. It’s a special kind of factory object.</p><footer><strong>wiki</strong><cite><a href="https://en.wikipedia.org/wiki/Object_pool_pattern">en.wikipedia.org/wiki/Object_pool_pattern</a></cite></footer></blockquote><p>In simple terms, it means pre-creating and storing some commonly used objects in a pool. When needed, you can directly take objects from the pool, avoiding the need to recreate them every time. <strong>Using an object pool can significantly improve performance. The time to get an object from the pool is predictable, whereas creating a new instance takes an uncertain amount of time.</strong></p><p>The following diagram illustrates how clients use connections from the pool to connect to a data source. The main tasks are:</p><ol><li>Managing available connections.</li><li>Allocating connections.</li><li>Releasing connections.</li></ol><p><img src="https://i.imgur.com/5NFJcwZ.png" alt=""></p><p>Now, let’s take a look at the UML diagram:</p><ul><li><code>Object Pool Class</code>: It is a Singleton, meaning it has a private constructor and a static <code>getInstance()</code> method to obtain an instance of the Object Pool.</li><li><code>acquireReusable()</code>: Used to get objects from the Object Pool. If there are no available objects, it will create a new one.</li><li><code>releaseReusable()</code>: Used to release an object from the client’s hand and return it to the available objects.</li><li><code>setMaxPoolSize()</code>: Used to set the maximum capacity of the Object Pool.</li></ul><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  classDiagram    class client    class ResuablePool{        - reusable        +BigDecimal balance        +static getInstance() ReusablePool        +acquireReusable() Reusable        +releaseReusable(Reusable reusable)        +setMaxPoolSize(int maxPoolSize)    }    client --&gt; ResuablePool : ResusablePool.getInstance().acquareReusable()  </pre></div><h2 id="JDBC-Connection-Pool-Example">JDBC Connection Pool Example</h2><p>You can refer to <a href="https://github.com/MicrosoftDocs/azure-docs.zh-tw/blob/master/articles/mysql/sample-scripts-java-connection-pooling.md">Azure’s approach</a> for a simple JDBC Connection Pool implementation. Inside, you can see how a Connection Pool is implemented.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.sql.Connection;</span><br><span class="line"><span class="keyword">import</span> java.sql.DriverManager;</span><br><span class="line"><span class="keyword">import</span> java.sql.ResultSet;</span><br><span class="line"><span class="keyword">import</span> java.sql.SQLException;</span><br><span class="line"><span class="keyword">import</span> java.sql.Statement;</span><br><span class="line"><span class="keyword">import</span> java.util.HashSet;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"><span class="keyword">import</span> java.util.Stack;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySQLConnectionPool</span> &#123;</span><br><span class="line">    <span class="comment">// Connection information</span></span><br><span class="line">    <span class="keyword">private</span> String databaseUrl;</span><br><span class="line">    <span class="keyword">private</span> String userName;</span><br><span class="line">    <span class="keyword">private</span> String password;</span><br><span class="line">    <span class="comment">// Pool size</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="variable">maxPoolSize</span> <span class="operator">=</span> <span class="number">10</span>;</span><br><span class="line">    <span class="comment">// Current number of connections</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="variable">connNum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">SQL_VERIFYCONN</span> <span class="operator">=</span> <span class="string">&quot;select 1&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Currently available connections</span></span><br><span class="line">    Stack&lt;Connection&gt; freePool = <span class="keyword">new</span> <span class="title class_">Stack</span>&lt;&gt;();</span><br><span class="line">    <span class="comment">// Currently in-use connections</span></span><br><span class="line">    Set&lt;Connection&gt; occupiedPool = <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Constructor: Create a Connection Pool</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> databaseUrl</span></span><br><span class="line"><span class="comment">     *            The connection URL</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> userName</span></span><br><span class="line"><span class="comment">     *            User name</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> password</span></span><br><span class="line"><span class="comment">     *            Password</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> maxSize</span></span><br><span class="line"><span class="comment">     *            Max size of the connection pool</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">MySQLConnectionPool</span><span class="params">(String databaseUrl, String userName,</span></span><br><span class="line"><span class="params">            String password, <span class="type">int</span> maxSize)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.databaseUrl = databaseUrl;</span><br><span class="line">        <span class="built_in">this</span>.userName = userName;</span><br><span class="line">        <span class="built_in">this</span>.password = password;</span><br><span class="line">        <span class="built_in">this</span>.maxPoolSize = maxSize;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Get an available connection</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> An available connection</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> SQLException</span></span><br><span class="line"><span class="comment">     *             Fail to get an available connection</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">synchronized</span> Connection <span class="title function_">getConnection</span><span class="params">()</span> <span class="keyword">throws</span> SQLException &#123;</span><br><span class="line">        <span class="type">Connection</span> <span class="variable">conn</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Cannot create a new connection (reached the maximum limit)</span></span><br><span class="line">        <span class="keyword">if</span> (isFull()) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">SQLException</span>(<span class="string">&quot;The connection pool is full.&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Return a connection from the freePool and mark it as occupied</span></span><br><span class="line">        conn = getConnectionFromPool();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// If conn is null, it means there are no objects in freePool, so we need to create a new connection</span></span><br><span class="line">        <span class="keyword">if</span> (conn == <span class="literal">null</span>) &#123;</span><br><span class="line">            conn = createNewConnectionForPool();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Some databases automatically disconnect idle connections after some time, so we check if the connection is still active</span></span><br><span class="line">        <span class="comment">// For Azure Database for MySQL, if there is no action on one connection for some time, the connection is lost. By this, make sure the connection is</span></span><br><span class="line">        <span class="comment">// active. Otherwise, reconnect it.</span></span><br><span class="line">        conn = makeAvailable(conn);</span><br><span class="line">        <span class="keyword">return</span> conn;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Return a connection to the pool</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> conn</span></span><br><span class="line"><span class="comment">     *            The connection</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> SQLException</span></span><br><span class="line"><span class="comment">     *             When the connection is returned already or it isn&#x27;t gotten</span></span><br><span class="line"><span class="comment">     *             from the pool.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title function_">returnConnection</span><span class="params">(Connection conn)</span></span><br><span class="line">            <span class="keyword">throws</span> SQLException &#123;</span><br><span class="line">        <span class="comment">// If conn is null, it means the client hasn&#x27;t used the connection, so there&#x27;s no need to return it</span></span><br><span class="line">        <span class="keyword">if</span> (conn == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">NullPointerException</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Check if conn is in the occupiedPool and can be removed from it, if not, throw SQLException</span></span><br><span class="line">        <span class="keyword">if</span> (!occupiedPool.remove(conn)) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">SQLException</span>(</span><br><span class="line">                    <span class="string">&quot;The connection is returned already or it isn&#x27;t for this pool&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// If no exception is thrown, it&#x27;s removed from occupiedPool and can be returned to freePool</span></span><br><span class="line">        freePool.push(conn);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Verify if the connection pool is full</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> True if the connection pool is full</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="type">boolean</span> <span class="title function_">isFull</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> ((freePool.size() == <span class="number">0</span>) &amp;&amp; (connNum &gt;= maxPoolSize));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Create a connection for the pool</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> The new created connection</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> SQLException</span></span><br><span class="line"><span class="comment">     *             When fail to create a new connection.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Connection <span class="title function_">createNewConnectionForPool</span><span class="params">()</span> <span class="keyword">throws</span> SQLException &#123;</span><br><span class="line">        <span class="type">Connection</span> <span class="variable">conn</span> <span class="operator">=</span> createNewConnection();</span><br><span class="line">        connNum++;</span><br><span class="line">        occupiedPool.add(conn);</span><br><span class="line">        <span class="keyword">return</span> conn;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Create a new connection</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> The new created connection</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> SQLException</span></span><br><span class="line"><span class="comment">     *             When fail to create a new connection.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Connection <span class="title function_">createNewConnection</span><span class="params">()</span> <span class="keyword">throws</span> SQLException &#123;</span><br><span class="line">        <span class="type">Connection</span> <span class="variable">conn</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        conn = DriverManager.getConnection(databaseUrl, userName, password);</span><br><span class="line">        <span class="keyword">return</span> conn;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Get a connection from the pool. If there is no free connection, return null</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> The connection.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Connection <span class="title function_">getConnectionFromPool</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">Connection</span> <span class="variable">conn</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">if</span> (freePool.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            conn = freePool.pop();</span><br><span class="line">            occupiedPool.add(conn);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> conn;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Make sure the connection is available now. Otherwise, reconnect it.</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> conn</span></span><br><span class="line"><span class="comment">     *            The connection for verification.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> The available connection.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> SQLException</span></span><br><span class="line"><span class="comment">     *             Fail to get an available connection</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Connection <span class="title function_">makeAvailable</span><span class="params">(Connection conn)</span> <span class="keyword">throws</span> SQLException &#123;</span><br><span class="line">        <span class="comment">// Verify if the connection is still active by running a query</span></span><br><span class="line">        <span class="keyword">if</span> (isConnectionAvailable(conn)) &#123;</span><br><span class="line">            <span class="keyword">return</span> conn;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// If the connection is found to be inactive, remove it from occupiedPool and close it</span></span><br><span class="line">        occupiedPool.remove(conn);</span><br><span class="line">        connNum--;</span><br><span class="line">        conn.close();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Then create a new connection and add it to occupiedPool</span></span><br><span class="line">        conn = createNewConnection();</span><br><span class="line">        occupiedPool.add(conn);</span><br><span class="line">        connNum++;</span><br><span class="line">        <span class="keyword">return</span> conn;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Check if the connection is available by running a query</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> conn</span></span><br><span class="line"><span class="comment">     *            The connection for verification</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> True if the connection is available</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">boolean</span> <span class="title function_">isConnectionAvailable</span><span class="params">(Connection conn)</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> (<span class="type">Statement</span> <span class="variable">st</span> <span class="operator">=</span> conn.createStatement()) &#123;</span><br><span class="line">            st.executeQuery(SQL_VERIFYCONN);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Just an Example</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> SQLException &#123;</span><br><span class="line">        <span class="type">Connection</span> <span class="variable">conn</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="comment">// Create a connection pool</span></span><br><span class="line">        <span class="type">MySQLConnectionPool</span> <span class="variable">pool</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MySQLConnectionPool</span>(</span><br><span class="line">                <span class="string">&quot;jdbc:mysql://mysqlaasdevintic-sha.cloudapp.net:3306/&lt;Your DB name&gt;&quot;</span>,</span><br><span class="line">                <span class="string">&quot;&lt;Your user&gt;&quot;</span>, <span class="string">&quot;&lt;Your Password&gt;&quot;</span>, <span class="number">2</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// Get a connection</span></span><br><span class="line">            conn = pool.getConnection();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// Prepare a query to execute</span></span><br><span class="line">            <span class="keyword">try</span> (<span class="type">Statement</span> <span class="variable">statement</span> <span class="operator">=</span> conn.createStatement())</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="type">ResultSet</span> <span class="variable">res</span> <span class="operator">=</span> statement.executeQuery(<span class="string">&quot;show tables&quot;</span>);</span><br><span class="line">                System.out.println(<span class="string">&quot;There are below tables:&quot;</span>);</span><br><span class="line">                <span class="keyword">while</span> (res.next()) &#123;</span><br><span class="line">                    <span class="type">String</span> <span class="variable">tblName</span> <span class="operator">=</span> res.getString(<span class="number">1</span>);</span><br><span class="line">                    System.out.println(tblName);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (conn != <span class="literal">null</span>) &#123;</span><br><span class="line">                <span class="comment">// Release the connection</span></span><br><span class="line">                pool.returnConnection(conn);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="About-Third-Party-Connection-Pool-Libraries">About Third-Party Connection Pool Libraries</h1><p>Now that we understand how Connection Pools work, it’s important to note that there are many mature third-party libraries available for us to use. These third-party Connection Pool libraries have been optimized for performance and reducing redundant work.</p><blockquote><p>The development of different third-party Connection Pools is primarily driven by performance considerations. Since JDBC has defined interfaces for JDBC Drivers, these third-party Connection Pool libraries adhere to the JDBC Driver Interface API. They all have the same API, but the difference lies in the internal implementation, which affects performance.</p><footer><strong>Albert</strong><cite><a href="https://medium.com/learning-from-jhipster/14-%E6%B7%B1%E5%85%A5-jdbc-connection-pool-%E4%B8%A6%E5%B0%8E%E5%85%A5-h2-db-939adee9c50">medium.com/learning-from-jhipster/14-%E6%B7%B1%E5%85%A5-jdbc-connection-pool-%E4%B8%A6%E5%B0%8E%E5%85%A5-h2-db-939adee9c50</a></cite></footer></blockquote><p>Currently, the most powerful and high-performance third-party Connection Pool library is HikariCP, with performance that surpasses other Connection Pool libraries by more than two times.<br>In the graph below:</p><ul><li><strong>Connection Cycle Comparison</strong>: It shows the connection speed from <code>DataSource.getConnection()</code> to <code>Connection.close()</code>. HikariCP can complete around 40,000 to 50,000 connections in less than 1 millisecond.</li><li><strong>Statement Cycle Comparison</strong>: It shows the SQL execution speed from <code>Connection.prepareStatement()</code> to <code>Statement.execute()</code> to <code>Statement.close()</code>. In terms of SQL execution speed, it can complete approximately 15,000 cycles within 1 millisecond. The only other library that can keep up is Tomcat’s JDBC Connection Pool; other libraries have much lower performance.</li></ul><blockquote><p>To understand why it is so fast, you can read this article: <a href="https://www.linqz.io/2019/03/why-to-use-hikari-connection-pool.html">Reasons for HikariCP’s Speed</a></p></blockquote><p><img src="https://i.imgur.com/0d8CJ8e.png" alt=""></p><h1 id="About-Third-Party-Libraries-Used-by-Spring-Boot">About Third-Party Libraries Used by Spring Boot</h1><p>Previously, we explained how to connect to databases using JDBC and the importance of Connection Pools. In Spring Boot, a series of commonly used tools are integrated, simplifying configuration tasks related to JDBC, Connection Pools, JPA, and more.</p><p>Now, you only need to import dependencies and configure properties to quickly and conveniently establish a connection with the database. If you want to communicate with a database using a Java application, you typically import the <code>spring-boot-starter-jdbc</code> library:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>But now it mainly uses <code>spring-boot-starter-data-jdbc</code>, with an extra word for data!</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-data-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="Spring-Boot-Starters-for-Data-and-JDBC">Spring Boot Starters for Data and JDBC</h2><p>When using <code>spring-boot-starter-jdbc</code> or <code>spring-boot-starter-data-jpa</code> starters, we automatically get a dependency on HikariCP. (See the snapshot below)<br><img src="https://i.imgur.com/BO5bFfS.png" alt=""></p><p>But what’s the difference between these data-related starters? If you are developing with JPA, the most commonly used one is <code>spring-boot-starter-data-jdbc</code>.</p><ul><li><code>spring-boot-starter-jdbc</code>: This starter is the most basic package. If you only need JDBC, you can import this starter.</li><li><code>spring-boot-starter-data-jdbc</code>: This starter builds upon <code>spring-boot-starter-jdbc</code> and provides a quick development interface for <code>curdRepository</code>. If you need to use JPA, then you should import this starter.</li></ul><blockquote><p>spring-jdbc (from: <a href="https://blog.csdn.net/assember/article/details/121976290">https://blog.csdn.net/assember/article/details/121976290</a>)</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> javax.sql.DataSource;</span><br><span class="line"><span class="keyword">import</span> org.springframework.jdbc.core.JdbcTemplate;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RunAQuery</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> JdbcTemplate jdbcTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// only provide basic JDBC connection</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setDataSource</span><span class="params">(DataSource dataSource)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.jdbcTemplate = <span class="keyword">new</span> <span class="title class_">JdbcTemplate</span>(dataSource);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getCount</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.jdbcTemplate.queryForObject(<span class="string">&quot;select count(*) from mytable&quot;</span>, Integer.class);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.jdbcTemplate.queryForObject(<span class="string">&quot;select name from mytable&quot;</span>, String.class);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>spring-data-jdbc Except for the basic database connection, it also provides CrudReporitoy</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.data.repository.CrudRepository;</span><br><span class="line"><span class="meta">@Repository</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">UserRepository</span> <span class="keyword">extends</span> <span class="title class_">CrudRepository</span>&lt;User, Long&gt; &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://i.imgur.com/08ZhuEH.png" alt=""></p><h2 id="Properties-Configuration">Properties Configuration</h2><p>If you take a closer look at this starter’s content, you will find that it mainly includes two dependencies:</p><ol><li>spring-JDBC: This is Spring’s library that wraps JDBC. If you use this starter, you must configure the database connection information in the properties (application.yml).</li><li>HikariCP: Spring Boot uses HikariCP as the default Connection Pool and includes it in <code>spring-boot-starter-jdbc</code>. (It’s highly efficient!)</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.zaxxer<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>HikariCP<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>Can refer to Spring Boot - Data Properties for configuration methods:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">datasource:</span></span><br><span class="line">    <span class="comment"># To use HikariCP, you can configure it directly using spring.datasource.*</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">Configure</span> <span class="string">the</span> <span class="string">type</span> <span class="string">of</span> <span class="string">DataSource</span> <span class="string">for</span> <span class="string">the</span> <span class="string">Connection</span> <span class="string">Pool</span> <span class="string">(or</span> <span class="string">automatically</span> <span class="string">detect</span> <span class="string">from</span> <span class="string">classpath)</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">Configure</span> <span class="string">the</span> <span class="string">JDBC</span> <span class="string">URL</span> <span class="string">for</span> <span class="string">connecting</span> <span class="string">to</span> <span class="string">the</span> <span class="string">database</span></span><br><span class="line">    <span class="attr">username:</span> <span class="string">Configure</span> <span class="string">the</span> <span class="string">username</span> <span class="string">for</span> <span class="string">connecting</span> <span class="string">to</span> <span class="string">the</span> <span class="string">database</span></span><br><span class="line">    <span class="attr">password:</span> <span class="string">Configure</span> <span class="string">the</span> <span class="string">password</span> <span class="string">for</span> <span class="string">connecting</span> <span class="string">to</span> <span class="string">the</span> <span class="string">database</span></span><br><span class="line">    <span class="attr">driver-class-name:</span> <span class="string">Configure</span> <span class="string">the</span> <span class="string">JDBC</span> <span class="string">driver</span> <span class="string">class</span> <span class="string">(or</span> <span class="string">automatically</span> <span class="string">detect</span> <span class="string">based</span> <span class="string">on</span> <span class="string">the</span> <span class="string">URL)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="spring-datasource-type">spring.datasource.type</h2><p>Since we’ve imported <code>spring-boot-starter-data-jdbc</code>, we can directly use <code>spring.datasource.type</code> to configure the Connection Pool we want to use. By default, Spring Boot will automatically detect it from the classpath, and if it’s not found, it will default to HikariCP.</p><p>If you’re curious about how it auto-detects or which class names it can auto-detect, you can refer to the <a href="https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot/src/main/java/org/springframework/boot/jdbc/DataSourceBuilder.java">DataSourceBuilder.java — Source Code</a>, or check out the code snippet below:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> &lt;T <span class="keyword">extends</span> <span class="title class_">DataSource</span>&gt; MappedDataSourceProperties&lt;T&gt; <span class="title function_">lookupPooled</span><span class="params">(ClassLoader classLoader,</span></span><br><span class="line"><span class="params">Class&lt;T&gt; type)</span> &#123;</span><br><span class="line">MappedDataSourceProperties&lt;T&gt; result = <span class="literal">null</span>;</span><br><span class="line">result = lookup(classLoader, type, result, <span class="string">&quot;com.zaxxer.hikari.HikariDataSource&quot;</span>,</span><br><span class="line">HikariDataSourceProperties::<span class="keyword">new</span>);</span><br><span class="line">result = lookup(classLoader, type, result, <span class="string">&quot;org.apache.tomcat.jdbc.pool.DataSource&quot;</span>,</span><br><span class="line">TomcatPoolDataSourceProperties::<span class="keyword">new</span>);</span><br><span class="line">result = lookup(classLoader, type, result, <span class="string">&quot;org.apache.commons.dbcp2.BasicDataSource&quot;</span>,</span><br><span class="line">MappedDbcp2DataSource::<span class="keyword">new</span>);</span><br><span class="line">result = lookup(classLoader, type, result, <span class="string">&quot;oracle.ucp.jdbc.PoolDataSourceImpl&quot;</span>,</span><br><span class="line">OraclePoolDataSourceProperties::<span class="keyword">new</span>, <span class="string">&quot;oracle.jdbc.OracleConnection&quot;</span>);</span><br><span class="line">result = lookup(classLoader, type, result, <span class="string">&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;</span>,</span><br><span class="line">ComboPooledDataSourceProperties::<span class="keyword">new</span>);</span><br><span class="line"><span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>In this code snippet, we can see that Spring Boot automatically detects several Connection Pool implementations, with HikariCP being the default choice.</p><ul><li><code>org.springframework.jdbc.datasource.SimpleDriverDataSource</code></li><li><code>com.zaxxer.hikari.HikariDataSource</code></li><li><code>org.apache.tomcat.jdbc.pool.DataSource</code></li><li><code>oracle.ucp.jdbc.PoolDataSourceImpl</code></li><li><code>oracle.jdbc.OracleConnection</code></li><li>and more.</li></ul><blockquote><p>If you use the spring-boot-starter-jdbc or spring-boot-starter-data-jpa “starters”, you automatically get a dependency to HikariCP.</p><footer><strong>spring-doc</strong><cite><a href="https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#data.sql.datasource.connection-pool">docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#data.sql.datasource.connection-pool</a></cite></footer></blockquote><div class="note danger flat"><p>Regarding <code>org.springframework.jdbc.datasource.SimpleDriverDataSource</code>, check its <a href="https://mvnrepository.com/artifact/org.springframework/spring-jdbc">API documentation</a>, and you’ll find the note <strong>This class is not an actual connection pool; it does not actually pool Connections</strong>. This means that this class is not a genuine Connection Pool, and it doesn’t perform Connection Pooling operations.</p></div>]]></content>
      
      
      <categories>
          
          <category> Research </category>
          
          <category> Database </category>
          
          <category> Thesis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database </tag>
            
            <tag> Connection Pool </tag>
            
            <tag> Master&#39;s Thesis </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
