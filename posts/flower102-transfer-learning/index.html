<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Flower102 Dataset - Using Transfer Learning to train + Using Batch Normalization in CNN | Shannon's Blog üêü Tech | Life | Travel</title><meta name="author" content="Shannon Hung"><meta name="copyright" content="Shannon Hung"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="Preface I recently took an ai course, this is the fourth assignment and the main topics taught are the following.  selecting a dataset and training a model on it. migration learning - fine tuning. bat">
<meta property="og:type" content="article">
<meta property="og:title" content="Flower102 Dataset - Using Transfer Learning to train + Using Batch Normalization in CNN">
<meta property="og:url" content="https://shannonhung.github.io/en/posts/flower102-transfer-learning/">
<meta property="og:site_name" content="Shannon&#39;s Blog üêü Tech | Life | Travel">
<meta property="og:description" content="Preface I recently took an ai course, this is the fourth assignment and the main topics taught are the following.  selecting a dataset and training a model on it. migration learning - fine tuning. bat">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://shannonhung.github.io/en/img/cover/flower-ml.jpeg">
<meta property="article:published_time" content="2023-10-31T06:27:13.000Z">
<meta property="article:modified_time" content="2023-12-09T23:40:52.254Z">
<meta property="article:author" content="Shannon Hung">
<meta property="article:tag" content="Mechine Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://shannonhung.github.io/en/img/cover/flower-ml.jpeg"><link rel="shortcut icon" href="/en/img/shannon-icon.png"><link rel="canonical" href="https://shannonhung.github.io/en/posts/flower102-transfer-learning/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="IAmwAuWZP3fXPtoYru7VJBancFMT2BkhN15HC2iea1o"/><link rel="stylesheet" href="/en/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-XBNKVVH2P4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-XBNKVVH2P4');
</script><script>const GLOBAL_CONFIG = {
  root: '/en/',
  algolia: undefined,
  localSearch: {"path":"/en/search.xml","preload":false,"top_n_per_article":-1,"unescape":false,"languages":{"hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found"}},
  translate: {"defaultEncoding":3,"translateDelay":0,"msgToTraditionalChinese":"ÁπÅ","msgToSimplifiedChinese":"Á∞°"},
  noticeOutdate: {"limitDay":500,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"You have switched to Traditional Chinese","cht_to_chs":"You have switched to Simplified Chinese","day_to_night":"You have switched to Dark Mode","night_to_day":"You have switched to Light Mode","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: true,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Flower102 Dataset - Using Transfer Learning to train + Using Batch Normalization in CNN',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-12-10 07:40:52'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/en/css/style.css"><link rel="stylesheet" href="/en/css/background.css"><link rel="shortcut icon" href="#"/></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/en/img/loading-icon.gif" data-original="/en/img/dudu-me.png" onerror="onerror=null;src='/en/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/en/archives/"><div class="headline">Articles</div><div class="length-num">12</div></a><a href="/en/tags/"><div class="headline">Tags</div><div class="length-num">11</div></a><a href="/en/categories/"><div class="headline">Categories</div><div class="length-num">12</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/en/"><i class="fa-fw fas fa-home"></i><span> Home Page</span></a></div><div class="menus_item"><a class="site-page" href="/en/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categroies</span></a></div><div class="menus_item"><a class="site-page" href="/en/about/"><i class="fa-fw fas fa-heart"></i><span> About Me</span></a></div><div class="menus_item"><a class="site-page" href="/en/link/"><i class="fa-fw fas fa-link"></i><span> Links</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fas fa-list"></i><span> Find Posts</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/en/tags/"><i class="fa-fw fas fa-tags"></i><span> By Tags</span></a></li><li><a class="site-page child" href="/en/archives/"><i class="fa-fw fas fa-archive"></i><span> By Posts</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fas fa-language"></i><span> Language</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/en/"><i class="fa-fw fas fa-e"></i><span> English</span></a></li><li><a class="site-page child" href="https://shannonhung.github.io/"><i class="fa-fw fas fa-c"></i><span> ‰∏≠Êñá</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/en/img/cover/flower-ml.jpeg')"><nav id="nav"><span id="blog-info"><a href="/en/" title="Shannon's Blog üêü Tech | Life | Travel"><span class="site-name">Shannon's Blog üêü Tech | Life | Travel</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/en/"><i class="fa-fw fas fa-home"></i><span> Home Page</span></a></div><div class="menus_item"><a class="site-page" href="/en/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categroies</span></a></div><div class="menus_item"><a class="site-page" href="/en/about/"><i class="fa-fw fas fa-heart"></i><span> About Me</span></a></div><div class="menus_item"><a class="site-page" href="/en/link/"><i class="fa-fw fas fa-link"></i><span> Links</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fas fa-list"></i><span> Find Posts</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/en/tags/"><i class="fa-fw fas fa-tags"></i><span> By Tags</span></a></li><li><a class="site-page child" href="/en/archives/"><i class="fa-fw fas fa-archive"></i><span> By Posts</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fas fa-language"></i><span> Language</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/en/"><i class="fa-fw fas fa-e"></i><span> English</span></a></li><li><a class="site-page child" href="https://shannonhung.github.io/"><i class="fa-fw fas fa-c"></i><span> ‰∏≠Êñá</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Flower102 Dataset - Using Transfer Learning to train + Using Batch Normalization in CNN</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-10-31T06:27:13.000Z" title="Created 2023-10-31 14:27:13">2023-10-31</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-12-09T23:40:52.254Z" title="Updated 2023-12-10 07:40:52">2023-12-10</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/en/categories/Code/">Code</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/en/categories/Code/Mechine-Learning/">Mechine Learning</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word Count:</span><span class="word-count">5.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading Time:</span><span>34mins</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Flower102 Dataset - Using Transfer Learning to train + Using Batch Normalization in CNN"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">Comments:</span><a href="/en/posts/flower102-transfer-learning/#post-comment"><span class="gitalk-comment-count"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Preface">Preface</h1>
<p>I recently took an ai course, this is the fourth assignment and the main topics taught are the following.</p>
<ol>
<li>selecting a dataset and training a model on it.</li>
<li>migration learning - fine tuning.</li>
<li>batch normalization in CNN.</li>
</ol>
<p>The main references are the following websites: 1.</p>
<ol>
<li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://pytorch.org/vision/stable/generated/torchvision.datasets.Flowers102.html#torchvision.datasets.Flowers102">Flower102 dataset</a></li>
<li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html">Migration Learning</a></li>
<li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://pytorch.org/vision/stable/datasets.html">Pytorch dataset</a></li>
<li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://pytorch.org/vision/stable/models.html">Migration Learning Model</a></li>
<li><a href="/posts/ML.html#Transfer-Learning">Shannon‚Äôs Transfer Learning Blog</a></li>
<li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet18.html#torchvision.models.resnet18">Resnet18</a></li>
</ol>
<h1 id="Assignment-Requirements">Assignment Requirements</h1>
<p>Tasks</p>
<ol>
<li><strong>Choose a dataset</strong>*: Look at torchvision <a target="_blank" rel="noopener external nofollow noreferrer" href="https://pytorch.org/vision/stable/datasets.html">Pytorch‚Äôs dataset</a> and decide which dataset you want to use (excluding<br>
CIFAR, ImageNet, FashionMNIST).</li>
<li><strong>Print images and profile sizes</strong>: show some sample images of the dataset in your notebook and print the size of the dataset.</li>
<li><strong>Construct a CNN using batch normalization</strong>: design a CNN to make predictions on the dataset. Use a similar architecture as last time, but this time<br>
also includes a batch normalization layer.</li>
<li><strong>Train a model using a dataset and print out the accuracy of the test</strong>: train a model on a dataset and measure the accuracy on retained test data.</li>
<li><strong>Use ResNet18 for Migration Learning</strong>: now use migration learning to use a pre-trained ResNet18 on the dataset as follows:</li>
<li><strong>Without changing the trained weights of other people‚Äôs models</strong>: ResNet18 is used as a fixed feature extractor.</li>
<li><strong>Fine-tuning using RestNet</strong> : ResNet18 is fine-tuned on the training data.</li>
<li><strong>Fine-tuning using EfficientNet_B5</strong>: Repeat step 4 but now use EfficientNet_B5 instead of RestNet18.<br>
<strong>Compare these different methods and print out the accuracy</strong>: Compare the accuracy of the different methods on the test data and print out the training time for each method.<br>
Training time for each method.</li>
</ol>
<h1 id="Task-0-Importing-Packages">Task 0 - Importing Packages</h1>
<p>Let‚Äôs start by importing the required package: # Task 0 - import package</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CNN </span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> lr_scheduler</span><br><span class="line"><span class="keyword">import</span> torch.backends.cudnn <span class="keyword">as</span> cudnn</span><br><span class="line"></span><br><span class="line"><span class="comment"># others</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> tempfile <span class="keyword">import</span> TemporaryDirectory</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># dataset </span></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, models, transforms</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> Flowers102</span><br><span class="line"></span><br><span class="line"><span class="comment"># label </span></span><br><span class="line"><span class="keyword">from</span> scipy.io <span class="keyword">import</span> loadmat</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">cudnn.benchmark = <span class="literal">True</span></span><br><span class="line">plt.ion()   <span class="comment"># interactive mode</span></span><br></pre></td></tr></table></figure>
<h1 id="Task-1-Selecting-a-DataSet">Task 1 - Selecting a DataSet</h1>
<ul>
<li>Ref: <a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.geeksforgeeks.org/how-to-normalize-images-in-pytorch/">Why [0.485, 0.456, 0.406] for Normalization</a></li>
</ul>
<div class="note info flat"><p><strong>Select a DataSet</strong>: Check out the torchvision <a target="_blank" rel="noopener external nofollow noreferrer" href="https://pytorch.org/vision/stable/datasets.html">DataSet of Pytorch</a> and decide one dataset that you want to use (no<br>
CIFAR, no ImageNet, no FashionMNIST).</p>
</div>
<p>In order to experience Transfer Learning and train it quickly, we use flower102 here. We use flower102 as our dataset. Since flower102 doesn‚Äôt provide Chinese labels, most of my searching on the web is done by reading the <code>.json</code> or <code>.txt</code> files that are already written, which describes each label index in Chinese.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Specify the data you want to download, the path and btach size, and the amount of training to do at once.</span></span><br><span class="line">batch_size = <span class="number">4</span></span><br><span class="line">data_dir = <span class="string">&#x27;... /... /Data/flowers-102&#x27;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Build the classes_name of the dataset</span></span><br><span class="line">json_data = <span class="string">&#x27;&#123;&quot;21&quot;: &quot;fire lily&quot;, &quot;3&quot;: &quot;canterbury bells&quot;, &quot;45&quot;: &quot;bolero deep blue&quot;, &quot;1&quot;: &quot;pink primrose&quot;, &quot;34&quot;: &quot;mexican aster&quot;, &quot;27&quot;: &quot;prince of wales feathers&quot;, &quot;7&quot;: &quot;moon orchid&quot;, &quot;16&quot;: &quot;globe-flower&quot;, &quot;25&quot;: &quot;grape hyacinth&quot;, &quot;26&quot;: &quot;corn poppy&quot;, &quot;79&quot;: &quot;toad lily&quot;, &quot;39&quot;: &quot;siam tulip&quot;, &quot;24&quot;: &quot;red ginger&quot;, &quot;67&quot;: &quot;spring crocus&quot;, &quot;35&quot;: &quot;alpine sea holly&quot;, &quot;32&quot;: &quot;garden phlox&quot;, &quot;10&quot;: &quot;globe thistle&quot;, &quot;6&quot;: &quot;tiger lily&quot;, &quot;93&quot;: &quot;ball moss&quot;, &quot;33&quot;: &quot;love in the mist&quot;, &quot;9&quot;: &quot;monkshood&quot;, &quot;102&quot;: &quot;blackberry lily&quot;, &quot;14&quot;: &quot;spear thistle&quot;, &quot;19&quot;: &quot;balloon flower&quot;, &quot;100&quot;: &quot;blanket flower&quot;, &quot;13&quot;: &quot;king protea&quot;, &quot;49&quot;: &quot;oxeye daisy&quot;, &quot;15&quot;: &quot;yellow iris&quot;, &quot;61&quot;: &quot;cautleya spicata&quot;, &quot;31&quot;: &quot;carnation&quot;, &quot;64&quot;: &quot;silverbush&quot;, &quot;68&quot;: &quot;bearded iris&quot;, &quot;63&quot;: &quot;black-eyed susan&quot;, &quot;69&quot;: &quot;windflower&quot;, &quot;62&quot;: &quot;japanese anemone&quot;, &quot;20&quot;: &quot;giant white arum lily&quot;, &quot;38&quot;: &quot;great masterwort&quot;, &quot;4&quot;: &quot;sweet pea&quot;, &quot;86&quot;: &quot;tree mallow&quot;, &quot;101&quot;: &quot;trumpet creeper&quot;, &quot;42&quot;: &quot;daffodil&quot;, &quot;22&quot;: &quot;pincushion flower&quot;, &quot;2&quot;: &quot;hard-leaved pocket orchid&quot;, &quot;54&quot;: &quot;sunflower&quot;, &quot;66&quot;: &quot;osteospermum&quot;, &quot;70&quot;: &quot;tree poppy&quot;, &quot;85&quot;: &quot;desert-rose&quot;, &quot;99&quot;: &quot;bromelia&quot;, &quot;87&quot;: &quot;magnolia&quot;, &quot;5&quot;: &quot;english marigold&quot;, &quot;92&quot;: &quot;bee balm&quot;, &quot;28&quot;: &quot;stemless gentian&quot;, &quot;97&quot;: &quot;mallow&quot;, &quot;57&quot;: &quot;gaura&quot;, &quot;40&quot;: &quot;lenten rose&quot;, &quot;47&quot;: &quot;marigold&quot;, &quot;59&quot;: &quot;orange dahlia&quot;, &quot;48&quot;: &quot;buttercup&quot;, &quot;55&quot;: &quot;pelargonium&quot;, &quot;36&quot;: &quot;ruby-lipped cattleya&quot;, &quot;91&quot;: &quot;hippeastrum&quot;, &quot;29&quot;: &quot;artichoke&quot;, &quot;71&quot;: &quot;gazania&quot;, &quot;90&quot;: &quot;canna lily&quot;, &quot;18&quot;: &quot;peruvian lily&quot;, &quot;98&quot;: &quot;mexican petunia&quot;, &quot;8&quot;: &quot;bird of paradise&quot;, &quot;30&quot;: &quot;sweet william&quot;, &quot;17&quot;: &quot;purple coneflower&quot;, &quot;52&quot;: &quot;wild pansy&quot;, &quot;84&quot;: &quot;columbine&quot;, &quot;12&quot;: &quot;colt\&#x27;s foot&quot;, &quot;11&quot;: &quot;snapdragon&quot;, &quot;96&quot;: &quot;camellia&quot;, &quot;23&quot;: &quot;fritillary&quot;, &quot;50&quot;: &quot;common dandelion&quot;, &quot;44&quot;: &quot;poinsettia&quot;, &quot;53&quot;: &quot;primula&quot;, &quot;72&quot;: &quot;azalea&quot;, &quot;65&quot;: &quot;californian poppy&quot;, &quot;80&quot;: &quot;anthurium&quot;, &quot;76&quot;: &quot;morning glory&quot;, &quot;37&quot;: &quot;cape flower&quot;, &quot;56&quot;: &quot;bishop of llandaff&quot;, &quot;60&quot;: &quot;pink-yellow dahlia&quot;, &quot;82&quot;: &quot;clematis&quot;, &quot;58&quot;: &quot;geranium&quot;, &quot;75&quot;: &quot;thorn apple&quot;, &quot;41&quot;: &quot;barbeton daisy&quot;, &quot;95&quot;: &quot;bougainvillea&quot;, &quot;43&quot;: &quot;sword lily&quot;, &quot;83&quot;: &quot;hibiscus&quot;, &quot;78&quot;: &quot;lotus lotus&quot;, &quot;88&quot;: &quot;cyclamen&quot;, &quot;94&quot;: &quot;foxglove&quot;, &quot;81&quot;: &quot;frangipani&quot;, &quot;74&quot;: &quot;rose&quot;, &quot;89&quot;: &quot;watercress&quot;, &quot;73&quot;: &quot;water lily&quot;, &quot;46&quot;: &quot;wallflower&quot;, &quot;77&quot;: &quot;passion flower&quot;, &quot;51&quot;: &quot;petunia&quot;&#125;&#x27;</span></span><br><span class="line"><span class="comment"># load data </span></span><br><span class="line">cat_to_name = json.loads(json_data)</span><br><span class="line"><span class="comment"># Turn the key into an int, because the label of the dataset starts from 0. But this json starts from 1, so we have to -1 </span></span><br><span class="line">cat_to_name = &#123;<span class="built_in">int</span>(k)-<span class="number">1</span>:v <span class="keyword">for</span> k,v <span class="keyword">in</span> cat_to_name.items()&#125;</span><br><span class="line"><span class="comment"># sort and print </span></span><br><span class="line">class_names = <span class="built_in">dict</span>(<span class="built_in">sorted</span>(cat_to_name.items()))</span><br><span class="line"><span class="built_in">print</span>(class_names)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Result</p>
</blockquote>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="number">0</span>: <span class="string">&#x27;pink primrose&#x27;</span>, <span class="number">1</span>: <span class="string">&#x27;hard-leaved pocket orchid&#x27;</span>, <span class="number">2</span>: <span class="string">&#x27;canterbury bells&#x27;</span>, <span class="number">3</span>: <span class="string">&#x27;sweet pea&#x27;</span>, <span class="number">4</span>: <span class="string">&#x27;english marigold&#x27;</span>, <span class="number">5</span>: <span class="string">&#x27;tiger lily&#x27;</span>, <span class="number">6</span>: <span class="string">&#x27;moon orchid&#x27;</span>, <span class="number">7</span>: <span class="string">&#x27;bird of paradise&#x27;</span>, <span class="number">8</span>: <span class="string">&#x27;monkshood&#x27;</span>, <span class="number">9</span>: <span class="string">&#x27;globe thistle&#x27;</span>, <span class="number">10</span>: <span class="string">&#x27;snapdragon&#x27;</span>, <span class="number">11</span>: <span class="string">&quot;colt&#x27;s foot&quot;</span>, <span class="number">12</span>: <span class="string">&#x27;king protea&#x27;</span>, <span class="number">13</span>: <span class="string">&#x27;spear thistle&#x27;</span>, <span class="number">14</span>: <span class="string">&#x27;yellow iris&#x27;</span>, <span class="number">15</span>: <span class="string">&#x27;globe-flower&#x27;</span>, <span class="number">16</span>: <span class="string">&#x27;purple coneflower&#x27;</span>, <span class="number">17</span>: <span class="string">&#x27;peruvian lily&#x27;</span>, <span class="number">18</span>: <span class="string">&#x27;balloon flower&#x27;</span>, <span class="number">19</span>: <span class="string">&#x27;giant white arum lily&#x27;</span>, <span class="number">20</span>: <span class="string">&#x27;fire lily&#x27;</span>, <span class="number">21</span>: <span class="string">&#x27;pincushion flower&#x27;</span>, <span class="number">22</span>: <span class="string">&#x27;fritillary&#x27;</span>, <span class="number">23</span>: <span class="string">&#x27;red ginger&#x27;</span>, <span class="number">24</span>: <span class="string">&#x27;grape hyacinth&#x27;</span>, <span class="number">25</span>: <span class="string">&#x27;corn poppy&#x27;</span>, <span class="number">26</span>: <span class="string">&#x27;prince of wales feathers&#x27;</span>, <span class="number">27</span>: <span class="string">&#x27;stemless gentian&#x27;</span>, <span class="number">28</span>: <span class="string">&#x27;artichoke&#x27;</span>, <span class="number">29</span>: <span class="string">&#x27;sweet william&#x27;</span>, <span class="number">30</span>: <span class="string">&#x27;carnation&#x27;</span>, <span class="number">31</span>: <span class="string">&#x27;garden phlox&#x27;</span>, <span class="number">32</span>: <span class="string">&#x27;love in the mist&#x27;</span>, <span class="number">33</span>: <span class="string">&#x27;mexican aster&#x27;</span>, <span class="number">34</span>: <span class="string">&#x27;alpine sea holly&#x27;</span>, <span class="number">35</span>: <span class="string">&#x27;ruby-lipped cattleya&#x27;</span>, <span class="number">36</span>: <span class="string">&#x27;cape flower&#x27;</span>, <span class="number">37</span>: <span class="string">&#x27;great masterwort&#x27;</span>, <span class="number">38</span>: <span class="string">&#x27;siam tulip&#x27;</span>, <span class="number">39</span>: <span class="string">&#x27;lenten rose&#x27;</span>, <span class="number">40</span>: <span class="string">&#x27;barbeton daisy&#x27;</span>, <span class="number">41</span>: <span class="string">&#x27;daffodil&#x27;</span>, <span class="number">42</span>: <span class="string">&#x27;sword lily&#x27;</span>, <span class="number">43</span>: <span class="string">&#x27;poinsettia&#x27;</span>, <span class="number">44</span>: <span class="string">&#x27;bolero deep blue&#x27;</span>, <span class="number">45</span>: <span class="string">&#x27;wallflower&#x27;</span>, <span class="number">46</span>: <span class="string">&#x27;marigold&#x27;</span>, <span class="number">47</span>: <span class="string">&#x27;buttercup&#x27;</span>, <span class="number">48</span>: <span class="string">&#x27;oxeye daisy&#x27;</span>, <span class="number">49</span>: <span class="string">&#x27;common dandelion&#x27;</span>, <span class="number">50</span>: <span class="string">&#x27;petunia&#x27;</span>, <span class="number">51</span>: <span class="string">&#x27;wild pansy&#x27;</span>, <span class="number">52</span>: <span class="string">&#x27;primula&#x27;</span>, <span class="number">53</span>: <span class="string">&#x27;sunflower&#x27;</span>, <span class="number">54</span>: <span class="string">&#x27;pelargonium&#x27;</span>, <span class="number">55</span>: <span class="string">&#x27;bishop of llandaff&#x27;</span>, <span class="number">56</span>: <span class="string">&#x27;gaura&#x27;</span>, <span class="number">57</span>: <span class="string">&#x27;geranium&#x27;</span>, <span class="number">58</span>: <span class="string">&#x27;orange dahlia&#x27;</span>, <span class="number">59</span>: <span class="string">&#x27;pink-yellow dahlia&#x27;</span>, <span class="number">60</span>: <span class="string">&#x27;cautleya spicata&#x27;</span>, <span class="number">61</span>: <span class="string">&#x27;japanese anemone&#x27;</span>, <span class="number">62</span>: <span class="string">&#x27;black-eyed susan&#x27;</span>, <span class="number">63</span>: <span class="string">&#x27;silverbush&#x27;</span>, <span class="number">64</span>: <span class="string">&#x27;californian poppy&#x27;</span>, <span class="number">65</span>: <span class="string">&#x27;osteospermum&#x27;</span>, <span class="number">66</span>: <span class="string">&#x27;spring crocus&#x27;</span>, <span class="number">67</span>: <span class="string">&#x27;bearded iris&#x27;</span>, <span class="number">68</span>: <span class="string">&#x27;windflower&#x27;</span>, <span class="number">69</span>: <span class="string">&#x27;tree poppy&#x27;</span>, <span class="number">70</span>: <span class="string">&#x27;gazania&#x27;</span>, <span class="number">71</span>: <span class="string">&#x27;azalea&#x27;</span>, <span class="number">72</span>: <span class="string">&#x27;water lily&#x27;</span>, <span class="number">73</span>: <span class="string">&#x27;rose&#x27;</span>, <span class="number">74</span>: <span class="string">&#x27;thorn apple&#x27;</span>, <span class="number">75</span>: <span class="string">&#x27;morning glory&#x27;</span>, <span class="number">76</span>: <span class="string">&#x27;passion flower&#x27;</span>, <span class="number">77</span>: <span class="string">&#x27;lotus lotus&#x27;</span>, <span class="number">78</span>: <span class="string">&#x27;toad lily&#x27;</span>, <span class="number">79</span>: <span class="string">&#x27;anthurium&#x27;</span>, <span class="number">80</span>: <span class="string">&#x27;frangipani&#x27;</span>, <span class="number">81</span>: <span class="string">&#x27;clematis&#x27;</span>, <span class="number">82</span>: <span class="string">&#x27;hibiscus&#x27;</span>, <span class="number">83</span>: <span class="string">&#x27;columbine&#x27;</span>, <span class="number">84</span>: <span class="string">&#x27;desert-rose&#x27;</span>, <span class="number">85</span>: <span class="string">&#x27;tree mallow&#x27;</span>, <span class="number">86</span>: <span class="string">&#x27;magnolia&#x27;</span>, <span class="number">87</span>: <span class="string">&#x27;cyclamen&#x27;</span>, <span class="number">88</span>: <span class="string">&#x27;watercress&#x27;</span>, <span class="number">89</span>: <span class="string">&#x27;canna lily&#x27;</span>, <span class="number">90</span>: <span class="string">&#x27;hippeastrum&#x27;</span>, <span class="number">91</span>: <span class="string">&#x27;bee balm&#x27;</span>, <span class="number">92</span>: <span class="string">&#x27;ball moss&#x27;</span>, <span class="number">93</span>: <span class="string">&#x27;foxglove&#x27;</span>, <span class="number">94</span>: <span class="string">&#x27;bougainvillea&#x27;</span>, <span class="number">95</span>: <span class="string">&#x27;camellia&#x27;</span>, <span class="number">96</span>: <span class="string">&#x27;mallow&#x27;</span>, <span class="number">97</span>: <span class="string">&#x27;mexican petunia&#x27;</span>, <span class="number">98</span>: <span class="string">&#x27;bromelia&#x27;</span>, <span class="number">99</span>: <span class="string">&#x27;blanket flower&#x27;</span>, <span class="number">100</span>: <span class="string">&#x27;trumpet creeper&#x27;</span>, <span class="number">101</span>: <span class="string">&#x27;blackberry lily&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>
<p>Here I mainly refer to the official website <a href="hhttps://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html" rel="external nofollow noreferrer">Transfer Learning</a> to change the writing style to the dataSet I want, and start to download the file:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Data augmentation and normalization for training</span></span><br><span class="line"><span class="comment"># Just normalization for validation</span></span><br><span class="line">data_transforms = &#123;</span><br><span class="line">    <span class="string">&#x27;train&#x27;</span>: transforms.Compose([</span><br><span class="line">        <span class="comment"># First, the image is randomly cropped and then resized. A random rectangular area is chosen and the image is cropped.</span></span><br><span class="line">        <span class="comment"># The cropped image is then resized to the specified size of 224x224 pixels.</span></span><br><span class="line">        transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">        <span class="comment"># Set the probability of image flipping, usually a number from 0 to 1, for example, 0.5, which means there&#x27;s a 50% chance of flipping the image. Default value is 0.5</span></span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        <span class="comment"># Convert the image into a Tensor</span></span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        <span class="comment"># Normalize the image values using numerical normalization, where the first parameter is mean, and the second parameter is the standard deviation (std)</span></span><br><span class="line">        <span class="comment"># The reason for setting [0.485, 0.456, 0.406] can be referred from: https://www.geeksforgeeks.org/how-to-normalize-images-in-pytorch/</span></span><br><span class="line">        transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">    ]),</span><br><span class="line">    <span class="string">&#x27;val&#x27;</span>: transforms.Compose([</span><br><span class="line">        <span class="comment"># This doesn&#x27;t randomly select an area but directly resizes the entire image to fit the specified size.</span></span><br><span class="line">        transforms.Resize(<span class="number">256</span>),</span><br><span class="line">        <span class="comment"># Keep the central part of the image, then resize to meet the specified size.</span></span><br><span class="line">        <span class="comment"># Used for validation or test data to ensure that the test images have similar features, and don&#x27;t have the randomness like RandomResizedCrop.</span></span><br><span class="line">        transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">    ]),</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># We download the training data into the data_dir/train folder, and use the data_transforms[&quot;train&quot;] function for data transformation.</span></span><br><span class="line">train_datasets = Flowers102(root=data_dir+<span class="string">&quot;/train&quot;</span>, split=<span class="string">&quot;train&quot;</span>, download=<span class="literal">True</span>, transform=data_transforms[<span class="string">&quot;train&quot;</span>])</span><br><span class="line"><span class="comment"># We download the validation data into the data_dir/val folder, and use the data_transforms[&quot;val&quot;] function for data transformation.</span></span><br><span class="line">val_datasets = Flowers102(root=data_dir+<span class="string">&quot;/val&quot;</span>, split=<span class="string">&quot;val&quot;</span>, download=<span class="literal">True</span>, transform=data_transforms[<span class="string">&quot;val&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Specify to download the flowers102 dataset, downloading both train and val datasets.</span></span><br><span class="line">image_datasets = &#123;x: Flowers102(root=data_dir, split=x, download=<span class="literal">True</span>, transform=data_transforms[x])</span><br><span class="line">                    <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert to DataLoader format, and specify batch_size</span></span><br><span class="line">dataloaders = &#123;x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,</span><br><span class="line">                                             shuffle=<span class="literal">True</span>, num_workers=<span class="number">4</span>)</span><br><span class="line">              <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;mps&quot;</span> <span class="keyword">if</span> torch.backends.mps.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;device: &quot;</span>,device)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;image_datasets function call: &quot;</span>, <span class="built_in">dir</span>(image_datasets[<span class="string">&quot;train&quot;</span>]))</span><br></pre></td></tr></table></figure>
<div class="note info flat"><p>This completes the first Task, which is to download the dataset we want.</p>
</div>
<h1 id="Task-2-Printing-out-images-and-profile-sizes">Task 2 - Printing out images and profile sizes</h1>
<div class="note info flat"><ol start="2">
<li><em><strong>Print images and profile size</strong></em>: display some sample images of the dataset in the notebook and print the dataset size.</li>
</ol>
</div>
<p>Referring to the official website <a href="hhttps://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html" rel="external nofollow noreferrer">Transfer Learning</a> for the writeup, we first create the</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">imshow</span>(<span class="params">inp, title=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Display image for Tensor.&quot;&quot;&quot;</span></span><br><span class="line">    inp = inp.numpy().transpose((<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line">    mean = np.array([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>])</span><br><span class="line">    std = np.array([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">    inp = std * inp + mean</span><br><span class="line">    inp = np.clip(inp, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    plt.imshow(inp)</span><br><span class="line">    <span class="keyword">if</span> title <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    plt.pause(<span class="number">0.001</span>)  <span class="comment"># pause a bit so that plots are updated</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get a batch of training data</span></span><br><span class="line">inputs, classes = <span class="built_in">next</span>(<span class="built_in">iter</span>(dataloaders[<span class="string">&#x27;train&#x27;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make a grid from batch</span></span><br><span class="line">out = torchvision.utils.make_grid(inputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># x.item() takes the value of the tensor, usually a number, and finds the English equivalent of that number in the class_names dic</span></span><br><span class="line">imshow(out, title=[class_names[x.item()] <span class="keyword">for</span> x <span class="keyword">in</span> classes])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(inputs.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;dataset_sizes: &quot;</span>,dataset_sizes)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Result</p>
</blockquote>
<p><img src="/en/img/loading-icon.gif" data-original="https://i.imgur.com/dPGyFvN.png" alt=""></p>
<h1 id="Task-3-4-CNN-Batch-Normalization">Task 3 &amp; 4 - CNN + Batch Normalization</h1>
<div class="note info flat"><ol start="3">
<li><strong>Construct a CNN using Batch Normalization</strong>: Design a CNN to predict on the dataset. Use a similar architecture like last time, but this time also include batch normalization layers.</li>
<li>**Train the model on the dataset and measure the accuracy on hold out test data.</li>
</ol>
</div>
<p><strong>According to Prof. Hongyi Li in Transfer Learning, he mentioned‚Ä¶</strong><br>
Usually, <code>Batch Normalization</code> is performed before <code>Activation Function</code>, you can refer to this <a href="/posts/ML.html#Feature-Normalization">section</a> if you are interested. <code>Batch Normalization</code> is simply to run <code>feature normalization</code> in the same way as <code>Batch</code>.</p>
<p><strong>Why do we need to do feature normalization?  Why do we do feature normalization?</strong><br>
It is to let different features have similar value ranges, so that when the model performs Gradient Descent, the effect of w1 and w2 on the loss will not be too big, and they have similar value ranges, so that they can affect the loss evenly, instead of a certain w1 affecting the loss much more than w2.</p>
<blockquote>
<p>Instead of a w1 having a much larger effect on loss than w2, the effect will be something like the following.</p>
</blockquote>
<p>! <a target="_blank" rel="noopener external nofollow noreferrer" href="https://i.imgur.com/RB51XXy.png">Origin</a></p>
<h2 id="Build-the-Network">Build the Network</h2>
<div class="note warning flat"><p>Note that depending on the size of the dataset and the number of hidden layers, you have to make two adjustments!</p>
<ol>
<li>In the fully connection layer, the input is determined by the number of times your hidden layer performs <code>max-pooling</code> and <code>convolution</code>. 2.</li>
<li>Then you have to adjust the number of outputs in the last output layer according to the number of categories in your dataset.</li>
</ol>
<p>Please note the part of the code labeled with the comment arrow <code>&lt;====</code>.</p>
</div>
<p>So our CNN architecture is as follows, <code>You can decide whether you want to run a dropout to unpack the annotations or not</code>.<br>
But in my case, I tested that the dropout didn‚Äôt result in higher accuracy.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NewNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(NewNet, self).__init__()</span><br><span class="line">        <span class="comment"># Layer 1: 3x3 kernel, depth = 32, 224-3+1=222 =&gt; 222x222 pixel</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">3</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(<span class="number">32</span>)</span><br><span class="line">        <span class="comment"># self.dropout1 = nn.Dropout(0.5) # Apply dropout as needed</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Layer 2: Max pooling with 2x2 kernel, 222/2=111 =&gt; 111x111 pixel</span></span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Layer 3: 3x3 kernel, depth = 64, 111-3+1=109 =&gt; 109x109 pixel</span></span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">3</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(<span class="number">64</span>)</span><br><span class="line">        <span class="comment"># self.dropout2 = nn.Dropout(0.5) # Apply dropout as needed</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Layer 4: Max pooling with 2x2 kernel, 109/2=54 =&gt; 54x54 pixel</span></span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Layer 5: 3x3 kernel, depth = 128, 54-3+1=52 =&gt; 52x52 pixel</span></span><br><span class="line">        self.conv3 = nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, <span class="number">3</span>)</span><br><span class="line">        self.bn3 = nn.BatchNorm2d(<span class="number">128</span>)</span><br><span class="line">        <span class="comment"># self.dropout3 = nn.Dropout(0.5) # Apply dropout as needed</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Layer 6: Max pooling with 2x2 kernel, 52/2=26 =&gt; 26x26 pixel</span></span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Final input is 512, pixel is 26*26 =&gt; 128*26*26</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">128</span> * <span class="number">26</span> * <span class="number">26</span>, <span class="number">2048</span>) <span class="comment"># &lt;==== Adjust according to the hidden layer, 128 * 26 * 26</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">2048</span>, <span class="number">1024</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">1024</span>, <span class="number">512</span>)</span><br><span class="line">        self.fc4 = nn.Linear(<span class="number">512</span>, <span class="number">102</span>) <span class="comment"># &lt;==== 102 according to the number of classes in the dataset</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># We put the batch normalization before the activation function. </span></span><br><span class="line">        x = F.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        x = self.pool(x)</span><br><span class="line">        <span class="comment"># x = self.dropout1(x) # Apply dropout as needed</span></span><br><span class="line">        x = F.relu(self.bn2(self.conv2(x)))</span><br><span class="line">        x = self.pool(x)</span><br><span class="line">        <span class="comment"># x = self.dropout2(x) # Apply dropout as needed</span></span><br><span class="line">        x = F.relu(self.bn3(self.conv3(x)))</span><br><span class="line">        x = self.pool(x)</span><br><span class="line">        <span class="comment"># x = self.dropout3(x) # Apply dropout as needed</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">128</span> * <span class="number">26</span> * <span class="number">26</span>) <span class="comment"># &lt;==== Adjust according to the hidden layer, 128 * 26 * 26</span></span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = F.relu(self.fc3(x))</span><br><span class="line">        x = self.fc4(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">net = NewNet()</span><br><span class="line">net.to(device)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>and specify the optimizer and loss function:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Create-a-Training-Func">Create a Training Func</h2>
<p>We need to create a funcntion to execute the training model as follows:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">epoch, start_time</span>):</span><br><span class="line">    net.train()</span><br><span class="line">    cur_count = <span class="number">0</span> </span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloaders[<span class="string">&quot;train&quot;</span>], <span class="number">0</span>):</span><br><span class="line">        cur_count += <span class="built_in">len</span>(data)</span><br><span class="line">        inputs, labels = data[<span class="number">0</span>].to(device), data[<span class="number">1</span>].to(device)</span><br><span class="line">        <span class="comment"># zero the parameter gradients</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward + backward + optimize</span></span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        outputs.to(device)</span><br><span class="line">        </span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.to(device)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">100</span> == <span class="number">99</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;[<span class="subst">&#123;epoch&#125;</span>, <span class="subst">&#123;batch_idx + <span class="number">1</span>:5d&#125;</span>] loss: <span class="subst">&#123;running_loss / <span class="number">100</span>:<span class="number">.3</span>f&#125;</span> time elapsed: <span class="subst">&#123;<span class="built_in">round</span>((time.time() - start_time))&#125;</span> sec.&#x27;</span>)</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br></pre></td></tr></table></figure>
<h2 id="Build-Testing-Func">Build Testing Func</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(): </span><br><span class="line">    net.<span class="built_in">eval</span>()  <span class="comment"># set model to evaluation mode</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    class_correct = [<span class="number">0</span>] * <span class="built_in">len</span>(class_names)  </span><br><span class="line">    class_total = [<span class="number">0</span>] * <span class="built_in">len</span>(class_names)  </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> dataloaders[<span class="string">&quot;val&quot;</span>]:</span><br><span class="line">            images, labels = data[<span class="number">0</span>].to(device), data[<span class="number">1</span>].to(device)</span><br><span class="line">            outputs = net(images) </span><br><span class="line"></span><br><span class="line">            <span class="comment"># select top 3 predictions</span></span><br><span class="line">            _, predicted = torch.topk(outputs, <span class="number">1</span>, dim=<span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># check if predicted labels are in true labels</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(labels)):</span><br><span class="line">                total += <span class="number">1</span></span><br><span class="line">                class_total[labels[i]] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> labels[i] <span class="keyword">in</span> predicted[i]:</span><br><span class="line">                    correct += <span class="number">1</span></span><br><span class="line">                    class_correct[labels[i]] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    class_accuracies = [class_correct[i] / class_total[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(class_names))]</span><br><span class="line">    accuracy = correct / total</span><br><span class="line">    <span class="keyword">return</span> accuracy, class_accuracies</span><br></pre></td></tr></table></figure>
<h2 id="Run-Training">Run Training</h2>
<p>In order for us to see the status of the training during the training process, we print the status of the training every 100 batches and the status of the test every 5 epochs.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">num_epochs = <span class="number">100</span> </span><br><span class="line">start_time = time.time()</span><br><span class="line"></span><br><span class="line">accuracy, class_accuracies = test()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Accuracy on test data (top-1): <span class="subst">&#123;<span class="number">100</span> * accuracy:<span class="number">.2</span>f&#125;</span>%&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_epochs - <span class="number">1</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;============ Epoch: <span class="subst">&#123;epoch&#125;</span> ==========&quot;</span>)</span><br><span class="line">    train(epoch, start_time)</span><br><span class="line">    <span class="comment"># every 5 epoch is completed, we will perform validation on the test set </span></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">        accuracy, class_accuracies = test()</span><br><span class="line">        <span class="comment"># print accuracies</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Accuracy on test data (top-1): <span class="subst">&#123;<span class="number">100</span> * accuracy:<span class="number">.2</span>f&#125;</span>%&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Finished Training. Total elapsed time: <span class="subst">&#123;<span class="built_in">round</span>((time.time() - start_time) / <span class="number">60</span>, <span class="number">1</span>)&#125;</span> min&#x27;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Result</p>
</blockquote>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Accuracy on test data (top<span class="number">-1</span>): <span class="number">0.0019</span>%</span><br><span class="line">============ Epoch: <span class="number">0</span> ==========</span><br><span class="line">[<span class="number">0</span>,   <span class="number">100</span>] loss: <span class="number">4.984</span> <span class="built_in">time</span> elapsed: <span class="number">40</span> sec.</span><br><span class="line">[<span class="number">0</span>,   <span class="number">200</span>] loss: <span class="number">4.876</span> <span class="built_in">time</span> elapsed: <span class="number">47</span> sec.</span><br><span class="line">...</span><br><span class="line">Accuracy on test data (top<span class="number">-1</span>): <span class="number">35.59</span>%</span><br><span class="line">Finished Training. Total elapsed <span class="built_in">time</span>: <span class="number">67</span> <span class="built_in">min</span></span><br></pre></td></tr></table></figure>
<h1 id="Task-5-4-Transfer-LearningÔºöResnet18">Task 5 &amp; 4 - Transfer LearningÔºöResnet18</h1>
<div class="note info flat"><ol start="4">
<li><strong>Train a model using a dataset and print out the accuracy of the test</strong>: train a model on a dataset and measure the accuracy on retained test data.</li>
<li><strong>Use ResNet18 for Migration Learning</strong>: now use migration learning to use a pre-trained ResNet18 on the dataset as follows:<br>
<strong>Without changing the trained weights of other people‚Äôs models</strong>: ResNet18 is used as a fixed feature extractor.
<ol>
<li><strong>Fix the parameters</strong>: Fix the parameters of the ResNet18 model and only train the last layer.</li>
<li><strong>Fine-tuning</strong>: Fine-tune the ResNet18 model.</li>
</ol>
</li>
</ol>
</div>
<h2 id="Build-up-Trainning-Testing-Func">Build up Trainning &amp; Testing Func</h2>
<p>Refer to the official website <a href="hhttps://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html" rel="external nofollow noreferrer">Transfer Learning</a> for the writeup, we first create the</p>
<figure class="highlight python"><figcaption><span>def train_model(model, criterion, optimizer, scheduler, num_epochs</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set the start time for logging to monitor the training time for each epoch</span></span><br><span class="line">since = time.time()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a temporary folder to store the best model parameters</span></span><br><span class="line"><span class="keyword">with</span> TemporaryDirectory() <span class="keyword">as</span> tempdir:</span><br><span class="line">    best_model_params_path = os.path.join(tempdir, <span class="string">&#x27;best_model_params.pt&#x27;</span>)</span><br><span class="line">    <span class="comment"># Haven&#x27;t started training yet, but we first save the current model</span></span><br><span class="line">    torch.save(model.state_dict(), best_model_params_path)</span><br><span class="line">    best_acc = <span class="number">0.0</span>  <span class="comment"># Set the current best accuracy to 0, it will be updated if a higher value is found to determine the best model</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Epoch <span class="subst">&#123;epoch&#125;</span>/<span class="subst">&#123;num_epochs - <span class="number">1</span>&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># After training each epoch, proceed with validation</span></span><br><span class="line">        <span class="keyword">for</span> phase <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]:</span><br><span class="line">            <span class="comment"># Determine whether it&#x27;s training or validation phase</span></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                model.train()  <span class="comment"># Set model to training mode</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                model.<span class="built_in">eval</span>()   <span class="comment"># Set model to evaluate mode</span></span><br><span class="line"></span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">            running_corrects = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Iterate over data.</span></span><br><span class="line">            <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> dataloaders[phase]:</span><br><span class="line">                <span class="comment"># Move to GPU</span></span><br><span class="line">                inputs = inputs.to(device)</span><br><span class="line">                labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Zero the parameter gradients</span></span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Forward propagation</span></span><br><span class="line">                <span class="comment"># track history if only in train</span></span><br><span class="line">                <span class="keyword">with</span> torch.set_grad_enabled(phase == <span class="string">&#x27;train&#x27;</span>):</span><br><span class="line">                    outputs = model(inputs)</span><br><span class="line">                    _, preds = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>) <span class="comment"># Select the number with the highest prediction as the label</span></span><br><span class="line">                    loss = criterion(outputs, labels) <span class="comment"># Calculate the difference between the answer and prediction</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment"># backward + optimize only if in training phase</span></span><br><span class="line">                    <span class="comment"># Perform backward propagation</span></span><br><span class="line">                    <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                        loss.backward()</span><br><span class="line">                        optimizer.step()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Since batch_size is 4, multiply loss by 4 to get the loss for a batch</span></span><br><span class="line">                running_loss += loss.item() * inputs.size(<span class="number">0</span>)</span><br><span class="line">                <span class="comment"># Calculate how many are correct in a batch</span></span><br><span class="line">                running_corrects += torch.<span class="built_in">sum</span>(preds == labels.data)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Adjust the learning rate only during training</span></span><br><span class="line">            <span class="comment"># scheduler is a learning rate (lr) adjuster used to modify the lr value during model training</span></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                scheduler.step()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># After an entire epoch of training, calculate the loss and accuracy for that epoch</span></span><br><span class="line">            <span class="comment"># Avg. loss = total loss / size of the entire dataset</span></span><br><span class="line">            epoch_loss = running_loss / dataset_sizes[phase]</span><br><span class="line">            <span class="comment"># Avg. Acc = total number of correct answers / size of the entire dataset</span></span><br><span class="line">            epoch_acc = running_corrects.<span class="built_in">float</span>() / dataset_sizes[phase]</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;phase&#125;</span> Loss: <span class="subst">&#123;epoch_loss:<span class="number">.4</span>f&#125;</span> Acc: <span class="subst">&#123;epoch_acc:<span class="number">.4</span>f&#125;</span> Time elapsed: <span class="subst">&#123;<span class="built_in">round</span>((time.time() - since))&#125;</span> sec.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># If during validation, and accuracy is found to be better than the current best, save the model parameters</span></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;val&#x27;</span> <span class="keyword">and</span> epoch_acc &gt; best_acc:</span><br><span class="line">                <span class="comment"># Update the current best accuracy</span></span><br><span class="line">                best_acc = epoch_acc</span><br><span class="line">                <span class="comment"># Deep copy the model</span></span><br><span class="line">                torch.save(model.state_dict(), best_model_params_path)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line">    time_elapsed = time.time() - since</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Training complete in <span class="subst">&#123;time_elapsed // <span class="number">60</span>:<span class="number">.0</span>f&#125;</span>m <span class="subst">&#123;time_elapsed % <span class="number">60</span>:<span class="number">.0</span>f&#125;</span>s&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Best val Acc: <span class="subst">&#123;best_acc:4f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load the best model weights</span></span><br><span class="line">    <span class="comment"># Take out the best model so far to continue with the next epoch of training</span></span><br><span class="line">    model.load_state_dict(torch.load(best_model_params_path))</span><br><span class="line"><span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h2 id="Use-Transfer-Learning">Use Transfer Learning</h2>
<p>According to the teacher‚Äôs request, I want to use resnet18 for Transfer Learning, currently according to the [official description](<a target="_blank" rel="noopener external nofollow noreferrer" href="https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet18">https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet18</a>. html#torchvision.models.ResNet18_Weights), <code>resent18</code> is <code>IMAGENET1K_V1</code> by default if we don‚Äôt give the parameter, in order to make it clear which model‚Äôs parameter we are using, we still give the parameter.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">model_ft = models.resnet18(weights=<span class="string">&#x27;IMAGENET1K_V1&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># num_ftrs is the number of input features for the last layer. </span></span><br><span class="line"><span class="comment"># Retrieve the number of input features for the last layer</span></span><br><span class="line">num_ftrs = model_ft.fc.in_features</span><br><span class="line"></span><br><span class="line"><span class="comment"># Here the size of each output sample is set to 102.</span></span><br><span class="line"><span class="comment"># model_ft.fc is the final layer of the model, used for classification.</span></span><br><span class="line"><span class="comment"># Creating the final layer ourselves, setting the input number as num_ftrs, and output number as 102 (since there are 102 classes in this case)</span></span><br><span class="line">model_ft.fc = nn.Linear(num_ftrs, <span class="number">102</span>)</span><br><span class="line">model_ft = model_ft.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The loss function uses CrossEntropyLoss </span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Observe that all parameters are being optimized</span></span><br><span class="line"><span class="comment"># Optimizer uses SGD with learning rate = 0.001, momentum = 0.9</span></span><br><span class="line">optimizer_ft = optim.SGD(model_ft.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decay LR by a factor of 0.1 every 7 epochs</span></span><br><span class="line"><span class="comment"># Multiply the learning rate by 0.1 every 7 epochs to decay the lr</span></span><br><span class="line">exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=<span class="number">7</span>, gamma=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/en/img/loading-icon.gif" data-original="https://i.imgur.com/rygK4KS.png" alt=""></p>
<div class="note warning flat"><p><strong>Why need to adjust lr?</strong><br>
Adjusting the learning rate every certain epoch is a common learning rate adjustment strategy called learning rate decay or learning rate scheduling. The effect of this is to:</p>
<ol>
<li>
<p>Improve model stability: During training, ``using a relatively large learning rate at the beginning helps to converge quickly.‚Äò‚Äô However, when training <code>near the optimal solution, a larger learning rate may cause the model to oscillate or over-adjust near the optimal solution</code>. By periodically decreasing the learning rate, the model will be more stable and closer to the optimal solution in the later stages of training.</p>
</li>
<li>
<p>Preventing overfitting: `Periodically decreasing the learning rate helps prevent the model from overfitting on the training set.‚Äô When the learning rate is reduced, the model adjusts its parameters more carefully and is less likely to fall into the noise in the training set.</p>
</li>
</ol>
<p>In practice, the specific settings of the learning rate tuning strategy (e.g., the values of <code>step_size</code> and <code>gamma</code>) are usually adjusted based on trials and experience to achieve optimal performance. Typically, the settings of these parameters depend on the size of your dataset, the model architecture, the difficulty of the problem, and other factors.</p>
</div>
<h2 id="Start-Training">Start Training</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,</span><br><span class="line">                       num_epochs=<span class="number">25</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Result: Accuracy on test data (top-1): 89.41%</p>
</blockquote>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">Epoch <span class="number">0</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">4.4280</span> Acc: <span class="number">0.0657</span> Time elapsed: <span class="number">33</span> sec.</span><br><span class="line">val Loss: <span class="number">2.9901</span> Acc: <span class="number">0.3118</span> Time elapsed: <span class="number">58</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">1</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">3.3046</span> Acc: <span class="number">0.2353</span> Time elapsed: <span class="number">87</span> sec.</span><br><span class="line">val Loss: <span class="number">1.6604</span> Acc: <span class="number">0.5941</span> Time elapsed: <span class="number">112</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">2</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">2.5080</span> Acc: <span class="number">0.4029</span> Time elapsed: <span class="number">141</span> sec.</span><br><span class="line">val Loss: <span class="number">1.2243</span> Acc: <span class="number">0.6951</span> Time elapsed: <span class="number">166</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">3</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">1.9871</span> Acc: <span class="number">0.5196</span> Time elapsed: <span class="number">195</span> sec.</span><br><span class="line">val Loss: <span class="number">0.9578</span> Acc: <span class="number">0.7216</span> Time elapsed: <span class="number">219</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">4</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">1.5865</span> Acc: <span class="number">0.6225</span> Time elapsed: <span class="number">249</span> sec.</span><br><span class="line">val Loss: <span class="number">0.6911</span> Acc: <span class="number">0.8108</span> Time elapsed: <span class="number">273</span> sec.</span><br><span class="line">...</span><br><span class="line">val Loss: <span class="number">0.3919</span> Acc: <span class="number">0.8912</span> Time elapsed: <span class="number">1313</span> sec.</span><br><span class="line"></span><br><span class="line">Training complete <span class="keyword">in</span> <span class="number">21</span>m <span class="number">53</span>s</span><br><span class="line">Best val Acc: <span class="number">0.894118</span></span><br></pre></td></tr></table></figure>
<h2 id="Using-ResNet18-as-a-fixed-feature-extractor">Using ResNet18 as a fixed feature extractor</h2>
<p>Due to the requirements of the homework, ResNet18 is required to be used as a fixed feature extractor, so we need to set all the parameters to be untrainable, and only the parameters of the last layer can be trained. <strong>Simply put, don‚Äôt change the weights of other people‚Äôs models.</strong> The only thing we need to change is to set each parameter of the model‚Äôs <code>requires_grad</code> to False. This way, we can use ResNet18 as a fixed feature extractor.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">model_conv = torchvision.models.resnet18(weights=<span class="string">&#x27;IMAGENET1K_V1&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># !!! Add these two lines to set requires_grad to False, so that the parameters will not be updated </span></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model_conv.parameters():</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">num_ftrs = model_conv.fc.in_features</span><br><span class="line">model_conv.fc = nn.Linear(num_ftrs, <span class="number">102</span>)</span><br><span class="line">model_conv = model_conv.to(device)</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=<span class="number">7</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># We start to train </span></span><br><span class="line">model_conv_SGD = train_model(model_conv, criterion, optimizer_conv,</span><br><span class="line">                         exp_lr_scheduler, num_epochs=<span class="number">25</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Result: Accuracy on test data: 79.11%</p>
</blockquote>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">Epoch <span class="number">0</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">4.6979</span> Acc: <span class="number">0.0176</span> Time elapsed: <span class="number">24</span> sec.</span><br><span class="line">val Loss: <span class="number">3.9863</span> Acc: <span class="number">0.1235</span> Time elapsed: <span class="number">48</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">1</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">4.0589</span> Acc: <span class="number">0.1137</span> Time elapsed: <span class="number">72</span> sec.</span><br><span class="line">val Loss: <span class="number">3.1125</span> Acc: <span class="number">0.3608</span> Time elapsed: <span class="number">95</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">2</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">3.4935</span> Acc: <span class="number">0.2304</span> Time elapsed: <span class="number">119</span> sec.</span><br><span class="line">val Loss: <span class="number">2.5003</span> Acc: <span class="number">0.4912</span> Time elapsed: <span class="number">142</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">3</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">3.1030</span> Acc: <span class="number">0.3422</span> Time elapsed: <span class="number">165</span> sec.</span><br><span class="line">val Loss: <span class="number">2.1583</span> Acc: <span class="number">0.5510</span> Time elapsed: <span class="number">189</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">4</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">2.7367</span> Acc: <span class="number">0.4402</span> Time elapsed: <span class="number">212</span> sec.</span><br><span class="line">val Loss: <span class="number">1.7064</span> Acc: <span class="number">0.6304</span> Time elapsed: <span class="number">236</span> sec.</span><br><span class="line">...</span><br><span class="line">val Loss: <span class="number">1.0910</span> Acc: <span class="number">0.7824</span> Time elapsed: <span class="number">1179</span> sec.</span><br><span class="line"></span><br><span class="line">Training complete <span class="keyword">in</span> <span class="number">19</span>m <span class="number">39</span>s</span><br><span class="line">Best val Acc: <span class="number">0.791176</span></span><br></pre></td></tr></table></figure>
<h1 id="Task-6-4-Transfer-LearningÔºöEfficientNet-B5">Task 6 &amp; 4 - Transfer LearningÔºöEfficientNet_B5</h1>
<div class="note info flat"><ol start="4">
<li><em><strong>Train a model using a dataset and print out the accuracy of the test</strong></em>: train a model on a dataset and measure the accuracy on retained test data.</li>
<li><em><strong>Fine-tuning using RestNet</strong></em> : ResNet18 is fine-tuned on the training data.</li>
</ol>
</div>
<p>We need to install the <code>efficientnet_pytorch</code> package first:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install efficientnet_pytorch</span><br></pre></td></tr></table></figure>
<p>Then we can import the package and use it:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> efficientnet_pytorch <span class="keyword">import</span> EfficientNet</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the pre-trained EfficientNet-B5 model</span></span><br><span class="line">model_ft = EfficientNet.from_pretrained(<span class="string">&#x27;efficientnet-b5&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># We obtain the number of input features for the last layer</span></span><br><span class="line">num_ftrs = model_ft._fc.in_features</span><br><span class="line"><span class="comment"># build a new layer, the input number is num_ftrs, and the output number is 102 (because there are 102 classes in this case)</span></span><br><span class="line">model_ft.fc = nn.Linear(num_ftrs, <span class="number">102</span>)</span><br><span class="line"><span class="comment"># Put the model on the GPU</span></span><br><span class="line">model_ft = model_ft.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loss function</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Observe that all parameters are being optimized</span></span><br><span class="line">optimizer_ft = optim.SGD(model_ft.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decay LR by a factor of 0.1 every 7 epochs</span></span><br><span class="line">exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=<span class="number">7</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start training </span></span><br><span class="line">model_ft_effb5 = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,</span><br><span class="line">                       num_epochs=<span class="number">25</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Result: Accuracy on test data: 82.15%</p>
</blockquote>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">Epoch <span class="number">0</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">6.2860</span> Acc: <span class="number">0.0157</span> Time elapsed: <span class="number">156</span> sec.</span><br><span class="line">val Loss: <span class="number">5.6637</span> Acc: <span class="number">0.0382</span> Time elapsed: <span class="number">200</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">1</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">4.8955</span> Acc: <span class="number">0.1039</span> Time elapsed: <span class="number">322</span> sec.</span><br><span class="line">val Loss: <span class="number">4.5101</span> Acc: <span class="number">0.2392</span> Time elapsed: <span class="number">365</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">2</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">3.8566</span> Acc: <span class="number">0.2422</span> Time elapsed: <span class="number">485</span> sec.</span><br><span class="line">val Loss: <span class="number">3.6194</span> Acc: <span class="number">0.4265</span> Time elapsed: <span class="number">529</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">3</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">3.0979</span> Acc: <span class="number">0.3637</span> Time elapsed: <span class="number">653</span> sec.</span><br><span class="line">val Loss: <span class="number">2.8613</span> Acc: <span class="number">0.5539</span> Time elapsed: <span class="number">696</span> sec.</span><br><span class="line"></span><br><span class="line">Epoch <span class="number">4</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">2.4323</span> Acc: <span class="number">0.4725</span> Time elapsed: <span class="number">818</span> sec.</span><br><span class="line">val Loss: <span class="number">2.2894</span> Acc: <span class="number">0.6725</span> Time elapsed: <span class="number">863</span> sec.</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Epoch <span class="number">24</span>/<span class="number">24</span></span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">train Loss: <span class="number">1.3168</span> Acc: <span class="number">0.7343</span> Time elapsed: <span class="number">4769</span> sec.</span><br><span class="line">val Loss: <span class="number">1.3167</span> Acc: <span class="number">0.8167</span> Time elapsed: <span class="number">4812</span> sec.</span><br><span class="line"></span><br><span class="line">Training complete <span class="keyword">in</span> <span class="number">80</span>m <span class="number">12</span>s</span><br><span class="line">Best val Acc: <span class="number">0.821569</span></span><br></pre></td></tr></table></figure>
<h1 id="Task-7-Discussion">Task 7 - Discussion</h1>
<div class="note info flat"><p><strong>Compare these different methods and print out the accuracy</strong>: Compare the accuracy of the different methods on the test data and print out the training time for each method.</p>
</div>
<p>From the results of the above experiments, we can see that the accuracy of the model is as follows:</p>
<ul>
<li><a href="#Task-3-4-CNN-Batch-Normalization">Use the CNN build by ourselves</a></li>
<li>[Using Transfer Learning Resnet18](#Task-5-4-Transfer Learning: Resnet18)</li>
<li>[Using Transfer Learning EfficientNet-B5](#Task-6-4-Transfer Learning: EfficientNet-B5)</li>
</ul>
<p>Their data are as follows:</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Accuracy</th>
<th>Training Time</th>
<th>Result</th>
</tr>
</thead>
<tbody>
<tr>
<td>Self-built CNN</td>
<td><code>35%</code></td>
<td><code>more than 1 hour</code></td>
<td>Worst</td>
</tr>
<tr>
<td>Resnet18</td>
<td><strong>89.41%</strong></td>
<td>21 minutes</td>
<td>highest accuracy</td>
</tr>
<tr>
<td>Resnet18 (fixed feature extractor)</td>
<td>79.11%</td>
<td><strong>19 minutes</strong></td>
<td>Shortest</td>
</tr>
<tr>
<td>EfficientNet-B5</td>
<td>82.15%</td>
<td>80 mins</td>
<td>PuPu</td>
</tr>
</tbody>
</table>
<div class="note warning flat"><p><strong>Conclusion</strong></p>
<ul>
<li>If we use Transfer Learning, we can obviously feel that the accuracy rate is significantly improved and the training time is greatly reduced.</li>
<li>Moreover, in the current case, the accuracy is better without fixed model parameters, although the matching time is longer because of the gradient descent.</li>
</ul>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://shannonhung.github.io/en">Shannon Hung</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://shannonhung.github.io/en/posts/flower102-transfer-learning/">https://shannonhung.github.io/en/posts/flower102-transfer-learning/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener external nofollow noreferrer" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/en/tags/Mechine-Learning/">Mechine Learning</a></div><div class="post_share"><div class="social-share" data-image="/en/img/cover/flower-ml.jpeg" data-sites="facebook"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/en/posts/pytorch-CNN-TensorBoard/" title="CIFAR10 Dataset - Using Pytorch to build CNN + activate GPU + output the result to TensorBoard"><img class="cover" src="/en/img/loading-icon.gif" data-original="/en/img/cover/CNN-bg.jpeg" onerror="onerror=null;src='/en/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous</div><div class="prev_info">CIFAR10 Dataset - Using Pytorch to build CNN + activate GPU + output the result to TensorBoard</div></div></a></div><div class="next-post pull-right"><a href="/en/posts/coco-object-diagnoise/" title="COCO Dataset - use Faster RCNN + MobileNet to conduct Object Detection"><img class="cover" src="/en/img/loading-icon.gif" data-original="/en/img/cover/object-detection.jpeg" onerror="onerror=null;src='/en/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next</div><div class="next_info">COCO Dataset - use Faster RCNN + MobileNet to conduct Object Detection</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/en/posts/coco-object-diagnoise/" title="COCO Dataset - use Faster RCNN + MobileNet to conduct Object Detection"><img class="cover" src="/en/img/loading-icon.gif" data-original="/en/img/cover/object-detection.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-03</div><div class="title">COCO Dataset - use Faster RCNN + MobileNet to conduct Object Detection</div></div></a></div><div><a href="/en/posts/nlp-twitter-emotion-diagnoise/" title="Twitter Dataset - Using LSTM to predict the emotion of the article"><img class="cover" src="/en/img/loading-icon.gif" data-original="/en/img/cover/lstm-emotion.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-16</div><div class="title">Twitter Dataset - Using LSTM to predict the emotion of the article</div></div></a></div><div><a href="/en/posts/pytorch-CNN-TensorBoard/" title="CIFAR10 Dataset - Using Pytorch to build CNN + activate GPU + output the result to TensorBoard"><img class="cover" src="/en/img/loading-icon.gif" data-original="/en/img/cover/CNN-bg.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-24</div><div class="title">CIFAR10 Dataset - Using Pytorch to build CNN + activate GPU + output the result to TensorBoard</div></div></a></div><div><a href="/en/posts/PyTorch-Mac-GPU/" title="MAC OS -  PyTorch on Mac OS with GPU support"><img class="cover" src="/en/img/loading-icon.gif" data-original="/en/img/cover/mac_ai_gpu.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-30</div><div class="title">MAC OS -  PyTorch on Mac OS with GPU support</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/en/img/loading-icon.gif" data-original="/en/img/dudu-me.png" onerror="this.onerror=null;this.src='/en/en/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Shannon Hung</div><div class="author-info__description">In order to avoid forgetfulness, I started to record</div></div><div class="card-info-data site-data is-center"><a href="/en/archives/"><div class="headline">Articles</div><div class="length-num">12</div></a><a href="/en/tags/"><div class="headline">Tags</div><div class="length-num">11</div></a><a href="/en/categories/"><div class="headline">Categories</div><div class="length-num">12</div></a></div><a id="card-info-btn" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/ShannonHung"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ShannonHung" rel="external nofollow noreferrer" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:hsuanhung036@gmail.com" rel="external nofollow noreferrer" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">I am a graduate student at the Taiwan University of Science and Technology - Institute of Information Management, planning to pursue a dual-degree program in Germany this year. The reason behind setting up this website is my rather short memory span. While I have learned a lot, I tend to forget much of it. To combat forgetfulness, I have embarked on my note-taking journey.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Preface"><span class="toc-text">Preface</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Assignment-Requirements"><span class="toc-text">Assignment Requirements</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Task-0-Importing-Packages"><span class="toc-text">Task 0 - Importing Packages</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Task-1-Selecting-a-DataSet"><span class="toc-text">Task 1 - Selecting a DataSet</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Task-2-Printing-out-images-and-profile-sizes"><span class="toc-text">Task 2 - Printing out images and profile sizes</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Task-3-4-CNN-Batch-Normalization"><span class="toc-text">Task 3 &amp; 4 - CNN + Batch Normalization</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Build-the-Network"><span class="toc-text">Build the Network</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Create-a-Training-Func"><span class="toc-text">Create a Training Func</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Build-Testing-Func"><span class="toc-text">Build Testing Func</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Run-Training"><span class="toc-text">Run Training</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Task-5-4-Transfer-Learning%EF%BC%9AResnet18"><span class="toc-text">Task 5 &amp; 4 - Transfer LearningÔºöResnet18</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Build-up-Trainning-Testing-Func"><span class="toc-text">Build up Trainning &amp; Testing Func</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Use-Transfer-Learning"><span class="toc-text">Use Transfer Learning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Start-Training"><span class="toc-text">Start Training</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Using-ResNet18-as-a-fixed-feature-extractor"><span class="toc-text">Using ResNet18 as a fixed feature extractor</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Task-6-4-Transfer-Learning%EF%BC%9AEfficientNet-B5"><span class="toc-text">Task 6 &amp; 4 - Transfer LearningÔºöEfficientNet_B5</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Task-7-Discussion"><span class="toc-text">Task 7 - Discussion</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/en/posts/textract-multi-column/" title="How to Handle Multi-Column Text Sorting with Amazon Textract"><img src="/en/img/loading-icon.gif" data-original="/en/img/cover/ocr-scan.jpeg" onerror="this.onerror=null;this.src='/en/img/404.jpg'" alt="How to Handle Multi-Column Text Sorting with Amazon Textract"/></a><div class="content"><a class="title" href="/en/posts/textract-multi-column/" title="How to Handle Multi-Column Text Sorting with Amazon Textract">How to Handle Multi-Column Text Sorting with Amazon Textract</a><time datetime="2024-03-19T16:40:35.000Z" title="Created 2024-03-20 00:40:35">2024-03-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/en/posts/nlp-twitter-emotion-diagnoise/" title="Twitter Dataset - Using LSTM to predict the emotion of the article"><img src="/en/img/loading-icon.gif" data-original="/en/img/cover/lstm-emotion.jpeg" onerror="this.onerror=null;this.src='/en/img/404.jpg'" alt="Twitter Dataset - Using LSTM to predict the emotion of the article"/></a><div class="content"><a class="title" href="/en/posts/nlp-twitter-emotion-diagnoise/" title="Twitter Dataset - Using LSTM to predict the emotion of the article">Twitter Dataset - Using LSTM to predict the emotion of the article</a><time datetime="2023-11-16T06:30:45.000Z" title="Created 2023-11-16 14:30:45">2023-11-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/en/posts/coco-object-diagnoise/" title="COCO Dataset - use Faster RCNN + MobileNet to conduct Object Detection"><img src="/en/img/loading-icon.gif" data-original="/en/img/cover/object-detection.jpeg" onerror="this.onerror=null;this.src='/en/img/404.jpg'" alt="COCO Dataset - use Faster RCNN + MobileNet to conduct Object Detection"/></a><div class="content"><a class="title" href="/en/posts/coco-object-diagnoise/" title="COCO Dataset - use Faster RCNN + MobileNet to conduct Object Detection">COCO Dataset - use Faster RCNN + MobileNet to conduct Object Detection</a><time datetime="2023-11-03T02:57:54.000Z" title="Created 2023-11-03 10:57:54">2023-11-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/en/posts/flower102-transfer-learning/" title="Flower102 Dataset - Using Transfer Learning to train + Using Batch Normalization in CNN"><img src="/en/img/loading-icon.gif" data-original="/en/img/cover/flower-ml.jpeg" onerror="this.onerror=null;this.src='/en/img/404.jpg'" alt="Flower102 Dataset - Using Transfer Learning to train + Using Batch Normalization in CNN"/></a><div class="content"><a class="title" href="/en/posts/flower102-transfer-learning/" title="Flower102 Dataset - Using Transfer Learning to train + Using Batch Normalization in CNN">Flower102 Dataset - Using Transfer Learning to train + Using Batch Normalization in CNN</a><time datetime="2023-10-31T06:27:13.000Z" title="Created 2023-10-31 14:27:13">2023-10-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/en/posts/pytorch-CNN-TensorBoard/" title="CIFAR10 Dataset - Using Pytorch to build CNN + activate GPU + output the result to TensorBoard"><img src="/en/img/loading-icon.gif" data-original="/en/img/cover/CNN-bg.jpeg" onerror="this.onerror=null;this.src='/en/img/404.jpg'" alt="CIFAR10 Dataset - Using Pytorch to build CNN + activate GPU + output the result to TensorBoard"/></a><div class="content"><a class="title" href="/en/posts/pytorch-CNN-TensorBoard/" title="CIFAR10 Dataset - Using Pytorch to build CNN + activate GPU + output the result to TensorBoard">CIFAR10 Dataset - Using Pytorch to build CNN + activate GPU + output the result to TensorBoard</a><time datetime="2023-10-24T06:40:52.000Z" title="Created 2023-10-24 14:40:52">2023-10-24</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2024 By Shannon Hung</div><div class="footer_custom_text">Hi, welcome to Shannon <a target="_blank" rel="noopener external nofollow noreferrer" href="https://butterfly.js.org/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="translateLink" type="button" title="Toggle Between Traditional Chinese And Simplified Chinese">EN</button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/en/js/utils.js"></script><script src="/en/js/main.js"></script><script src="/en/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const initGitalk = () => {
    const gitalk = new Gitalk(Object.assign({
      clientID: '51917ecdc184bb98b226',
      clientSecret: 'e48b44c1908c14b74ff7513f06c7cb892a4f4748',
      repo: 'shannonhung.github.io',
      owner: 'ShannonHung',
      admin: ['ShannonHung'],
      id: '84134249d7e65795a06c74e48f1a9571',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async() => {
    if (typeof Gitalk === 'function') initGitalk()
    else {
      await getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
      await getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js')
      initGitalk()
    }
  }
  
  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  if ('Gitalk' === 'Gitalk' || !false) {
    if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><script data-pjax src="/en/self/btf.js"></script><script data-pjax src="/en/self/tw_en.js"></script><script id="canvas_nest" defer="defer" color="139,71,38" opacity="0.5" zIndex="-1" count="500" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/en/js/search/local-search.js"></script></div></div>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 3,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(r){r.imageLazyLoadSetting.processImages=t;var e=r.imageLazyLoadSetting.isSPA,n=r.imageLazyLoadSetting.preloadRatio||1,c=a();function a(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(){e&&(c=a());for(var t,o=0;o<c.length;o++)0<=(t=(t=c[o]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(r.innerHeight*n||document.documentElement.clientHeight*n)&&function(){var t,e,n,a,i=c[o];e=function(){c=c.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(n=new Image,a=t.getAttribute("data-original"),n.onload=function(){t.src=a,t.removeAttribute("data-original"),e&&e()},t.src!==a&&(n.src=a))}()}function i(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",i),r.addEventListener("resize",i),r.addEventListener("orientationchange",i)}(this);</script></body></html>